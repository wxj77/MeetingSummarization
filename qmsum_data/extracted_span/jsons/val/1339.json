{
    "query": "<s> summarize the discussion on detecting important linguistic features",
    "answer": "professor a : yeah . yeah . so they would like clean channels . uh and for that mmm uh that purpose uh they 'd like to pull it out . so i think i think dan ellis or somebody who was working with him was going to uh work on that . so . ok . right ? um . and uh i do n't know if we 've talked lately about the the plans you 're developing that we talked about this morning uh i do n't remember if we talked about that last week or not , but maybe just a quick reprise of of what we were saying this morning . grad e : um . { comment } so continuing to um extend phd b : what about the stuff that um mirjam has been doing ? and and s shawn , yeah . oh . so they 're training up nets to try to recognize these acoustic features ? i see . professor a : but that 's uh uh all that 's is a a certainly relevant { comment } uh study and , you know , what are the features that they 're finding . we have this problem with the overloading of the term `` feature `` so phd b : yeah . professor a : uh what are the variables , what we 're calling this one , what are the variables that they 're found finding useful um for phd b : and their their targets are based on canonical mappings of phones to acoustic f features . professor a : right . and that 's certainly one thing to do and we 're gon na try and do something more f more fine than that but uh um so um so i guess you know what , i was trying to remember some of the things we were saying , do you ha still have that ? yeah . grad e : oh yeah . professor a : there 's those that uh yeah , some of some of the issues we were talking about was in j just getting a good handle on on uh what `` good features `` are and phd b : what does what did um larry saul use for it was the sonorant uh detector , right ? how did he h how did he do that ? wh - what was his detector ? mm - hmm . mm - hmm . oh , ok . mm - hmm . so how did he combine all these features ? what what r mmm classifier did he hmm . oh right . you were talking about that , yeah . i see . professor a : and the other thing you were talking about is is is where we get the targets from . so i mean , there 's these issues of what are the what are the variables that you use and do you combine them using the soft `` and - or `` or you do something , you know , more complicated um and then the other thing was so where do you get the targets from ? the initial thing is just the obvious that we 're discussing is starting up with phone labels from somewhere and then uh doing the transformation . but then the other thing is to do something better and eh w why do n't you tell us again about this this database ? this is the and then tell them to talk naturally ? yeah , yeah . phd b : pierced tongues and yeah . you could just mount it to that and they would n't even notice . weld it . zzz . professor a : maybe you could go to these parlors and and you could , you know you know have have , you know , reduced rates if you if you can do the measurements . phd b : yeah . i that 's right . you could what you could do is you could sell little rings and stuff with embedded you know , transmitters in them and things professor a : yeah . yeah , be cool and help science . phd b : and yeah . hmm ! there 's a bunch of data that l around , that people have done studies like that w way way back right ? i mean i ca n't remember where uh wisconsin or someplace that used to have a big database of yeah . i remember there was this guy at a t - andt , randolph ? or r what was his name ? do you remember that guy ? um , researcher at a t - andt a while back that was studying , trying to do speech recognition from these kinds of features . i ca n't remember what his name was . dang . now i 'll think of it . that 's interesting . professor a : do you mean eh but you i mean mar phd c : well he was the guy the guy that was using professor a : you mean when was was mark randolph there , or ? phd b : mark randolph . professor a : yeah he 's he 's he 's at motorola now . phd b : oh is he ? professor a : yeah . phd b : oh ok . professor a : yeah . phd b : yeah . phd c : is it the guy that was using the pattern of pressure on the tongue or ? phd b : i ca n't remember exactly what he was using , now . but i know i just remember it had to do with you know uh positional parameters phd c : what yeah . phd b : and trying to m you know do speech recognition based on them . phd c : mm - hmm . professor a : yeah . so the only the only uh hesitation i had about it since , i mean i have n't see the data is it sounds like it 's it 's continuous variables and a bunch of them . and so i do n't know how complicated it is to go from there what you really want are these binary labels , and just a few of them . and maybe there 's a trivial mapping if you wan na do it and it 's e but it i i i worry a little bit that this is a research project in itself , whereas um if you did something instead that like um having some manual annotation by uh you know , linguistics students , this would there 'd be a limited s set of things that you could do a as per our discussions with with john before phd b : mm - hmm . professor a : but the things that you could do , like nasality and voicing and a couple other things you probably could do reasonably well . phd b : mm - hmm . professor a : and then there would it would really be uh this uh uh binary variable . course then , that 's the other question is do you want binary variables . so . i mean the other thing you could do is boot trying to to uh get those binary variables and take the continuous variables from uh the uh uh the data itself there , but i i 'm not sure phd b : could you cluster the just do some kind of clustering ? professor a : guess you could , yeah . phd b : bin them up into different categories and professor a : yeah . so anyway that 's that 's uh that 's another whole direction that cou could be looked at . um . um . i mean in general it 's gon na be for new data that you look at , it 's gon na be hidden variable because we 're not gon na get everybody sitting in these meetings to wear the pellets and um . so . grad e : right . right . phd b : so you 're talking about using that data to get uh instead of using canonical mappings of phones . grad e : right . phd b : so you 'd use that data to give you sort of what the the true mappings are for each phone ? grad e : mm - hmm . phd b : i see . grad e : mm - hmm . professor a : yeah . so wh yeah , where this fits into the rest in in my mind , i guess , is that um we 're looking at different ways that we can combine uh different kinds of of rep front - end representations um in order to get robustness under difficult or even , you know , typical conditions . and part of it , this robustness , seems to come from uh multi - stream or multi - band sorts of things and saul seems to have a reasonable way of looking at it , at least for one one um articulatory feature . the question is is can we learn from that to change some of the other methods we have , since i mean , one of the things that 's nice about what he had i thought was that that it it um the decision about how strongly to train the different pieces is based on uh a a reasonable criterion with hidden variables rather than um just assuming that you should train e e every detector uh with equal strength towards uh it being this phone or that phone . right ? so it so um he 's got these um uh uh he `` and 's `` between these different features . it 's a soft `` and `` , i guess but in in principle you you wan na get a strong concurrence of all the different things that indicate something and then he `` or 's `` across the different soft `` or 's `` across the different uh multi - band channels . and um the weight yeah , the target for the training of the `` and `` `` and ' ed `` things is something that 's kept uh as a hidden variable , and is learned with em . whereas what we were doing is is uh taking the phone target and then just back propagating from that phd b : so he does n't have professor a : which means that it 's it 's uh i it could be for instance that for a particular point in the data you do n't want to um uh train a particular band train the detectors for a particular band . you you wan na ignore that band , cuz that 's a ban - band is a noisy noisy measure . phd b : mm - hmm . professor a : and we do n't we 're we 're still gon na try to train it up . in our scheme we 're gon na try to train it up to do as well well as it can at predicting . uh . maybe that 's not the right thing to do . phd b : so he does n't have to have truth marks or ho grad e : f right , and uh he does n't have to have hard labels . professor a : well at the at the tail end , yeah , he has to know what 's where it 's sonorant . but he 's but what he 's - but what he 's not training up uh what he does n't depend on as truth is grad e : right . for the full band . professor a : um i guess one way of describing would be if if a sound is sonorant is it sonorant in this band ? is it sonorant in that band ? grad e : right . professor a : is it sonorant in that band ? i it 's hard to even answer that what you really mean is that the whole sound is sonorant . so phd b : mm - hmm . ok . professor a : then it comes down to , you know , to what extent should you make use of information from particular band towards making your decision . and um uh we 're making in a sense sort of this hard decision that you should you should use everything uh with with uh equal strength . phd b : i see . professor a : and uh because in the ideal case we would be going for posterior probabilities , if we had uh enough data to really get posterior probabilities and if the if we also had enough data so that it was representative of the test data then we would in fact be doing the right thing to train everything as hard as we can . but um this is something that 's more built up along an idea of robustness from from the beginning and so you do n't necessarily want to train everything up towards the phd b : so where did he get his uh his tar his uh high - level targets about what 's sonorant and what 's not ? grad e : from uh canonical mappings { comment } um at first"
}