{
    "query": "<s> what did the professor think about clustering ?",
    "answer": "professor a : guess you could , yeah . phd b : bin them up into different categories and professor a : yeah . so anyway that 's that 's uh that 's another whole direction that cou could be looked at . um . um . i mean in general it 's gon na be for new data that you look at , it 's gon na be hidden variable because we 're not gon na get everybody sitting in these meetings to wear the pellets and um . so . grad e : right . right . phd b : so you 're talking about using that data to get uh instead of using canonical mappings of phones . grad e : right . phd b : so you 'd use that data to give you sort of what the the true mappings are for each phone ? grad e : mm - hmm . phd b : i see . grad e : mm - hmm . professor a : yeah . so wh yeah , where this fits into the rest in in my mind , i guess , is that um we 're looking at different ways that we can combine uh different kinds of of rep front - end representations um in order to get robustness under difficult or even , you know , typical conditions . and part of it , this robustness , seems to come from uh multi - stream or multi - band sorts of things and saul seems to have a reasonable way of looking at it , at least for one one um articulatory feature . the question is is can we learn from that to change some of the other methods we have , since i mean , one of the things that 's nice about what he had i thought was that that it it um the decision about how strongly to train the different pieces is based on uh a a reasonable criterion with hidden variables rather than um just assuming that you should train e e every detector uh with equal strength towards uh it being this phone or that phone . right ? so it so um he 's got these um uh uh he `` and 's `` between these different features . it 's a soft `` and `` , i guess but in in principle you you wan na get a strong concurrence of all the different things that indicate something and then he `` or 's `` across the different soft `` or 's `` across the different uh multi - band channels . and um the weight yeah , the target for the training of the `` and `` `` and ' ed `` things is something that 's kept uh as a hidden variable , and is learned with em . whereas what we were doing is is uh taking the phone target and then just back propagating from that phd b : so he does n't have professor a : which means that it 's it 's uh i it could be for instance that for a particular point in the data you do n't want to um uh train a particular band train the detectors for a particular band . you you wan na ignore that band , cuz that 's a ban - band is a noisy noisy measure . phd b : mm - hmm . professor a : and we do n't we 're we 're still gon na try to train it up . in our scheme we 're gon na try to train it up to do as well well as it can at predicting . uh . maybe that 's not the right thing to do . phd b : so he does n't have to have truth marks or ho grad e : f right , and uh he does n't have to have hard labels . professor a : well at the at the tail end , yeah , he has to know what 's where it 's sonorant . but he 's but what he 's - but what he 's not training up uh what he does n't depend on as truth is grad e : right . for the full band . professor a : um i guess one way of describing would be if if a sound is sonorant is it sonorant in this band ? is it sonorant in that band ? grad e : right . professor a : is it sonorant in that band ? i it 's hard to even answer that what you really mean is that the whole sound is sonorant . so phd b : mm - hmm . ok . professor a : then it comes down to , you know , to what extent should you make use of information from particular band towards making your decision . and um uh we 're making in a sense sort of this hard decision that you should you should use everything uh with with uh equal strength . phd b : i see . professor a : and uh because in the ideal case we would be going for posterior probabilities , if we had uh enough data to really get posterior probabilities and if the if we also had enough data so that it was representative of the test data then we would in fact be doing the right thing to train everything as hard as we can . but um this is something that 's more built up along an idea of robustness from from the beginning and so you do n't necessarily want to train everything up towards the phd b : so where did he get his uh his tar his uh high - level targets about what 's sonorant and what 's not ?"
}