{
    "query": "<s> what was discussed about contextualizing output ?",
    "answer": "grad b : well , if he does n't want to go there , even if the enter posterior proba so . go - there is no . enter is high , and info - on is high . grad c : well , yeah , just out of the other three , though , that you had in the those three nodes . the - d they did n't seem like they were mutually exclusive . grad b : no , there 's no . but it 's through the grad c : so th s so , yeah , but some so , some things would drop out , and some things would still be important . grad b : mm - hmm . grad c : but i guess what 's confusing me is , if we have a bayes - net to deal w another bayes - net to deal with this stuff , grad a : mm - hmm . grad c : you know , uh , is the only reason ok , so , i guess , if we have a ba - another bayes - net to deal with this stuff , the only r reason we can design it is cuz we know what each question is asking ? grad a : yeah . i think that 's true . grad c : and then , so , the only reason way we would know what question he 's asking is based upon oh , so if let 's say i had a construction parser , and i plug this in , i would know what each construction the communicative intent of the construction was grad a : mm - hmm . grad c : and so then i would know how to weight the nodes appropriately , in response . so no matter what they said , if i could map it onto a where - is construction , i could say , `` ah ! grad a : ge mm - hmm . grad c : well the the intent , here , was where - is `` , grad a : ok , right . grad c : and i could look at those . grad a : yeah . yes , i mean . sure . you do need to know i mean , to have that kind of information ."
}