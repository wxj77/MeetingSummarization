{
    "query": "<s> summarize the discussion about voice-unvoice detection",
    "answer": "professor c : ok . so uh , he 's not here , so you get to phd d : yeah , i will try to explain the thing that i did this this week during this week . professor c : yeah . phd d : well eh you know that i work i begin to work with a new feature to detect voice - unvoice . phd e : mm - hmm . phd d : what i trying two mlp to to the with this new feature and the fifteen feature uh from the eh bus base system phd e : the the mel cepstrum ? phd d : no , satly the mes the mel cepstrum , the new base system the new base system . phd e : oh the phd d : yeah , we phd e : ok , the aurora system . phd d : yeah the aurora system with the new filter , vad or something like that . and i 'm trying two mlp , one one that only have t three output , voice , unvoice , and silence , professor c : mm - hmm . phd d : and other one that have fifty - six output . the probabilities of the allophone . and i tried to do some experiment of recognition with that and only have result with with the mlp with the three output . and i put together the fifteen features and the three mlp output . and , well , the result are li a little bit better , but more or less similar . professor c : uh , i i 'm i 'm slightly confused . what what feeds the uh the three - output net ? phd d : voice , unvoice , and si professor c : no no , what feeds it ? what features does it see ? phd d : the feature the input ? the inputs are the fifteen the fifteen uh bases feature . professor c : uh - huh . phd d : the with the new code . and the other three features are r , the variance of the difference between the two spectrum , professor c : uh - huh . phd d : the variance of the auto - correlation function , except the the first point , because half the height value is r - zero professor c : mm - hmm . mm - hmm . mm - hmm . mm - hmm . phd d : and also r - zero , the first coefficient of the auto - correlation function . that is like the energy with these three feature , professor c : right . phd d : also these three feature . professor c : you would n't do like r - one over r - zero or something like that ? i mean usually for voiced - unvoiced you 'd do yeah , you 'd do something you 'd do energy phd d : yeah . professor c : but then you have something like spectral slope , which is you get like r - one ov over r - zero or something like that . phd d : uh yeah . phd e : what are the r 's ? professor c : r correlations . phd e : i 'm sorry i missed it . phd d : no , r c no . auto - correlation ? yes , yes , the variance of the auto - correlation function that uses that professor c : ye - well that 's the variance , but if you just say `` what is `` i mean , to first order , um yeah one of the differences between voiced , unvoiced and silence is energy . another one is but the other one is the spectral shape . phd d : yeah , i i 'll the spectral shape , professor c : yeah , and so r - one over r - zero is what you typically use for that . phd d : yeah . no , i do n't use that i ca n't use professor c : no , i 'm saying that 's what people us typically use . see , because it because this is this is just like a single number to tell you um `` does the spectrum look like that or does it look like that `` . phd d : mm - hmm . grad a : oh . r r r - zero . professor c : right ? phd d : mm - hmm . professor c : so if it 's if it 's um if it 's low energy uh but the but the spectrum looks like that or like that , it 's probably silence . phd d : mm - hmm . professor c : uh but if it 's low energy and the spectrum looks like that , it 's probably unvoiced . phd d : yeah . professor c : so if you just if you just had to pick two features to determine voiced - unvoiced , you 'd pick something about the spectrum like uh r - one over r - zero , um and r - zero phd d : mm - hmm , ok . professor c : or i i you know you 'd have some other energy measure and like in the old days people did like uh zero crossing counts . phd d : yeah , yeah . professor c : right . s s phd d : well , i can also th use this . professor c : yeah . um , phd d : bec - because the result are a little bit better but we have in a point that everything is more or less the similar more or less similar . professor c : yeah . but um phd d : it 's not quite better . professor c : right , but it seemed to me that what you were what you were getting at before was that there is something about the difference between the original signal or the original fft and with the filter which is what and the variance was one take uh on it . phd d : yeah , i used this too . professor c : right . but it it could be something else . suppose you did n't have anything like that . then in that case , if you have two nets , alright , and this one has three outputs , and this one has f phd d : mm - hmm . professor c : whatever , fifty - six , or something , phd d : mm - hmm . professor c : if you were to sum up the probabilities for the voiced and for the unvoiced and for the silence here , we 've found in the past you 'll do better at voiced - unvoiced - silence than you do with this one . so just having the three output thing does n't does n't really buy you anything . the issue is what you feed it . phd d : yeah . yeah , i have yeah . no phd e : so you 're saying take the features that go into the voiced - unvoiced - silence net and feed those into the other one , as additional inputs , rather than having a separate professor c : w w well that 's another way . phd d : yeah . professor c : that was n't what i was saying but yeah that 's certainly another thing to do . no i was just trying to say if you b if you bring this into the picture over this , what more does it buy you ? and what i was saying is that the only thing i think that it buys you is um based on whether you feed it something different . and something different in some fundamental way . and so the kind of thing that that she was talking about before , was looking at something uh ab um something uh about the difference between the the uh um log fft uh log power uh and the log magnitude uh f f - spectrum uh and the um uh filter bank . phd d : yeah . professor c : and so the filter bank is chosen in fact to sort of integrate out the effects of pitch and she 's saying you know trying so the particular measure that she chose was the variance of this m of this difference , but that might not be the right number . phd d : mm - hmm . maybe . professor c : right ? i mean maybe there 's something about the variance that 's that 's not enough or maybe there 's something else that that one could use , but i think that , for me , the thing that that struck me was that uh you wan na get something back here , so here 's here 's an idea . uh what about it you skip all the all the really clever things , and just fed the log magnitude spectrum into this ? phd d : ah i 'm sorry . professor c : this is f you have the log magnitude spectrum , and you were looking at that and the difference between the filter bank and and c c computing the variance . phd d : yeah . mm - hmm . professor c : that 's a clever thing to do . phd d : mm - hmm . professor c : what if you stopped being clever ? and you just took this thing in here because it 's a neural net and neural nets are wonderful phd d : mm - hmm . professor c : and figure out what they can what they most need from things , and i mean that 's what they 're good at . phd d : yeah . professor c : so i mean you 're you 're you 're trying to be clever and say what 's the statistic that should we should get about this difference but uh in fact , you know maybe just feeding this in or or feeding both of them in you know , another way , saying let it figure out what 's the what is the interaction , especially if you do this over multiple frames ? phd d : mm - hmm . professor c : then you have this over time , and and both kinds of measures and uh you might get uh something better . phd d : mm - hmm . phd e : so so do n't uh do n't do the division , but let the net have everything . professor c : that 's another thing you could do yeah . yeah . phd d : yeah . professor c : um . i mean , it seems to me , if you have exactly the right thing then it 's better to do it without the net because otherwise you 're asking the net to learn this you know , say if you wanted to learn how to do multiplication . phd e : mm - hmm . professor c : i mean you could feed it a bunch of s you could feed two numbers that you wanted to multiply into a net and have a bunch of nonlinearities in the middle and train it to get the product of the output and it would work . but , it 's kind of crazy , cuz we know how to multiply and you you 'd be you know much lower error usually if you just multiplied it out . but suppose you do n't really know what the right thing is . and that 's what these sort of dumb machine learning methods are good at . so . um . anyway . it 's just a thought . phd e : how long does it take , carmen , to train up one of these nets ? phd d : oh , not too much . phd e : yeah . phd d : mmm , one day or less . professor c : yeah , it 's probably worth it . grad a : what are what are your f uh frame error rates for for this ? phd d : eh fifty - f six uh no , the frame error rate ? fifty - six i think . professor c : is that maybe that 's accuracy ? phd d : percent . grad a : fif - fifty - six percent accurate for v voice - unvoice phd d : the accuracy . mm - hmm . no for , yes f i do n't remember for voice - unvoice , grad a : oh , ok . phd d : maybe for the other one . professor c : yeah , voiced - unvoiced hopefully would be a lot better . phd d : for voiced . i do n't reme grad a : should be in nineties somewhere . phd d : better . maybe for voice - unvoice . grad a : right . phd d : this is for the other one . i should i ca n't show that . but i think that fifty - five was for the when the output are the fifty - six phone . grad a : mm - hmm . phd d : that i look in the with the other nnn the other mlp that we have are more or less the same number . silence will be better but more or less the same . professor c : i think at the frame level for fifty - six that was the kind of number we were getting for for uh um reduced band width uh stuff . phd d : i think that i i i think that for the other one , for the three output , is sixty sixty - two , sixty three more or less . grad a : mm - hmm . professor c : that 's all ? phd d : it 's yeah . professor c : that 's pretty bad . phd d : yeah , because it 's noise also . grad a : oh yeah . phd d : and we have professor c : aha ! yeah . yeah . ok . phd d : i know . professor c : but even i in oh yeah , in training . still , uh . well actually , so this is a test that you should do then . um , if you 're getting fifty - six percent over here , uh that 's in noise also , right ? phd d : yeah , yeah , yeah . professor c : oh ok . if you 're getting fifty - six here , try adding together the probabilities of all of the voiced phones here and all of the unvoiced phones phd d : will be professor c : and see what you get then . phd d : yeah . professor c : i bet you get better than sixty - three . phd d : well i do n't know , but i th i i think that we i have the result more or less . maybe . i do n't know . i do n't i 'm not sure but i remember @ @ that i ca n't show that . professor c : ok , but that 's a that is a a good check point , you should do that anyway , phd d : yeah . professor c : ok ? given this this uh regular old net that 's just for choosing for other purposes , uh add up the probabilities of the different subclasses and see see how well you do . uh and that you know anything that you do over here should be at least as good as that . phd d : mm - hmm . i will do that . but phd e : the targets for the neural net , uh , they come from forced alignments ? phd d : uh , { comment } no . grad a : timit canonical ma mappings . phd d : timit . professor c : oh . so , this is trained on timit . phd e : ah ! ok . grad a : yeah , noisy timit . phd d : yeah . yeah this for timit . professor c : but noisy timit ? grad a : right . phd d : noisy timit . we have noisy timit with the noise of the the ti - digits . and now we have another noisy timit also with the noise of uh italian database . professor c : i see . yeah . well there 's gon na be it looks like there 's gon na be a noisy uh some large vocabulary noisy stuff too . somebody 's preparing . phd e : really ? professor c : yeah . i forget what it 'll be , resource management , wall street journal , something . some some read task actually , that they 're preparing . phd e : for what for aurora ? professor c : yeah . yeah , so the uh uh , the issue is whether people make a decision now based on what they 've already seen , or they make it later . and one of the arguments for making it later is let 's make sure that whatever techniques that we 're using work for something more than than connected digits . phd e : when are they planning when would they do that ? professor c : mmm , i think late uh i think in the summer sometime . so . ok , thanks ."
}