{
    "query": "<s> summarize the discussion on latency in the system",
    "answer": "phd d : um , so this is the first thing . um yeah , another thing that i it 's important to mention is , um , that this has a this has some additional latency . um . because when i do the smoothing , uh , it 's a recursion that estimated the means , so of the g of the gain curve . and this is a filter that has some latency . and i noticed that it 's better if we take into account this latency . so , instead o of using the current estimated mean to , uh , subtract the current frame , it 's better to use an estimate that 's some somewhere in the future . um phd a : and that 's what causes the latency ? ok . phd b : you mean , the m the mean is computed o based on some frames in the future also ? professor c : mm - hmm . phd d : yeah . phd b : or or no ? phd d : it 's the recursion , so it 's it 's the center recursion , right ? phd b : mm - hmm . phd d : um and the latency of this recursion is around fifty milliseconds . professor c : one five ? one five ? five zero ? phd d : five zero , professor c : five zero . phd d : yeah . professor c : yeah . phd b : i 'm sorry , why why is that delay coming ? like , you estimate the mean ? phd d : yeah , the mean estimation has some delay , right ? phd b : oh , yeah . phd d : i mean , the the filter that that estimates the mean has a time constant . phd b : it is n't ok , so it 's like it looks into the future also . ok . phd d : yeah . professor c : what if you just look into the past ? phd d : it 's , uh , not as good . it 's not bad . professor c : how m by how much ? phd d : um , it helps a lot over the ba the baseline but , mmm professor c : by how much ? phd d : it it 's around three percent , um , relative . professor c : worse . phd d : yeah . yeah . um , mmm so , uh professor c : it 's depending on how all this stuff comes out we may or may not be able to add any latency . phd d : yeah , but yeah . so , yeah , it depends . uh , y actually , it 's it 's l it 's three percent . right . mmm . yeah , b but i do n't think we have to worry too much on that right now while you kno . mm - hmm . professor c : um , s yeah , i mean , i think the only thing is that phd d : so professor c : i would worry about it a little . phd d : mm - hmm . professor c : because if we completely ignore latency , and then we discover that we really have to do something about it , we 're going to be find ourselves in a bind . phd d : mm - hmm . professor c : so , um , you know , maybe you could make it twenty - five . you know what i mean ? phd d : yeah . professor c : yeah , just , you know , just be be a little conservative phd d : oh yes . professor c : because we may end up with this crunch where all of a sudden we have to cut the latency in half or something . phd d : s mm - hmm . yeah . um . so , yeah , there are other things in the , um , algorithm that i did n't , uh , @ @ a lot yet , which phd a : sorry . a quick question just about the latency thing . if if there 's another part of the system that causes a latency of a hundred milliseconds , is this an additive thing ? or c or is yours hidden in that ? phd d : mm - hmm . phd a : uh phd d : no , it 's it 's added . phd a : it 's additive . ok . phd d : mm - hmm . phd b : we can ok . we can do something in parallel also , in some like some cases like , if you wanted to do voice activity detection . phd a : uh - huh . phd b : and we can do that in parallel with some other filtering you can do . so you can make a decision on that voice activity detection and then you decide whether you want to filter or not . phd d : yeah . phd b : but by then you already have the sufficient samples to do the filtering . phd a : mm - hmm . phd b : so so , sometimes you can do it anyway . phd a : i mean , could n't , uh i could n't you just also i mean , i if you know that the l the largest latency in the system is two hundred milliseconds , do n't you could n't you just buffer up that number of frames and then everything uses that buffer ? phd b : yeah . phd a : and that way it 's not additive ? professor c : well , in fact , everything is sent over in buffers cuz of is n't it the tcp buffer some ? phd b : you mean , the the data , the super frame or something ? phd d : mm - hmm . professor c : yeah , yeah . phd d : yeah . phd b : yeah , but that has a variable latency because the last frame does n't have any latency phd d : mm - hmm . phd b : and first frame has a twenty framed latency . so you ca n't r rely on that latency all the time . professor c : yeah . phd b : because i mean the transmission over over the air interface is like a buffer . phd d : yeah . phd b : twenty frame phd a : yeah . phd b : twenty four frames . phd a : yeah . phd b : so but the only thing is that the first frame in that twenty - four frame buffer has a twenty - four frame latency . and the last frame does n't have any latency . phd a : mm - hmm . phd b : because it just goes as phd a : yeah , i was n't thinking of that one in particular phd b : yeah . phd a : but more of , you know , if if there is some part of your system that has to buffer twenty frames , uh , ca n't the other parts of the system draw out of that buffer and therefore not add to the latency ? professor c : yeah . yeah . and and that 's sort of one of the all of that sort of stuff is things that they 're debating in their standards committee . phd a : oh ! hmm . phd d : mm - hmm . yeah . so , um , there is uh , { comment } these parameters that i still have to to look at . like , i played a little bit with this overestimation factor , uh , but i still have to to look more at this , um , at the level of noise i add after . uh , i know that adding noise helped , um , the system just using spectral subtraction without smoothing , but i do n't know right now if it 's still important or not , and if the level i choose before is still the right one . same thing for the shape of the the noise . maybe it would be better to add just white noise instead of speech shaped noise . professor c : that 'd be more like the jrasta thing in a sense . yeah . phd d : mm - hmm . um , yep . uh , and another thing is to yeah , for this i just use as noise estimate the mean , uh , spectrum of the first twenty frames of each utterance . i do n't remember for this experiment what did you use for these two stage phd b : i used ten just ten frames . yeah , because phd d : the ten frames ? phd b : i mean , the reason was like in ti - digits i do n't have a lot . i had twenty frames most of the time . phd d : mm - hmm . um . but , so what 's this result you told me about , the fact that if you use more than ten frames you can improve by t phd b : well , that 's that 's using the channel zero . if i use a channel zero vad to estimate the noise . phd d : oh , ok . phd b : which phd d : but this is ten frames plus plus phd b : channel zero dropping . phd d : channel uh , no , these results with two stage wiener filtering is ten frames phd b : t oh , this phd d : but possibly more . i mean , if channel one vad gives you phd b : f yeah . mm - hmm . yeah . phd d : yeah . ok . yeah , but in this experiment i did i did n't use any vad . i just used the twenty first frame to estimate the noise . and so i expected it to be a little bit better , if , uh , i use more more frames . um . ok , that 's it for spectral subtraction . the second thing i was working on is to , um , try to look at noise estimation , { comment } mmm , and using some technique that does n't need voice activity detection . um , and for this i u simply used some code that , uh , i had from from belgium , which is technique that , um , takes a bunch of frame , um , and for each frequency bands of this frame , takes a look at the minima of the energy . and then average these minima and take this as an an energy estimate of the noise for this particular frequency band . and there is something more to this actually . what is done is that , uh , these minima are computed , um , based on , um , high resolution spectra . so , i compute an fft based on the long , uh , signal frame which is sixty - four millisecond phd a : so you have one minimum for each frequency ? phd d : what what i what i d uh , i do actually , is to take a bunch of to take a tile on the spectrogram and this tile is five hundred milliseconds long and two hundred hertz wide . and this tile uh , in this tile appears , like , the harmonics if you have a voiced sound , because it 's it 's the ftt bins . and when you take the m the minima of of these this tile , when you do n't have speech , these minima will give you some noise level estimate , if you have voiced speech , these minima will still give you some noise estimate because the minima are between the harmonics . and if you have other other kind of speech sounds then it 's not the case , but if the time frame is long enough , uh , like s five hundred milliseconds seems to be long enough , { comment } you still have portions which , uh , are very close whi which minima are very close to the noise energy . professor c : i 'm confused . you said five hundred milliseconds but you said sixty - four milliseconds . which is which ? what ? phd d : sixty - four milliseconds is to compute the fft , uh , bins . professor c : yeah , phd d : the the fft . professor c : yeah . phd d : um , actually it 's better to use sixty - four milliseconds because , um , if you use thirty milliseconds , then , uh , because of the this short windowing and at low pitch , uh , sounds , the harmonics are not , wha uh , correctly separated . professor c : mm - hmm . phd d : so if you take these minima , it b they will overestimate the noise a lot . professor c : so you take sixty - four millisecond f f ts and then you average them { comment } over five hundred ? or ? uh , what do you do over five hundred ? phd d : so i take to i take a bunch of these sixty - four millisecond frame to cover five hundred milliseconds , professor c : ah . ok . phd d : and then i look for the minima , professor c : i see . phd d : on the on on the bunch of uh fifty frames , right ? professor c : i see . phd d : mmm . so the interest of this is that , as y with this technique you can estimate u some reasonable noise spectra with only five hundred milliseconds of of signal , so if the the n the noise varies a lot , uh , you can track better track the noise , professor c : mm - hmm . phd d : which is not the case if you rely on the voice activity detector . so even if there are no no speech pauses , you can track the noise level . the only requirement is that you must have , in these five hundred milliseconds segment , { comment } you must have voiced sound at least . cuz this these will help you to to track the the noise level . um . so what i did is just to simply replace the vad - based , uh , noise estimate by this estimate , first on speechdat - car well , only on speechdat - car actually . and it 's , uh , slightly worse , like one percent relative compared to the vad - based estimates . um , i think the reason why it 's not better , is that the speechdat - car noises are all stationary . um . so , u y y there really is no need to have something that 's adaptive professor c : mm - hmm . phd d : and uh , well , they are mainly stationary . um . but , i expect s maybe some improvement on ti - digits because , nnn , in this case the noises are all sometimes very variable . uh , so i have to test it . mmm . professor c : but are you comparing with something e i 'm i 'm p s a little confused again , i it uh , when you compare it with the v a d - based , phd d : mm - hmm . professor c : vad - is this is this the ? phd d : it 's it 's the france - telecom - based spectra , s uh , wiener filtering and vad . so it 's their system but just i replace their noise estimate by this one . professor c : oh , you 're not doing this with our system ? phd d : in i i 'm not no , no . yeah , it 's our system but with just the wiener filtering from their system . right ? mmm . yeah . actually , th the best system that we still have is , uh , our system but with their noise compensation scheme , right ? professor c : right . but phd d : so i 'm trying to improve on this , and by by replacing their noise estimate by , uh , something that might be better . professor c : ok . but the spectral subtraction scheme that you reported on also re requires a a noise estimate . phd d : yeah . yeah . professor c : could n't you try this for that ? phd d : but i di professor c : do you think it might help ? phd d : not yet , because i did this in parallel , professor c : i see , phd d : and i was working on one and the other . professor c : i see . yeah . phd b : yeah . phd d : yeah , for for sure i will . i can try also , mmm , the spectral subtraction . phd b : so i 'm also using that n new noise estimate technique on this wiener filtering what i 'm trying . so i i have , like , some experiments running , i do n't have the results . phd d : mm - hmm . professor c : yeah . yeah . phd b : i do n't estimate the f noise on the ten frames but use his estimate . professor c : yeah . phd d : mm - hmm . um . yeah . i , um , also implemented a sp um spectral whitening idea which is in the , um , ericsson proposal . uh , the idea is just to um , flatten the log , uh , spectrum , um , and to flatten it more if the the probability of silence is higher . so in this way , you can also reduce somewhat reduce the musical noise and you reduce the variability if you have different noise shapes , because the the spectrum becomes more flat in the silence portions . um . yeah . with this , no improvement , uh , but there are a lot of parameters that we can play with and , um actually , this this could be seen as a soft version of the frame dropping because , um , you could just put the threshold and say that `` below the threshold , i will flatten comp completely flatten the the spectrum `` . and above this threshold , uh , keep the same spectrum . so it would be like frame dropping , because during the silence portions which are below the threshold of voice activity probability , { comment } uh , w you would have some kind of dummy frame which is a perfectly flat spectrum . and this , uh , whitening is something that 's more soft because , um , you whiten you just , uh , have a function the whitening is a function of the speech probability , so it 's not a hard decision . professor c : mm - hmm . phd d : um , so i think maybe it can be used together with frame dropping and when we are not sure about if it 's speech or silence , well , maybe it has something do with this . professor c : it 's interesting . i mean , um , you know , in in jrasta we were essentially adding in , uh , white uh , white noise dependent on our estimate of the noise . phd d : mm - hmm . professor c : on the overall estimate of the noise . uh , i think it never occurred to us to use a probability in there . phd d : mm - hmm ."
}