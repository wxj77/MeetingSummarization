{
    "query": "<s> summarize the meeting",
    "answer": "phd a : it 's not very significant . professor b : uh , channel one . yes . grad d : channel three . phd f : mm - hmm . grad d : channel three . channel three . alright . professor b : ok , did you solve speech recognition last week ? grad e : almost . professor b : alright ! let 's do image processing . phd c : yes , again . phd a : great . phd c : we did it again , morgan . professor b : alright ! grad e : doo - doop , doo - doo . phd a : what 's wrong with ? professor b : ok . it 's april fifth . actually , hynek should be getting back in town shortly if he is n't already . phd c : is he gon na come here ? professor b : uh . well , we 'll drag him here . i know where he is . phd c : so when you said `` in town `` , you mean oregon . professor b : u u u u uh , i meant , you know , this end of the world , yeah , is really what i meant , grad e : doo , doo - doo . professor b : uh , cuz he 's been in europe . grad e : doo - doo . phd c : i have something just fairly brief to report on . um , i did some experim uh , uh , just a few more experiments before i had to , uh , go away for the w well , that week . professor b : great ! phd c : was it last week or whenever ? um , so what i was started playing with was the th again , this is the htk back - end . and , um , i was curious because the way that they train up the models , they go through about four sort of rounds of of training . and in the first round they do uh , i think it 's three iterations , and for the last three rounds e e they do seven iterations of re - estimation in each of those three . and so , you know , that 's part of what takes so long to train the the the back - end for this . professor b : i 'm sorry , i did n't quite get that . there 's there 's four and there 's seven and i i 'm sorry . phd c : yeah . uh , maybe i should write it on the board . so , there 's four rounds of training . um , i g i g i guess you could say iterations . the first one is three , then seven , seven , and seven . and what these numbers refer to is the number of times that the , uh , hmm re - estimation is run . it 's this program called h e professor b : but in htk , what 's the difference between , uh , a an inner loop and an outer loop in these iterations ? phd c : ok . so what happens is , um , at each one of these points , you increase the number of gaussians in the model . professor b : yeah . oh , right ! this was the mix up stuff . phd c : yeah . the mix up . professor b : that 's right . phd c : right . professor b : i remember now . phd c : and so , in the final one here , you end up with , uh for all of the the digit words , you end up with , uh , three mixtures per state , professor b : yeah . phd c : eh , in the final thing . so i had done some experiments where i was i i want to play with the number of mixtures . professor b : mm - hmm . phd c : but , um , uh , i wanted to first test to see if we actually need to do this many iterations early on . grad e : uh , one , two , professor b : mm - hmm . phd c : and so , um , i i ran a couple of experiments where i reduced that to l to be three , two , two , uh , five , i think , and i got almost the exact same results . professor b : mm - hmm . phd c : and but it runs much much faster . so , um , i i think m it only took something like , uh , three or four hours to do the full training , professor b : as opposed to ? phd f : good . phd c : as opposed to wh what , sixteen hours or something like that ? i mean , it takes you have to do an overnight basically , the way it is set up now . phd f : yeah . it depends . phd a : mm - hmm . professor b : mm - hmm . phd c : so , uh , even we do n't do anything else , doing something like this could allow us to turn experiments around a lot faster . professor b : and then when you have your final thing , do a full one , so it 's phd c : and when you have your final thing , we go back to this . phd f : yeah . phd c : so , um , and it 's a real simple change to make . i mean , it 's like one little text file you edit and change those numbers , and you do n't do anything else . phd f : oh , this is a phd a : mm - hmm . phd c : and then you just run . so it 's a very simple change to make and it does n't seem to hurt all that much . phd a : so you you run with three , two , two , five ? that 's a phd c : so i uh , i i have to look to see what the exact numbers were . phd a : yeah . phd c : i i thought was , like , three , two , two , five , phd a : mm - hmm . phd c : but i i 'll i 'll double check . it was over a week ago that i did it , phd a : ok . mm - hmm . phd c : so i ca n't remember exactly . but , uh professor b : mm - hmm . phd c : um , but it 's so much faster . i it makes a big difference . so we could do a lot more experiments and throw a lot more stuff in there . phd f : yeah . professor b : that 's great . phd c : um . oh , the other thing that i did was , um , i compiled the htk stuff for the linux boxes . so we have this big thing that we got from ibm , which is a five - processor machine . really fast , but it 's running linux . so , you can now run your experiments on that machine and you can run five at a time and it runs , uh , as fast as , you know , uh , five different machines . phd a : mm - hmm . phd f : mm - hmm . phd c : so , um , i 've forgotten now what the name of that machine is but i can i can send email around about it . phd a : yeah . phd c : and so we 've got it now htk 's compiled for both the linux and for , um , the sparcs . um , you have to make you have to make sure that in your dot cshrc , um , it detects whether you 're running on the linux or a a sparc and points to the right executables . uh , and you may not have had that in your dot cshrc before , if you were always just running the sparc . so , um , phd a : mm - hmm . phd c : uh , i can i can tell you exactly what you need to do to get all of that to work . but it 'll it really increases what we can run on . grad e : hmm . cool . phd c : so , together with the fact that we 've got these faster linux boxes and that it takes less time to do these , um , we should be able to crank through a lot more experiments . phd a : mm - hmm . phd c : so after i did that , then what i wanted to do { comment } was try increasing the number of mixtures , just to see , um see how how that affects performance . phd a : yeah . professor b : yeah . in fact , you could do something like keep exactly the same procedure and then add a fifth thing onto it phd c : mm - hmm . professor b : that had more . phd c : exactly . professor b : yeah . phd c : right . right . grad e : so at at the middle o where the arrows are showing , that 's you 're adding one more mixture per state , phd c : uh - huh . uh , grad e : or ? phd c : let 's see , uh . it goes from this uh , try to go it backwards this at this point it 's two mixtures per state . so this just adds one . except that , uh , actually for the silence model , it 's six mixtures per state . professor b : mm - hmm . phd c : uh , so it goes to two . um . and i think what happens here is professor b : might be between , uh , shared , uh shared variances or something , phd c : yeah . i think that 's what it is . professor b : or phd c : uh , yeah . it 's , uh shoot . i i i ca n't remember now what happens at that first one . uh , i have to look it up and see . grad e : oh , ok . phd c : um , there because they start off with , uh , an initial model which is just this global model , and then they split it to the individuals . and so , it may be that that 's what 's happening here . i i i have to look it up and see . i i do n't exactly remember . so . that 's it . professor b : alright . so what else ? phd a : um . yeah . there was a conference call this tuesday . um . i do n't know yet the what happened tuesday , but the points that they were supposed to discuss is still , uh , things like the weights , uh professor b : oh , this is a conference call for , uh , uh , aurora participant sort of thing . grad e : for phd a : yeah . yeah . professor b : i see . do you know who was who was since we were n't in on it , uh , do you know who was in from ogi ? was was was hynek involved or was it sunil phd a : i have no idea . professor b : or ? phd a : mmm , i just professor b : oh , you do n't know . ok . phd a : yeah . professor b : alright . phd a : um , yeah . so the points were the the weights how to weight the different error rates that are obtained from different language and and conditions . um , it 's not clear that they will keep the same kind of weighting . right now it 's a weighting on on improvement . professor b : mm - hmm . phd a : some people are arguing that it would be better to have weights on uh well , to to combine error rates before computing improvement . uh , and the fact is that for right now for the english , they have weights they they combine error rates , but for the other languages they combine improvement . so it 's not very consistent . um professor b : mm - hmm . phd a : yeah . the , um yeah . and so well , this is a point . and right now actually there is a thing also , uh , that happens with the current weight is that a very non - significant improvement on the well - matched case result in huge differences in in the final number . professor b : mm - hmm . phd a : and so , perhaps they will change the weights to yeah . phd c : how should that be done ? i mean , it it seems like there 's a simple way phd a : mm - hmm . phd c : uh , this seems like an obvious mistake or something . professor b : well , i mean , the fact that it 's inconsistent is an obvious mistake . phd c : th - they 're professor b : but the but , um , the other thing i do n't know i have n't thought it through , but one one would think that each it it 's like if you say what 's the what 's the best way to do an average , an arithmetic average or a geometric average ? phd c : mm - hmm . professor b : it depends what you wan na show . phd a : mm - hmm . professor b : each each one is gon na have a different characteristic . phd a : yeah . professor b : so phd c : well , it seems like they should do , like , the percentage improvement or something , rather than the absolute improvement . phd a : tha - that 's what they do . professor b : well , they are doing that . phd a : yeah . professor b : no , that is relative . but the question is , do you average the relative improvements or do you average the error rates and take the relative improvement maybe of that ? phd a : yeah . yeah . professor b : and the thing is it 's not just a pure average because there are these weightings . it 's a weighted average . um . phd a : yeah . and so when you average the the relative improvement it tends to to give a lot of of , um , importance to the well - matched case because the baseline is already very good and , um , i it 's phd c : why do n't they not look at improvements but just look at your av your scores ? you know , figure out how to combine the scores phd a : mm - hmm . phd c : with a weight or whatever , and then give you a score here 's your score . and then they can do the same thing for the baseline system and here 's its score . and then you can look at phd a : mm - hmm . professor b : well , that 's what he 's seeing as one of the things they could do . phd a : yeah . professor b : it 's just when you when you get all done , i think that they pro i m i i was n't there but i think they started off this process with the notion that you should be significantly better than the previous standard . phd c : mm - hmm . professor b : and , um , so they said `` how much is significantly better ? what do you ? `` and and so they said `` well , you know , you should have half the errors , `` or something , `` that you had before `` . phd a : mm - hmm . hmm . phd c : mm - hmm . phd a : yeah . professor b : so it 's , uh , but it does seem like i i it does seem like it 's more logical to combine them first and then do the phd a : combine error rates and then professor b : yeah . phd a : yeah . well professor b : yeah . phd a : but there is this this is this still this problem of weights . when when you combine error rate it tends to give more importance to the difficult cases , and some people think that professor b : oh , yeah ? phd a : well , they have different , um , opinions about this . some people think that it 's more important to look at to have ten percent imp relative improvement on well - matched case than to have fifty percent on the m mismatched , and other people think that it 's more important to improve a lot on the mismatch and so , bu phd c : it sounds like they do n't really have a good idea about what the final application is gon na be . phd a : l de fff ! mmm . professor b : well , you know , the the thing is that if you look at the numbers on the on the more difficult cases , um , if you really believe that was gon na be the predominant use , none of this would be good enough . phd a : yeah . mmm . yeah . professor b : nothing anybody 's phd c : mm - hmm . professor b : whereas you sort of with some reasonable error recovery could imagine in the better cases that these these systems working . so , um , i think the hope would be that it would uh , it would work well for the good cases and , uh , it would have reasonable reas soft degradation as you got to worse and worse conditions . um . phd c : yeah . i i guess what i 'm i mean , i i was thinking about it in terms of , if i were building the final product and i was gon na test to see which front - end i 'd i wanted to use , i would try to weight things depending on the exact environment that i was gon na be using the system in . professor b : but but no . phd c : if i professor b : well , no well , no . i mean , it is n't the operating theater . i mean , they don they they do n't they do n't really know , i think . phd c : yeah . professor b : i mean , i th phd c : so if if they do n't know , does n't that suggest the way for them to go ? uh , you assume everything 's equal . i mean , y y i mean , you professor b : well , i mean , i i think one thing to do is to just not rely on a single number to maybe have two or three numbers , phd c : yeah . professor b : you know , phd c : right . professor b : and and and say here 's how much you , uh you improve the , uh the the relatively clean case and here 's or or well - matched case , and here 's how here 's how much you , phd c : mm - hmm . professor b : uh phd c : so not so not try to combine them . professor b : yeah . uh , actually it 's true . phd c : yeah . professor b : uh , i had forgotten this , uh , but , uh , well - matched is not actually clean . what it is is just that , u uh , the training and testing are similar . phd c : the training and testing . professor b : so , i guess what you would do in practice is you 'd try to get as many , uh , examples of similar sort of stuff as you could , and then , phd c : yeah . professor b : uh so the argument for that being the the the more important thing , is that you 're gon na try and do that , but you wan na see how badly it deviates from that when when when the , uh it 's a little different . phd c : so so you should weight those other conditions v very you know , really small . professor b : but no . that 's a that 's a that 's an arg phd c : i mean , that 's more of an information kind of thing . professor b : that 's an ar well , that 's an argument for it , but let me give you the opposite argument . the opposite argument is you 're never really gon na have a good sample of all these different things . phd c : uh - huh . professor b : i mean , are you gon na have w uh , uh , examples with the windows open , half open , full open ? going seventy , sixty , fifty , forty miles an hour ? on what kind of roads ? phd c : mm - hmm . professor b : with what passing you ? with uh , i mean , phd c : mm - hmm . professor b : i i i think that you could make the opposite argument that the well - matched case is a fantasy . phd c : mm - hmm . professor b : you know , so , grad e : uh - huh . professor b : i think the thing is is that if you look at the well - matched case versus the po you know , the the medium and the and the fo and then the mismatched case , um , we 're seeing really , really big differences in performance . right ? and and y you would n't like that to be the case . you would n't like that as soon as you step outside you know , a lot of the the cases it 's is phd c : well , that 'll teach them to roll their window up . professor b : i mean , in these cases , if you go from the the , uh i mean , i do n't remember the numbers right off , but if you if you go from the well - matched case to the medium , it 's not an enormous difference in the in the the training - testing situation , and and and it 's a really big performance drop . phd c : mm - hmm . professor b : you know , so , um yeah , i mean the reference one , for instance this is back old on , uh on italian uh , was like six percent error for the well - matched and eighteen for the medium - matched and sixty for the for highly - mismatched . uh , and , you know , with these other systems we we helped it out quite a bit , but still there 's there 's something like a factor of two or something between well - matched and medium - matched . and so i think that if what you 're if the goal of this is to come up with robust features , it does mean so you could argue , in fact , that the well - matched is something you should n't be looking at at all , that that the goal is to come up with features that will still give you reasonable performance , you know , with again gentle degregra degradation , um , even though the the testing condition is not the same as the training . so , you know , i i could argue strongly that something like the medium mismatch , which is you know not compl pathological but i mean , what was the the medium - mismatch condition again ? phd a : um , it 's yeah . medium mismatch is everything with the far microphone , but trained on , like , low noisy condition , like low speed and or stopped car and tested on high - speed conditions , i think , like on a highway and professor b : right . phd a : so professor b : so it 's still the same same microphone in both cases , phd a : same microphone but yeah . professor b : but , uh , it 's there 's a mismatch between the car conditions . and that 's uh , you could argue that 's a pretty realistic situation phd c : yeah . phd a : mm - hmm . professor b : and , uh , i 'd almost argue for weighting that highest . but the way they have it now , it 's i guess it 's it 's they they compute the relative improvement first and then average that with a weighting ? phd a : yeah . professor b : and so then the that that makes the highly - matched the really big thing . phd a : mm - hmm . professor b : um , so , u i since they have these three categories , it seems like the reasonable thing to do is to go across the languages and to come up with an improvement for each of those . phd a : mm - hmm . professor b : just say `` ok , in the in the highly - matched case this is what happens , in the m the , uh this other m medium if this happens , in the highly - mismatched that happens `` . phd a : mm - hmm . professor b : and , uh , you should see , uh , a gentle degradation through that . um . but i do n't know . phd a : yeah . professor b : i think that that i i i gather that in these meetings it 's it 's really tricky to make anything ac make any { comment } policy change because everybody has has , uh , their own opinion phd a : mm - hmm . professor b : and i do n't know . phd a : yeah . professor b : yeah . phd a : uh , so yeah . yeah , but there is probably a a big change that will be made is that the the baseline th they want to have a new baseline , perhaps , which is , um , mfcc but with a voice activity detector . and apparently , uh , some people are pushing to still keep this fifty percent number . so they want to have at least fifty percent improvement on the baseline , but w which would be a much better baseline . professor b : mm - hmm . mm - hmm . phd a : and if we look at the result that sunil sent , just putting the vad in the baseline improved , like , more than twenty percent , professor b : mm - hmm . phd a : which would mean then then mean that fifty percent on this new baseline is like , well , more than sixty percent improvement on on o e e uh professor b : so nobody would be there , probably . right ? phd a : right now , nobody would be there , but yeah . professor b : good . work to do . phd a : uh - huh . professor b : so whose vad is is is this a ? phd a : uh , they did n't decide yet . i guess i this was one point of the conference call also , but mmm , so i do n't know . um , but yeah . professor b : oh , i i think th that would be good . i mean , it 's not that the design of the vad is n't important , but it 's just that it it it does seem to be i uh , a lot of work to do a good job on on that and as well as being a lot of work to do a good job on the feature design , phd a : yeah . yeah . professor b : if we can cut down on that maybe we can make some progress . phd a : m yeah . but i guess perhaps i do n't know w yeah . uh , yeah . per - e s s someone told that perhaps it 's not fair to do that because the , um to make a good vad you do n't have enough to with the the features that are the baseline features . so mmm , you need more features . so you really need to put more more in the in in the front - end . professor b : yeah . sure . but i bu phd c : wait a minute . i i 'm confused . phd a : yeah . phd c : wha - what do you mean ? phd a : yeah , if i professor b : so y so you m s yeah , but well , let 's say for ins see , mfcc for instance does n't have anything in it , uh , related to the pitch . so just just for example . so suppose you 've that what you really wan na do is put a good pitch detector on there and if it gets an unambiguous phd c : oh , oh . i see . phd a : mm - hmm . professor b : if it gets an unambiguous result then you 're definitely in a in a in a voice in a , uh , s region with speech . uh . phd c : so there 's this assumption that the v the voice activity detector can only use the mfcc ? phd a : that 's not clear , but this e professor b : well , for the baseline . phd c : yeah . professor b : so so if you use other features then y but it 's just a question of what is your baseline . right ? what is it that you 're supposed to do better than ? phd c : i g yeah . professor b : and so having the baseline be the mfcc 's means that people could choose to pour their ener their effort into trying to do a really good vad phd c : i do n't s but they seem like two separate issues . professor b : or tryi they 're sort of separate . phd c : right ? i mean professor b : unfortunately there 's coupling between them , which is part of what i think stephane is getting to , is that you can choose your features in such a way as to improve the vad . phd a : yeah . professor b : and you also can choose your features in such a way as to prove improve recognition . they may not be the same thing . phd c : but it seems like you should do both . professor b : you should do both phd c : right ? professor b : and and i i think that this still makes i still think this makes sense as a baseline . it 's just saying , as a baseline , we know you know , we had the mfcc 's before , lots of people have done voice activity detectors , phd a : mm - hmm . professor b : you might as well pick some voice activity detector and make that the baseline , just like you picked some version of htk and made that the baseline . phd a : yeah . right . professor b : and then let 's try and make everything better . um , and if one of the ways you make it better is by having your features be better features for the vad then that 's so be it . phd a : mm - hmm . professor b : but , uh , uh , uh , at least you have a starting point that 's um , cuz i i some of the some of the people did n't have a vad at all , i guess . right ? and and phd a : yeah . professor b : then they they looked pretty bad and and in fact what they were doing was n't so bad at all . phd a : mm - hmm . mm - hmm . professor b : but , um . phd c : yeah . it seems like you should try to make your baseline as good as possible . and if it turns out that you ca n't improve on that , well , i mean , then , you know , nobody wins and you just use mfcc . right ? professor b : yeah . i mean , it seems like , uh , it should include sort of the current state of the art that you want are trying to improve , and mfcc 's , you know , or plp or something it seems like reasonable baseline for the features , and anybody doing this task , uh , is gon na have some sort of voice activity detection at some level , in some way . they might use the whole recognizer to do it but rather than a separate thing , but but they 'll have it on some level . so , um . phd c : it seems like whatever they choose they should n't , you know , purposefully brain - damage a part of the system to make a worse baseline , or professor b : well , i think people just had phd c : you know ? professor b : it was n't that they purposely brain - damaged it . i think people had n't really thought through about the , uh the vad issue . phd a : mm - hmm . professor b : and and then when the the the proposals actually came in and half of them had v a ds and half of them did n't , and the half that did did well and the half that did n't did poorly . phd c : mm - hmm . professor b : so it 's phd a : mm - hmm . um . yeah . so we 'll see what happen with this . and yeah . so what happened since , um , last week is well , from ogi , these experiments on putting vad on the baseline . and these experiments also are using , uh , some kind of noise compensation , so spectral subtraction , and putting on - line normalization , um , just after this . so i think spectral subtraction , lda filtering , and on - line normalization , so which is similar to the pro proposal - one , but with spectral subtraction in addition , and it seems that on - line normalization does n't help further when you have spectral subtraction . phd c : is this related to the issue that you brought up a couple of meetings ago with the the musical tones phd a : i phd c : and ? phd a : i have no idea , because the issue i brought up was with a very simple spectral subtraction approach , and the one that they use at ogi is one from from the proposed the the the aurora prop uh , proposals , which might be much better . so , yeah . i asked sunil for more information about that , but , uh , i do n't know yet . um . and what 's happened here is that we so we have this kind of new , um , reference system which use a nice a a clean downsampling - upsampling , which use a new filter that 's much shorter and which also cuts the frequency below sixty - four hertz , professor b : right . phd a : which was not done on our first proposal . professor b : when you say `` we have that `` , does sunil have it now , too , phd a : i no . professor b : or ? phd a : because we 're still testing . so we have the result for , uh , just the features and we are currently testing with putting the neural network in the klt . um , it seems to improve on the well - matched case , um , but it 's a little bit worse on the mismatch and highly - mismatched i mean when we put the neural network . and with the current weighting i think it 's sh it will be better because the well - matched case is better . mmm . professor b : but how much worse since the weighting might change how how much worse is it on the other conditions , when you say it 's a little worse ? phd a : it 's like , uh , fff , fff { comment } um , { comment } ten percent relative . yeah . professor b : ok . um . phd a : mm - hmm . professor b : but it has the , uh the latencies are much shorter . that 's phd a : uh - y w when i say it 's worse , it 's not it 's when i i uh , compare proposal - two to proposal - one , so , r uh , y putting neural network compared to n not having any neural network . i mean , this new system is is is better , professor b : uh - huh . phd a : because it has um , this sixty - four hertz cut - off , uh , clean downsampling , and , um what else ? uh , yeah , a good vad . we put the good vad . so . yeah , i do n't know . i i j uh , uh pr professor b : but the latencies but you 've got the latency shorter now . phd a : latency is short is yeah . professor b : yeah . phd f : is n't it phd a : and so professor b : so it 's better than the system that we had before . phd a : yeah . mainly because of the sixty - four hertz and the good vad . and then i took this system and , mmm , w uh , i p we put the old filters also . so we have this good system , with good vad , with the short filter and with the long filter , and , um , with the short filter it 's not worse . so well , is it it 's in professor b : so that 's that 's all fine . phd a : yes . uh professor b : but what you 're saying is that when you do these so let me try to understand . when when you do these same improvements to proposal - one , phd a : mm - hmm . professor b : that , uh , on the i things are somewhat better , uh , in proposal - two for the well - matched case and somewhat worse for the other two cases . phd a : yeah . professor b : so does , uh when you say , uh so the th now that these other things are in there , is it the case maybe that the additions of proposal - two over proposal - one are less im important ? phd a : yeah . probably , yeah . professor b : i get it . phd a : um so , yeah . uh . yeah , but it 's a good thing anyway to have shorter delay . then we tried , um , to do something like proposal - two but having , um , e using also msg features . so there is this klt part , which use just the standard features , professor b : mm - hmm . right . phd a : and then two neura two neural networks . professor b : mm - hmm . phd a : mmm , and it does n't seem to help . um , however , we just have one result , which is the italian mismatch , so . uh . we have to wait for that to fill the whole table , but professor b : ok . there was a start of some effort on something related to voicing or something . is that ? phd a : yeah . um , yeah . so basically we try to , uh , find good features that could be used for voicing detection , uh , but it 's still , uh on the , um t phd f : oh , well , i have the picture . phd a : we w basically we are still playing with matlab to to look at at what happened , phd c : what sorts of phd f : yeah . phd a : and phd c : what sorts of features are you looking at ? phd f : we have some phd a : so we would be looking at , um , the variance of the spectrum of the excitation , phd f : uh , um , this , this , and this . phd a : something like this , which is should be high for voiced sounds . uh , we phd c : wait a minute . i what does that mean ? the variance of the spectrum of excitation . phd a : yeah . so the so basically the spectrum of the excitation for a purely periodic sig signal shou sh professor b : ok . yeah , w what yo what you 're calling the excitation , as i recall , is you 're subtracting the the , um the mel mel mel filter , uh , spectrum from the fft spectrum . phd a : e that 's right . yeah . so professor b : right . phd a : yeah . phd f : mm - hmm . phd a : so we have the mel f filter bank , we have the fft , so we just professor b : so it 's it 's not really an excitation , but it 's something that hopefully tells you something about the excitation . phd a : yeah , that 's right . professor b : yeah , yeah . phd a : um yeah . phd f : we have here some histogram , phd a : e yeah , phd f : but they have a lot of overlap . phd a : but it 's it 's still yeah . so , well , for unvoiced portion we have something tha that has a mean around o point three , and for voiced portion the mean is o point fifty - nine . but the variance seem quite high . phd c : how do you know ? phd a : so mmm . phd c : how did you get your voiced and unvoiced truth data ? phd a : we used , uh , timit and we used canonical mappings between the phones phd f : yeah . we , uh , use timit on this , for phd a : th yeah . phd f : but if we look at it in one sentence , it apparently it 's good , i think . phd a : yeah , but yeah . uh , so it 's noisy timit . that 's right . yeah . grad e : it 's noisy timit . phd f : yeah . phd a : it seems quite robust to noise , so when we take we draw its parameters across time for a clean sentence and then nois the same noisy sentence , it 's very close . professor b : mm - hmm . phd a : yeah . so there are there is this . there could be also the , um something like the maximum of the auto - correlation function or which phd c : is this a a s a trained system ? or is it a system where you just pick some thresholds ? ho - how does it work ? phd a : right now we just are trying to find some features . and , phd c : mm - hmm . phd a : uh yeah . hopefully , i think what we want to have is to put these features in s some kind of , um well , to to obtain a statistical model on these features and to or just to use a neural network and hopefully these features w would help phd c : because it seems like what you said about the mean of the the voiced and the unvoiced { comment } that seemed pretty encouraging . phd a : mm - hmm . professor b : well , yeah , except the variance was big . phd c : right ? phd a : yeah . except the variance is quite high . professor b : right ? phd c : well , y phd a : yeah . phd c : well , y i i do n't know that i would trust that so much because you 're doing these canonical mappings from timit labellings . phd a : uh - huh . phd c : right ? so , really that 's sort of a cartoon picture about what 's voiced and unvoiced . so that could be giving you a lot of variance . phd a : yeah . phd c : i mean , i it it may be that that you 're finding something good and that the variance is sort of artificial because of how you 're getting your truth . phd a : mm - hmm . professor b : yeah . but another way of looking at it might be that i mean , what w we we are coming up with feature sets after all . so another way of looking at it is that um , the mel cepstru mel spectrum , mel cepstrum , any of these variants , um , give you the smooth spectrum . it 's the spectral envelope . by going back to the fft , you 're getting something that is more like the raw data . so the question is , what characterization and you 're playing around with this another way of looking at it is what characterization of the difference between the raw data and this smooth version is something that you 're missing that could help ? so , i mean , looking at different statistical measures of that difference , coming up with some things and just trying them out and seeing if you add them onto the feature vector does that make things better or worse in noise , where you 're really just i i the way i 'm looking at it is not so much you 're trying to f find the best the world 's best voiced - unvoiced , uh , uh , classifier , phd c : mm - hmm . professor b : but it 's more that , you know , uh , uh , try some different statistical characterizations of that difference back to the raw data phd c : right . professor b : and and m maybe there 's something there that the system can use . phd c : right . phd a : yeah . yeah , but ther more obvious is that yeah . the the more obvious is that that well , using the th the fft , um , you just it gives you just information about if it 's voiced or not voiced , ma mainly , i mean . but so , professor b : yeah . phd a : this is why we we started to look by having sort of voiced phonemes professor b : well , that 's the rea w w what i 'm arguing is that 's yeah . i mean , uh , what i 'm arguing is that that that 's givi you gives you your intuition . phd a : and mm - hmm . professor b : but in in reality , it 's you know , there 's all of this this overlap and so forth , grad e : oh , sorry . professor b : and but what i 'm saying is that may be ok , because what you 're really getting is not actually voiced versus unvoiced , both for the fac the reason of the overlap and and then , uh , th you know , structural reasons , uh , uh , like the one that chuck said , that that in fact , well , the data itself is that you 're working with is not perfect . phd a : yeah . mm - hmm . professor b : so , what i 'm saying is maybe that 's not a killer because you 're just getting some characterization , one that 's driven by your intuition about voiced - unvoiced certainly , phd a : mm - hmm . professor b : but it 's just some characterization of something back in the in the in the almost raw data , rather than the smooth version . phd a : mm - hmm . professor b : and your intuition is driving you towards particular kinds of , uh , statistical characterizations of , um , what 's missing from the spectral envelope . phd a : mm - hmm . professor b : um , obviously you have something about the excitation , um , and what is it about the excitation , and , you know and you 're not getting the excitation anyway , you know . so so i i would almost take a uh , especially if if these trainings and so forth are faster , i would almost just take a uh , a scattershot at a few different ways of look of characterizing that difference and , uh , you could have one of them but and and see , you know , which of them helps . phd a : mm - hmm . ok . phd c : so i is the idea that you 're going to take whatever features you develop and and just add them onto the future vector ? or , what 's the use of the the voiced - unvoiced detector ? phd a : uh , i guess we do n't know exactly yet . but , um yeah . th phd c : it 's not part of a vad system that you 're doing ? phd a : uh , no . no . phd c : oh , ok . phd a : no , the idea was , i guess , to to use them as as features . phd c : features . i see . phd a : uh yeah , it could be , uh it could be a neural network that does voiced and unvoiced detection , phd c : mm - hmm . phd a : but it could be in the also the big neural network that does phoneme classification . phd c : mm - hmm . phd a : mmm . yeah . professor b : but each one of the mixture components i mean , you have , uh , uh , variance only , so it 's kind of like you 're just multiplying together these , um , probabilities from the individual features within each mixture . so it 's so , uh , it seems l you know phd c : i think it 's a neat thing . uh , it seems like a good idea . professor b : yeah . um . yeah . i mean , i know that , um , people doing some robustness things a ways back were were just doing just being gross and just throwing in the fft and actually it was n't was n't was n't so bad . uh , so it would s and and you know that i it 's got ta hurt you a little bit to not have a a spectral , uh a s a smooth spectral envelope , so there must be something else that you get in return for that phd a : mm - hmm . professor b : that , uh uh so . phd c : so how does uh , maybe i 'm going in too much detail , but how exactly do you make the difference between the fft and the smoothed spectral envelope ? wha - wh i i uh , how is that , uh ? phd a : um , we just how did we do it up again ? phd f : uh , we distend the we have the twenty - three coefficient af after the mel f filter , phd a : mm - hmm . phd f : and we extend these coefficient between the all the frequency range . phd c : mm - hmm . phd f : and i the interpolation i between the point is give for the triang triangular filter , the value of the triangular filter and of this way we obtained this mode this model speech . professor b : so you essentially take the values that th that you get from the triangular filter and extend them to sor sort of like a rectangle , that 's at that m value . phd f : yeah . phd a : yeah . i think we have linear interpolation . phd f : mm - hmm . phd a : so we have we have one point for one energy for each filter bank , phd f : mmm yeah , it 's linear . phd a : which is the energy that 's centered on on on the triangle phd f : yeah . at the n at the center of the filter phd c : so you you end up with a vector that 's the same length as the fft vector ? phd a : yeah . that 's right . phd f : yeah . phd c : and then you just , uh , compute differences phd f : yeah . i have here one example if you if you want see something like that . phd a : then we compute the difference . yeah . uh - huh . phd c : uh , sum the differences ? phd a : so . and i think the variance is computed only from , like , two hundred hertz to one to fifteen hundred . phd c : oh ! ok . professor b : mm - hmm . phd f : two thou two { comment } fifteen hundred ? professor b : mm - hmm . phd a : because professor b : right . phd f : two hundred and fifty thousand . phd a : fifteen hundred . because yeah . phd f : yeah . two thousand and fifteen hundred . phd a : above , um it seems that well , some voiced sound can have also , like , a noisy part on high frequencies , and but professor b : yeah . phd a : well , it 's just professor b : no , it 's makes sense to look at low frequencies . phd c : so this is uh , basically this is comparing an original version of the signal to a smoothed version of the same signal ? phd f : yeah . professor b : right . so i so i i this is i mean , i you could argue about whether it should be linear interpolation or or or or zeroeth order , but but phd c : uh - huh . professor b : at any rate something like this is what you 're feeding your recognizer , typically . phd c : like which of the ? professor b : no . uh , so the mel cepstrum is the is the is the cepstrum of this this , uh , spectrum or log spectrum , phd a : so this is yeah . phd c : yeah . right , right . professor b : whatever it you - you 're subtracting in in in power domain or log domain ? phd a : in log domain . yeah . phd f : log domain . professor b : ok . so it 's sort of like division , when you do the yeah , the spectra . phd f : yeah . phd a : uh , yeah . phd c : it 's the ratio . professor b : um . yeah . but , anyway , um and that 's phd c : so what 's th uh , what 's the intuition behind this kind of a thing ? i i do n't know really know the signal - processing well enough to understand what what is that doing . phd a : so . yeah . what happen if what we have have what we would like to have is some spectrum of the excitation signal , professor b : yeah . i guess that makes sense . yeah . phd a : which is for voiced sound ideally a a pulse train phd c : uh - huh . phd a : and for unvoiced it 's something that 's more flat . phd c : uh - huh . right . phd a : and the way to do this is that well , we have the we have the fft because it 's computed in in the in the system , and we have the mel filter banks , phd c : mm - hmm . mm - hmm . phd a : and so if we if we , like , remove the mel filter bank from the fft , we have something that 's close to the excitation signal . it 's something that 's like a a a train of p a pulse train for voiced sound professor b : yeah . phd c : oh ! ok . yeah . phd a : and that 's that should be flat for professor b : yeah . phd c : i see . so do you have a picture that sh ? phd a : so - it 's y phd c : is this for a voiced segment , phd a : yeah . phd c : this picture ? what does it look like for unvoiced ? phd f : yeah . phd a : you have several some unvoiced ? phd f : the dif no . unvoiced , i do n't have for unvoiced . professor b : yeah . so , you know , all phd f : i 'm sorry . phd a : but yeah . professor b : yeah . phd f : yeah . this is the between phd a : this is another voiced example . yeah . phd f : no . but it 's this , phd a : oh , yeah . this is phd f : but between the frequency that we are considered for the excitation phd a : right . mm - hmm . phd f : for the difference and this is the difference . phd a : yeah . phd c : this is the difference . ok . phd a : so , of course , it 's around zero , professor b : yeah . grad e : sure looks phd a : but well , no . it is phd f : yeah . because we begin , uh , in fifteen point the fifteen point . phd c : so , does does the periodicity of this signal say something about the the phd f : fifteen p phd a : so it 's yeah . professor b : pitch . phd a : it 's the pitch . phd c : the pitch ? phd a : yeah . mm - hmm . professor b : yeah . that 's like fundamental frequency . phd a : mm - hmm . professor b : so , i mean , i t t phd c : ok . i see . professor b : i mean , to first order what you 'd what you 're doing i mean , ignore all the details and all the ways which is that these are complete lies . uh , the the you know , what you 're doing in feature extraction for speech recognition is you have , uh , in your head a a a a simplified production model for speech , phd c : mm - hmm . professor b : in which you have a periodic or aperiodic source that 's driving some filters . phd c : mm - hmm . phd f : yeah . this is the the auto - correlation the r - zero energy . phd a : do you have the mean do you have the mean for the auto - correlation ? professor b : uh , first order for speech recognition , you say `` i do n't care about the source `` . phd f : for yeah . phd a : well , i mean for the the energy . phd f : i have the mean . professor b : right ? phd c : right . professor b : and so you just want to find out what the filters are . phd c : right . phd f : yeah . professor b : the filters roughly act like a , um a , uh a an overall resonant you know , f some resonances and so forth that th that 's processing excitation . phd f : here . phd a : they should be more close . phd f : ah , no . this is this ? more close . is this ? and this . phd c : mm - hmm . phd a : yeah . phd c : mm - hmm . phd a : so they are this is there is less difference . phd f : mm - hmm . professor b : so if you look at the spectral envelope , just the very smooth properties of it , you get something closer to that . phd a : this is less it 's less robust . phd f : less robust . yeah . phd a : oh , yeah . professor b : and the notion is if you have the full spectrum , with all the little nitty - gritty details , that that has the effect of both , phd c : yeah . professor b : and it would be a multiplication in in frequency domain phd c : mm - hmm . professor b : so that would be like an addition in log power spectrum domain . phd c : mm - hmm . mm - hmm . professor b : and so this is saying , well , if you really do have that sort of vocal tract envelope , and you subtract that off , what you get is the excitation . and i call that lies because you do n't really have that , you just have some kind of signal - processing trickery to get something that 's kind of smooth . it 's not really what 's happening in the vocal tract phd c : yeah . professor b : so you 're not really getting the vocal excitation . phd c : right . professor b : that 's why i was going to the why i was referring to it in a more a more , uh , uh , conservative way , when i was saying `` well , it 's yeah , it 's the excitation `` . but it 's not really the excitation . it 's whatever it is that 's different between phd c : oh . this moved in the professor b : so so , stand standing back from that , you sort of say there 's this very detailed representation . phd c : yeah . professor b : you go to a smooth representation . phd c : mm - hmm . professor b : you go to a smooth representation cuz this typically generalizes better . phd c : mm - hmm . professor b : um , but whenever you smooth you lose something , so the question is have you lost something you can you use ? phd c : right . professor b : um , probably you would n't want to go to the extreme of just ta saying `` ok , our feature set will be the fft `` , cuz we really think we do gain something in robustness from going to something smoother , but maybe there 's something that we missed . phd c : mm - hmm . professor b : so what is it ? phd c : yeah . professor b : and then you go back to the intuition that , well , you do n't really get the excitation , but you get something related to it . phd c : mm - hmm . professor b : and it and as you can see from those pictures , you do get something that shows some periodicity , uh , in frequency , phd c : mm - hmm . professor b : you know , and and and also in time . so phd c : that 's that 's really neat . so you do n't have one for unvoiced picture ? phd f : uh , not here . no , i have s phd a : mm - hmm . professor b : yeah . phd f : but not here . professor b : but presumably you 'll see something that wo n't have this kind of , uh , uh , uh , regularity in frequency , uh , in the phd a : but yeah . well . phd f : not here . phd c : i would li i would like to see those pictures . phd f : well , so . professor b : yeah . phd f : i ca n't see you { comment } now . professor b : yeah . phd c : yeah . professor b : yeah . phd a : mm - hmm . phd f : i do n't have . phd c : and so you said this is pretty doing this kind of thing is pretty robust to noise ? phd a : it seems , yeah . um , phd f : pfft . oops . the mean is different with it , because the the histogram for the the classifica phd a : no , no , no . but th the kind of robustness to noise so if if you take this frame , uh , from the noisy utterance and the same frame from the clean utterance phd c : you end up with a similar difference phd a : y y y yeah . we end up with phd c : over here ? phd a : yeah . phd c : ok . cool ! phd f : i have here the same frame for the clean speech phd c : oh , that 's clean . phd f : the same cle phd c : oh , ok phd f : but they are a difference . phd a : yeah , that 's phd f : because here the fft is only with two hundred fifty - six point and this is with five hundred twelve . phd a : yeah . this is kind of inter interesting also because if we use the standard , uh , frame length of of , like , twenty - five milliseconds , um , what happens is that for low - pitched voiced , because of the frame length , y you do n't really have you do n't clearly see this periodic structure , professor b : mm - hmm . phd a : because of the first lobe of of each each of the harmonics . phd c : so this one inclu is a longer ah . phd a : so , this is like yeah , fifty milliseconds or something like that . phd f : fifty millis yeah . phd a : yeah , but it 's the same frame and phd c : oh , it 's that time - frequency trade - off thing . phd a : yeah . phd c : right ? i see . yeah . phd a : so , yeah . professor b : mm - hmm . phd c : oh . oh , so this i is this the difference here , for that ? phd f : no . this is the signal . this is the signal . phd a : i see that . oh , yeah . phd f : the frame . phd c : oh , that 's the f the original . phd a : yeah . phd f : this is the fra the original frame . phd a : so with a short frame basically you have only two periods phd c : yeah . phd a : and it 's not not enough to to have this kind of neat things . phd c : mm - hmm . phd f : mm - hmm . phd c : yeah . phd a : but phd f : and here no , well . phd a : yeah . so probably we 'll have to use , like , long f long frames . mm - hmm . phd c : mm - hmm . that 's interesting . professor b : yeah , maybe . well , i mean it looks better , but , i mean , the thing is if if , uh if you 're actually asking you know , if you actually j uh , need to do place along an fft , it may be it may be pushing things . phd a : yeah . professor b : and and , uh phd c : would you would you wan na do this kind of , uh , difference thing after you do spectral subtraction ? phd a : uh , maybe . phd f : no . maybe we can do that . professor b : hmm . the spectral subtraction is being done at what level ? is it being done at the level of fft bins or at the level of , uh , mel spectrum or something ? phd a : um , i guess it depends . professor b : i mean , how are they doing it ? phd a : how they 're doing it ? yeah . um , i guess ericsson is on the , um , filter bank , phd f : fft . filter bank , phd a : no ? it 's on the filter bank , phd f : yeah . phd a : so . so , yeah , probably i i it yeah . professor b : so in that case , it might not make much difference at all . phd c : seems like you 'd wan na do it on the fft bins . professor b : maybe . i mean , certainly it 'd be better . phd c : i i mean , if you were gon na uh , for for this purpose , that is . phd a : mm - hmm . professor b : yeah . phd a : mm - hmm . professor b : yeah . ok . what else ? phd a : uh . yeah , that 's all . so we 'll perhaps try to convince ogi people to use the new the new filters and yeah . professor b : ok . uh , has has anything happened yet on this business of having some sort of standard , uh , source , phd a : uh , not yet professor b : or ? phd a : but i wi i will call them and now they are i think they have more time because they have this well , eurospeech deadline is over phd c : when is the next , um , aurora deadline ? phd a : and it 's , um , in june . yeah . phd c : june . professor b : early june , late june , middle june ? phd a : i do n't know w professor b : ok . um , and he 's been doing all the talking but but these he 's he 's , uh phd f : yeah . professor b : this is this by the way a bad thing . we 're trying to get , um , m more female voices in this record as well . so . make sur make sure carmen talks as well . uh , but has he pretty much been talking about what you 're doing also , and ? phd f : oh , i i am doing this . yeah , yeah . i do n't know . i 'm sorry , but i think that for the recognizer for the meeting recorder that it 's better that i do n't speak . professor b : yeah , well . phd f : because professor b : you know , uh , we 'll get we 'll get to , uh , spanish voices sometime , and we do we want to recognize , uh , you too . phd f : after the after , uh , the result for the ti - digits on the meeting record there will be foreigns people . phd a : yeah , but professor b : oh , no . we like we we 're we 're w we are we 're in the , uh , bourlard - hermansky - morgan , uh , frame of mind . yeah , we like high error rates . it 's phd a : yeah . professor b : that way there 's lots of work to do . so it 's uh , anything to talk about ? grad d : n um , not not not much is new . so when i talked about what i 'm planning to do last time , i said i was , um , going to use avendano 's method of , um , using a transformation , um , to map from long analysis frames which are used for removing reverberation to short analysis frames for feature calculation . he has a trick for doing that involving viewing the dft as a matrix . um , but , uh , um , i decided not to do that after all because i i realized to use it i 'd need to have these short analysis frames get plugged directly into the feature computation somehow professor b : mm - hmm . grad d : and right now i think our feature computation is set to up to , um , take , um , audio as input , in general . so i decided that i i 'll do the reverberation removal on the long analysis windows and then just re - synthesize audio and then send that . professor b : this is in order to use the sri system or something . right ? grad d : um , or or even if i 'm using our system , i was thinking it might be easier to just re - synthesize the audio , professor b : yeah ? grad d : because then i could just feacalc as is and i would n't have to change the code . professor b : oh , ok . yeah . i mean , it 's um , certainly in a short short - term this just sounds easier . grad d : uh - huh . professor b : yeah . i mean , longer - term if it 's if it turns out to be useful , one one might want to do something else , grad d : right . that 's true . professor b : but uh , uh , i mean , in in other words , you you may be putting other kinds of errors in from the re - synthesis process . grad d : but e u from the re - synthesis ? um , professor b : yeah . grad d : o - ok . i do n't know anything about re - synthesis . uh , how likely do you think that is ? professor b : uh , it depends what you what you do . i mean , it 's it 's it 's , uh , um do n't know . but anyway it sounds like a reasonable way to go for a for an initial thing , and we can look at at exactly what you end up doing and and then figure out if there 's some something that could be be hurt by the end part of the process . ok . so that 's that was it , huh ? grad d : that yeah , e that 's it , that 's it . professor b : ok . ok . grad d : uh - huh . professor b : um , anything to add ? grad e : um . well , i 've been continuing reading . i went off on a little tangent this past week , um , looking at , uh , uh , modulation s spectrum stuff , um , and and learning a bit about what what , um what it is , and , uh , the importance of it in speech recognition . and i found some some , uh , neat papers , um , historical papers from , um , kanedera , hermansky , and arai . professor b : yeah . grad e : and they they did a lot of experiments where th where , um , they take speech and , um , e they modify the , uh they they they measure the relative importance of having different , um , portions of the modulation spectrum intact . professor b : yeah . grad e : and they find that the the spectrum between one and sixteen hertz in the modulation is , uh is im important for speech recognition . professor b : sure . i mean , this sort of goes back to earlier stuff by drullman . and and , uh , the the msg features were sort of built up with this notion grad e : yeah . right . professor b : but , i guess , i thought you had brought this up in the context of , um , targets somehow . grad e : right . professor b : but i m grad e : um professor b : i it 's not i mean , they 're sort of not in the same kind of category as , say , a phonetic target or a syllabic target grad e : mmm . mm - hmm . professor b : or a grad e : um , i was thinking more like using them as as the inputs to to the detectors . professor b : or a feature or something . oh , i see . well , that 's sort of what msg does . grad e : yeah . yeah . professor b : right ? so it 's grad e : mm - hmm . professor b : but but , uh yeah . grad e : yeah . professor b : anyway , we 'll talk more about it later . yeah . grad e : we can talk more about it later . professor b : yeah . yeah . grad e : yeah . professor b : so maybe , le phd c : should we do digits ? professor b : let 's do digits . let you you start . grad d : oh , ok . grad e : l fifty ."
}