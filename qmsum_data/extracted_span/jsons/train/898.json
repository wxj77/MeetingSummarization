{
    "query": "<s> summarize the meeting",
    "answer": "phd a : alright . we 're on . professor b : test , um . test , test , test . guess that 's me . yeah . ok . grad d : ooh , thursday . professor b : so . there 's two sheets of paper in front of us . phd a : what are these ? phd e : yeah . so . professor b : this is the arm wrestling ? phd c : uh . yeah , we formed a coalition actually . phd e : yeah . almost . phd c : we already made it into one . professor b : oh , good . phd c : yeah . professor b : excellent . phd e : yeah . professor b : that 's the best thing . phd e : mm - hmm . professor b : so , tell me about it . phd e : so it 's well , it 's spectral subtraction or wiener filtering , um , depending on if we put if we square the transfer function or not . professor b : right . phd e : and then with over - estimation of the noise , depending on the , uh the snr , with smoothing along time , um , smoothing along frequency . professor b : mm - hmm . phd e : it 's very simple , smoothing things . professor b : mm - hmm . phd e : and , um , the best result is when we apply this procedure on fft bins , uh , with a wiener filter . professor b : mm - hmm . phd e : and there is no noise addition after after that . so it 's good because it 's difficult when we have to add noise to to to find the right level . phd a : are you looking at one in in particular of these two ? phd e : yeah . so the sh it 's the sheet that gives fifty - f three point sixty - six . professor b : mm - hmm . phd e : um , the second sheet is abo uh , about the same . it 's the same , um , idea but it 's working on mel bands , and it 's a spectral subtraction instead of wiener filter , and there is also a noise addition after , uh , cleaning up the mel bins . mmm . well , the results are similar . professor b : yeah . i mean , it 's { comment } it 's actually , uh , very similar . phd e : mm - hmm . professor b : i mean , if you look at databases , uh , the , uh , one that has the smallest smaller overall number is actually better on the finnish and spanish , uh , but it is , uh , worse on the , uh , aurora phd e : it 's worse on professor b : i mean on the , uh , ti - ti - digits , phd e : on the multi - condition in ti - digits . yeah . professor b : uh , uh . um . so , it probably does n't matter that much either way . but , um , when you say u uh , unified do you mean , uh , it 's one piece of software now , or ? phd e : so now we are , yeah , setting up the software . professor b : mm - hmm . phd e : um , it should be ready , uh , very soon . um , and we phd a : so what 's what 's happened ? i think i 've missed something . professor b : ok . so a week ago maybe you were n't around when when when hynek and guenther and i ? phd c : hynek was here . phd a : yeah . i did n't . professor b : oh , ok . so yeah , let 's summarize . um and then if i summarize somebody can tell me if i 'm wrong , which will also be possibly helpful . what did i just press here ? i hope this is still working . phd e : p - p - p professor b : we , uh we looked at , uh anyway we after coming back from qualcomm we had , you know , very strong feedback and , uh , i think it was hynek and guenter 's and my opinion also that , um , you know , we sort of spread out to look at a number of different ways of doing noise suppression . but given the limited time , uh , it was sort of time to choose one . phd a : mm - hmm . mmm . professor b : uh , and so , uh , th the vector taylor series had n't really worked out that much . uh , the subspace stuff , uh , had not been worked with so much . um , so it sort of came down to spectral subtraction versus wiener filtering . uh , we had a long discussion about how they were the same and how they were d uh , completely different . phd a : mm - hmm . professor b : and , uh , i mean , fundamentally they 're the same sort of thing but the math is a little different so that there 's a a there 's an exponent difference in the index you know , what 's the ideal filtering , and depending on how you construct the problem . phd a : uh - huh . professor b : and , uh , i guess it 's sort you know , after after that meeting it sort of made more sense to me because um , if you 're dealing with power spectra then how are you gon na choose your error ? and typically you 'll do choose something like a variance . and so that means it 'll be something like the square of the power spectra . whereas when you 're when you 're doing the the , uh , um , looking at it the other way , you 're gon na be dealing with signals phd c : mm - hmm . professor b : and you 're gon na end up looking at power uh , noise power that you 're trying to reduce . and so , eh so there should be a difference of you know , conceptually of of , uh , a factor of two in the exponent . phd a : mm - hmm . professor b : but there 're so many different little factors that you adjust in terms of of , uh , uh , over - subtraction and and and and and so forth , um , that arguably , you 're c and and and the choice of do you do you operate on the mel bands or do you operate on the fft beforehand . there 're so many other choices to make that are are almost well , if not independent , certainly in addition to the choice of whether you , uh , do spectral subtraction or wiener filtering , that , um , @ @ again we sort of felt the gang should just sort of figure out which it is they wan na do and then let 's pick it , go forward with it . so that 's that was that was last week . and and , uh , we said , uh , take a week , go arm wrestle , you know , figure it out . i mean , and th the joke there was that each of them had specialized in one of them . phd a : oh , ok . professor b : and and so they so instead they went to yosemite and bonded , and and they came out with a single single piece of software . so it 's another another victory for international collaboration . so . phd a : so so you guys have combined or you 're going to be combining the software ? phd c : well , the piece of software has , like , plenty of options , phd e : oh boy . phd c : like you can parse command - line arguments . so depending on that , it it becomes either spectral subtraction or wiener filtering . phd a : oh , ok . phd c : so , ye phd a : they 're close enough . professor b : well , that 's fine , but the thing is the important thing is that there is a piece of software that you that we all will be using now . phd c : yeah . yeah . there 's just one piece of software . phd e : yeah . professor b : yeah . phd e : i need to allow it to do everything and even more more than this . phd c : right . phd e : well , if we want to , like , optimize different parameters of phd c : parameters . yeah . professor b : sure . phd e : yeah , we can do it later . but , still so , there will be a piece of software with , uh , will give this system , the fifty - three point sixty - six , by default and professor b : mm - hmm . phd a : how how is how good is that ? phd e : mm - hmm . phd a : i i i do n't have a sense of phd e : it 's just one percent off of the best proposal . phd c : best system . phd e : it 's between i we are second actually if we take this system . professor b : yeah . phd c : yeah . phd e : right ? phd a : compared to the last evaluation numbers ? yeah . professor b : but , uh w which we sort of were before phd c : yeah . phd e : mm - hmm . yeah . professor b : but we were considerably far behind . and the thing is , this does n't have neural net in yet for instance . you know ? phd e : mm - hmm . professor b : so it so , um , it 's it it 's not using our full bal bag of tricks , if you will . phd a : mm - hmm . professor b : and , uh , and it it is , uh , very close in performance to the best thing that was there before . uh , but , you know , looking at it another way , maybe more importantly , uh , we did n't have any explicit noise , uh , handling stationary dealing with e e we did n't explicitly have anything to deal with stationary noise . phd a : mm - hmm . professor b : and now we do . phd a : so will the neural net operate on the output from either the wiener filtering or the spectral subtraction ? or will it operate on the original ? professor b : well , so so so argu arguably , i mean , what we should do i mean , i gather you have it sounds like you have a few more days of of nailing things down with the software and so on . but and then but , um , arguably what we should do is , even though the software can do many things , we should for now pick a set of things , th these things i would guess , and not change that . phd e : mm - hmm . professor b : and then focus on everything that 's left . and i think , you know , that our goal should be by next week , when hynek comes back , uh , to uh , really just to have a firm path , uh , for the you know , for the time he 's gone , of of , uh , what things will be attacked . but i would i would i would thought think that what we would wan na do is not futz with this stuff for a while because what 'll happen is we 'll change many other things in the system , phd a : mm - hmm . professor b : and then we 'll probably wan na come back to this and possibly make some other choices . but , um . phd a : but just conceptually , where does the neural net go ? do do you wan na h run it on the output of the spectrally subtracted ? professor b : well , depending on its size well , one question is , is it on the , um , server side or is it on the terminal side ? uh , if it 's on the server side , it you probably do n't have to worry too much about size . phd a : mm - hmm . professor b : so that 's kind of an argument for that . we do still , however , have to consider its latency . so the issue is is , um , for instance , could we have a neural net that only looked at the past ? phd a : right . professor b : um , what we 've done in uh in the past is to use the neural net , uh , to transform , um , all of the features that we use . so this is done early on . this is essentially , um , um i guess it 's it 's more or less like a spee a speech enhancement technique here phd a : mm - hmm . professor b : right ? where we 're just kind of creating new if not new speech at least new new fft 's that that have you know , which could be turned into speech uh , that that have some of the noise removed . phd e : mm - hmm . phd a : mm - hmm . professor b : um , after that we still do a mess of other things to to produce a bunch of features . phd a : right . professor b : and then those features are not now currently transformed by the neural net . and then the the way that we had it in our proposal - two before , we had the neural net transformed features and we had the untransformed features , which i guess you you actually did linearly transform with the klt , phd e : yeah . yeah . right . professor b : but but but uh , to orthogonalize them but but they were not , uh , processed through a neural net . and stephane 's idea with that , as i recall , was that you 'd have one part of the feature vector that was very discriminant and another part that was n't , phd a : mm - hmm . professor b : uh , which would smooth things a bit for those occasions when , uh , the testing set was quite different than what you 'd trained your discriminant features for . so , um , all of that is is , uh still seems like a good idea . the thing is now we know some other constraints . we ca n't have unlimited amounts of latency . uh , y you know , that 's still being debated by the by people in europe but , uh , no matter how they end up there , it 's not going to be unlimited amounts , phd a : yeah . professor b : so we have to be a little conscious of that . um . so there 's the neural net issue . there 's the vad issue . and , uh , there 's the second stream thing . and i think those that we last time we agreed that those are the three things that have to get , uh , focused on . phd a : what was the issue with the vad ? professor b : well , better { comment } ones are good . phd a : and so the w the default , uh , boundaries that they provide are they 're ok , but they 're not all that great ? professor b : i guess they still allow two hundred milliseconds on either side or some ? is that what the deal is ? phd e : mm - hmm . uh , so th um , they keep two hundred milliseconds at the beginning and end of speech . and they keep all the phd a : outside the beginnings and end . phd e : yeah . phd a : uh - huh . phd e : and all the speech pauses , which is sometimes on the speechdat - car you have pauses that are more than one or two seconds . more than one second for sure . um . yeah . and , yeah , it seems to us that this way of just dropping the beginning and end is not we cou we can do better , i think , phd a : mm - hmm . phd e : because , um , with this way of dropping the frames they improve over the baseline by fourteen percent and sunil already showed that with our current vad we can improve by more than twenty percent . phd a : on top of the vad that they provide ? phd e : just using either their vad or our current vad . phd c : our way . phd a : oh , ok . phd e : so , our current vad is is more than twenty percent , while their is fourteen . phd a : theirs is fourteen ? i see . phd e : yeah . so . yeah . and another thing that we did also is that we have all this training data for let 's say , for speechdat - car . we have channel zero which is clean , channel one which is far - field microphone . and if we just take only the , um , vad probabilities computed on the clean signal and apply them on the far - field , uh , test utterances , then results are much better . phd a : mm - hmm . phd e : in some cases it divides the error rate by two . so it means that there are stim { comment } still phd a : how how much latency does the , uh does our vad add ? phd e : if if we can have a good vad , well , it would be great . phd a : is it significant , phd e : uh , right now it 's , um , a neural net with nine frames . phd a : or ? phd e : so it 's forty milliseconds plus , um , the rank ordering , which , uh , should be phd c : like another ten frames . phd e : ten yeah . grad d : rank . oh . phd e : so , right now it 's one hundred and forty milliseconds . professor b : with the rank ordering ? i 'm sorry . phd c : the the the smoothing the m the the filtering of the probabilities . phd e : the the , um phd c : on the r . phd e : yeah . it 's not a median filtering . it 's just we do n't take the median value . we take something um , so we have eleven , um , frames . professor b : oh , this is for the vad . phd c : yeah . phd e : and for the vad , yeah professor b : oh , ok . phd c : yeah . phd e : and we take th the third . phd c : yeah . professor b : yeah . um . so { comment } yeah , i was just noticing on this that it makes reference to delay . so what 's the ? if you ignore um , the vad is sort of in in parallel , is n't i is n't it , with with the ? i mean , it is n't additive with the the , uh , lda and the wiener filtering , and so forth . phd c : the lda ? professor b : right ? phd c : yeah . so so what happened right now , we removed the delay of the lda . phd e : mm - hmm . professor b : yeah . phd c : so we i mean , if so if we if so which is like if we reduce the delay of va so , the f the final delay 's now ba is f determined by the delay of the vad , because the lda does n't have any delay . so if we re if we reduce the delay of the vad , i mean , it 's like effectively reducing the delay . phd a : how how much , uh , delay was there on the lda ? phd c : so the lda and the vad both had a hundred millisecond delay . so and they were in parallel , so which means you pick either one of them the the biggest , whatever . phd a : i see . professor b : mm - hmm . phd c : so , right now the lda delays are more . professor b : and there phd a : oh , ok . professor b : and there did n't seem to be any , uh , penalty for that ? there did n't seem to be any penalty for making it causal ? phd c : pardon ? oh , no . it actually made it , like , point one percent better or something , actually . professor b : ok . well , may as well , then . phd c : or something like that professor b : and he says wiener filter is is forty milliseconds delay . phd c : and professor b : so is it ? phd c : yeah . so that 's the one which stephane was discussing , like professor b : the smoothing ? phd c : yeah . the you smooth it and then delay the decision by so . professor b : right . ok . so that 's that 's really not not bad . so we may in fact we 'll see what they decide . we may in fact have , um , the the , uh , latency time available for to have a neural net . i mean , sounds like we probably will . so . phd c : mm - hmm . professor b : that 'd be good . cuz i cuz it certainly always helped us before . so . phd a : what amount of latency are you thinking about when you say that ? professor b : uh . well , they 're you know , they 're disputing it . you know , they 're saying , uh one group is saying a hundred and thirty milliseconds and another group is saying two hundred and fifty milliseconds . two hundred and fifty is what it was before actually . so , uh , some people are lobbying lobbying { comment } to make it shorter . um . and , um . phd a : were you thinking of the two - fifty or the one - thirty when you said we should have enough for the neural net ? professor b : well , it just it when we find that out it might change exactly how we do it , is all . phd a : oh , ok . professor b : i mean , how much effort do we put into making it causal ? i mean , i think the neural net will probably do better if it looks at a little bit of the future . phd a : mm - hmm . professor b : but , um , it will probably work to some extent to look only at the past . and we ha you know , limited machine and human time , and effort . and , you know , how how much time should we put into into that ? so it 'd be helpful if we find out from the the standards folks whether , you know , they 're gon na restrict that or not . phd a : mm - hmm . professor b : um . but i think , you know , at this point our major concern is making the performance better and and , um , if , uh , something has to take a little longer in latency in order to do it that 's you know , a secondary issue . phd a : mm - hmm . professor b : but if we get told otherwise then , you know , we may have to c clamp down a bit more . phd c : so , the one one one difference is that was there is like we tried computing the delta and then doing the frame - dropping . phd e : mm - hmm . phd c : the earlier system was do the frame - dropping and then compute the delta on the professor b : uh - huh . phd c : so this phd a : which could be a kind of a funny delta . right ? phd c : yeah . professor b : oh , oh . so that 's fixed in this . yeah , we talked about that . phd c : yeah . so we have no delta . and then phd e : yeah . uh - huh . professor b : good . phd c : so the frame - dropping is the last thing that we do . so , yeah , what we do is we compute the silence probability , convert it to that binary flag , professor b : uh - huh . phd c : and then in the end you c up upsample it to match the final features number of phd e : mm - hmm . phd a : did that help then ? phd c : it seems to be helping on the well - matched condition . so that 's why this improvement i got from the last result . so . and it actually r reduced a little bit on the high mismatch , so in the final weightage it 's b b better because the well - matched is still weighted more than professor b : so , @ @ i mean , you were doing a lot of changes . did you happen to notice how much , uh , the change was due to just this frame - dropping problem ? what about this ? phd c : uh , y you had something on it . right ? phd e : just the frame - dropping problem . yeah . but it 's it 's difficult . sometime we we change two two things together and but it 's around maybe it 's less than one percent . professor b : uh - huh . phd c : yeah . phd e : it professor b : well . but like we 're saying , if there 's four or five things like that then pretty sho soon you 're talking real improvement . phd e : yeah . yeah . and it yeah . and then we have to be careful with that also with the neural net professor b : yeah . phd e : because in { comment } the proposal the neural net was also , uh , working on after frame - dropping . professor b : mm - hmm . oh , that 's a real good point . phd e : so . well , we 'll have to be to do the same kind of correction . professor b : it might be hard if it 's at the server side . right ? phd e : mmm . well , we can do the frame - dropping on the server side or we can just be careful at the terminal side to send a couple of more frames before and after , and so . i think it 's ok . phd a : you have , um so when you uh , maybe i do n't quite understand how this works , but , um , could n't you just send all of the frames , but mark the ones that are supposed to be dropped ? cuz you have a bunch more bandwidth . right ? professor b : well , you could . yeah . i mean , it it always seemed to us that it would be kind of nice to in addition to , uh , reducing insertions , actually use up less bandwidth . phd a : yeah . yeah . professor b : but nobody seems to have cared about that in this evaluation . phd a : and that way the net could use if the net 's on the server side then it could use all of the frames . phd c : yes , it could be . it 's , like , you mean you just transferred everything and then finally drop the frames after the neural net . phd a : mm - hmm . phd c : right ? yeah . that 's that 's one thing which phd e : mm - hmm . phd a : but you could even mark them , before they get to the server . phd c : yeah . right now we are uh , ri right now what wha what we did is , like , we just mark we just have this additional bit which goes around the features , saying it 's currently a it 's a speech or a nonspeech . phd a : oh , ok . phd c : so there is no frame - dropping till the final features , like , including the deltas are computed . phd a : i see . phd c : and after the deltas are computed , you just pick up the ones that are marked silence and then drop them . phd a : mm - hmm . i see . i see . professor b : so it would be more or less the same thing with the neural net , i guess , actually . phd e : mm - hmm . phd c : so . yeah , that 's what that 's what that 's what , uh , this is doing right now . phd a : i see . ok . professor b : yeah . phd e : mm - hmm . professor b : um . ok . so , uh , what 's , uh ? that 's that 's a good set of work that that , uh phd c : just one more thing . like , should we do something f more for the noise estimation , because we still ? professor b : yeah . i was wondering about that . that was i i had written that down there . phd c : yeah . phd e : mm - hmm . professor b : um phd e : so , we , uh actually i did the first experiment . this is with just fifteen frames . um . we take the first fifteen frame of each utterance to it , professor b : yeah . phd e : and average their power spectra . um . i tried just plugging the , um , uh , guenter noise estimation on this system , and it uh , it got worse . um , but of course i did n't play with it . professor b : uh - huh . phd e : but mm - hmm . uh , i did n't do much more for noise estimation . i just tried this , professor b : hmm . yeah . well , it 's not surprising it 'd be worse the first time . phd e : and professor b : but , um , phd e : mm - hmm . professor b : it does seem like , you know , i i i i some compromise between always depending on the first fifteen frames and a a always depending on a a pause is is is a good idea . uh , maybe you have to weight the estimate from the first - teen fifteen frames more heavily than than was done in your first attempt . but phd e : mm - hmm . professor b : but phd e : yeah , i guess . professor b : yeah . um . no , i mean um , do you have any way of assessing how well or how poorly the noise estimation is currently doing ? phd e : mmm . no , we do n't . professor b : yeah . phd e : we do n't have nothing that phd c : is there was there any experiment with ? well , i i did the only experiment where i tried was i used the channel zero vad for the noise estimation and frame - dropping . so i do n't have a i do n't have a split , like which one helped more . phd e : yeah . phd c : so . it it was the best result i could get . phd e : mm - hmm . phd c : so , that 's the professor b : so that 's something you could do with , um , this final system . right ? just do this everything that is in this final system except , uh , use the channel zero . phd c : mm - hmm . for the noise estimation . professor b : yeah . phd c : yeah . we can try something . professor b : and then see how much better it gets . phd c : mm - hmm . sure . professor b : if it 's , you know , essentially not better , then it 's probably not worth phd e : yeah . professor b : any more . phd c : yeah . but the guenter 's argument is slightly different . it 's , like , ev even even if i use a channel zero vad , i 'm just averaging the the s power spectrum . but the guenter 's argument is , like , if it is a non - stationary segment , then he does n't update the noise spectrum . so he 's , like he tries to capture only the stationary part in it . so the averaging is , like , different from updating the noise spectrum only during stationary segments . so , th the guenter was arguing that , i mean , even if you have a very good vad , averaging it , like , over the whole thing is not a good idea . professor b : i see . phd c : because you 're averaging the stationary and the non - stationary , and finally you end up getting something which is not really the s because , you anyway , you ca n't remove the stationary part fr i mean , non - stationary part from the signal . professor b : not using these methods anyway . yeah . phd c : so yeah . so you just update only doing or update only the stationary components . yeah . so , that 's so that 's still a slight difference from what guenter is trying professor b : well , yeah . and and also there 's just the fact that , um , eh , uh , although we 're trying to do very well on this evaluation , um , we actually would like to have something that worked well in general . and , um , relying on having fifteen frames at the front or something is is pretty phd c : yeah , yeah . professor b : i mean , you might , you might not . phd e : mm - hmm . professor b : so , um . um , it 'd certainly be more robust to different kinds of input if you had at least some updates . um . phd e : mm - hmm . professor b : but , um . well , i do n't know . what what do you , uh what do you guys see as as being what you would be doing in the next week , given wha what 's happened ? phd c : cure the vad ? phd e : yeah . phd a : what was that ? phd c : and phd e : so , should we keep the same ? i think we might try to keep the same idea of having a neural network , but training it on more data and adding better features , i think , but because the current network is just plp features . well , it 's trained on noisy plp phd c : just the cepstra . yeah . phd e : plp features computed on noisy speech . but there is no nothing particularly robust in these features . phd a : so , i i uh phd e : there 's no rasta , no phd a : so , uh , i i do n't remember what you said the answer to my , uh , question earlier . will you will you train the net on after you 've done the spectral subtraction or the wiener filtering ? professor b : this is a different net . phd c : so we have a vad which is like neur that 's a neural net . phd e : oh , yeah . hmm . phd a : oh , you 're talking about the vad net . ok . phd c : yeah . phd e : mm - hmm . phd a : i see . phd c : so that that vad was trained on the noisy features . phd a : mm - hmm . phd c : so , right now we have , like , uh we have the cleaned - up features , so we can have a better vad by training the net on the cleaned - up speech . phd a : mm - hmm . i see . i see . phd c : yeah , but we need a vad for uh noise estimation also . so it 's , like , where do we want to put the vad ? uh , it 's like phd a : can you use the same net to do both , or ? phd c : for phd a : can you use the same net that you that i was talking about to do the vad ? phd c : mm - hmm . uh , it actually comes at v at the very end . phd a : mm - hmm . phd c : so the net the final net i mean , which is the feature net so that actually comes after a chain of , like , lda plus everything . so it 's , like , it takes a long time to get a decision out of it . and and you can actually do it for final frame - dropping , but not for the va - f noise estimation . phd a : mm - hmm . professor b : you see , the idea is that the , um , initial decision to that that you 're in silence or speech happens pretty quickly . phd a : oh , ok . cuz that 's used by some of these other ? professor b : and that yeah . and that 's sort of fed forward , and and you say `` well , flush everything , it 's not speech anymore `` . phd a : oh , ok . i see . phd c : yeah . phd a : i thought that was only used for doing frame - dropping later on . professor b : um , it is used , uh yeah , it 's only used f well , it 's used for frame - dropping . um , it 's used for end of utterance because , you know , there 's if you have more than five hundred milliseconds of of of nonspeech then you figure it 's end of utterance or something like that . phd a : mm - hmm . professor b : so , um . phd e : and it seems important for , like , the on - line normalization . um . we do n't want to update the mean and variance during silen long silence portions . um . so it it has to be done before phd a : oh . i see . phd e : this mean and variance normalization . um . professor b : um . yeah . so probably the vad and and maybe testing out the noise estimation a little bit . i mean , keeping the same method but but , uh , seeing if you cou but , um noise estimation could be improved . those are sort of related issues . phd e : mm - hmm . professor b : it probably makes sense to move from there . and then , uh , later on in the month i think we wan na start including the neural net at the end . um . ok . anything else ? phd e : the half dome was great . professor b : good . yeah . you did n't did n't fall . that 's good . phd c : well , yeah . professor b : our e our effort would have been devastated if you guys had { comment } run into problems . phd a : so , hynek is coming back next week , you said ? professor b : yeah , that 's the plan . i guess the week after he 'll be , uh , going back to europe , and so we wan na phd a : is he in europe right now or is he up at ? professor b : no , no . he 's he 's he 's dropped into the us . yeah . yeah . phd a : oh . hmm . professor b : so . uh . so , uh . uh , the idea was that , uh , we 'd we 'd sort out where we were going next with this with this work before he , uh , left on this next trip . good . uh , barry , you just got through your quals , so i do n't know if you have much to say . but , uh . grad d : mmm . no , just , uh , looking into some some of the things that , um , uh , john ohala and hynek , um , gave as feedback , um , as as a starting point for the project . um . in in my proposal , i i was thinking about starting from a set of , uh , phonological features , or a subset of them . um , but that might not be necessarily a good idea according to , um , john . phd a : mm - hmm . grad d : he said , uh , um , these these phonological features are are sort of figments of imagination also . phd a : mm - hmm . grad d : um . s professor b : in conversational speech in particular . i think you can you can put them in pretty reliably in synthetic speech . but we do n't have too much trouble recognizing synthetic speech since we create it in the first place . so , it 's grad d : right . yeah . so , um , a better way would be something more more data - driven , phd a : mm - hmm . grad d : just looking at the data and seeing what 's similar and what 's not similar . phd a : mm - hmm . grad d : so , i 'm i 'm , um , taking a look at some of , um , sangita 's work on on traps . she did something where , um w where the traps learn she clustered the the temporal patterns of , um , certain certain phonemes in in m averaged over many , many contexts . and , uh , some things tended to cluster . phd a : mm - hmm . grad d : right ? you know , like stop stop consonants clustered really well . um , silence was by its own self . phd a : mm - hmm . grad d : and , uh , um , v vocalic was clustered . phd a : mm - hmm . grad d : and , um , so , those are interesting things to phd a : so you 're now you 're sort of looking to try to gather a set of these types of features ? grad d : right . phd a : mm - hmm . grad d : yeah . just to see where where i could start off from , phd a : mm - hmm . grad d : uh , you know ? a a a set of small features and continue to iterate and find , uh , a better set . phd a : mm - hmm . grad d : yeah . professor b : ok . well , short meeting . that 's ok . phd a : yeah . professor b : ok . so next week hopefully we 'll can get hynek here to to join us and , uh , uh . phd a : should we do digits ? professor b : digits , digits . ok , now . phd a : go ahead , morgan . you can start . professor b : alright . let me get my glasses on so i can see them . ok ."
}