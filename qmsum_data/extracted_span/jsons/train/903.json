{
    "query": "<s> what did phd e think about improving the model ?",
    "answer": "phd e : just the frame - dropping problem . yeah . but it 's it 's difficult . sometime we we change two two things together and but it 's around maybe it 's less than one percent . professor b : uh - huh . phd c : yeah . phd e : it professor b : well . but like we 're saying , if there 's four or five things like that then pretty sho soon you 're talking real improvement . phd e : yeah . yeah . and it yeah . and then we have to be careful with that also with the neural net professor b : yeah . phd e : because in { comment } the proposal the neural net was also , uh , working on after frame - dropping . professor b : mm - hmm . oh , that 's a real good point . phd e : so . well , we 'll have to be to do the same kind of correction . professor b : it might be hard if it 's at the server side . right ? phd e : mmm . well , we can do the frame - dropping on the server side or we can just be careful at the terminal side to send a couple of more frames before and after , and so . i think it 's ok . phd a : you have , um so when you uh , maybe i do n't quite understand how this works , but , um , could n't you just send all of the frames , but mark the ones that are supposed to be dropped ? cuz you have a bunch more bandwidth . right ? professor b : well , you could . yeah . i mean , it it always seemed to us that it would be kind of nice to in addition to , uh , reducing insertions , actually use up less bandwidth . phd a : yeah . yeah . professor b : but nobody seems to have cared about that in this evaluation . phd a : and that way the net could use if the net 's on the server side then it could use all of the frames . phd c : yes , it could be . it 's , like , you mean you just transferred everything and then finally drop the frames after the neural net . phd a : mm - hmm . phd c : right ? yeah . that 's that 's one thing which phd e : mm - hmm . phd a : but you could even mark them , before they get to the server . phd c : yeah . right now we are uh , ri right now what wha what we did is , like , we just mark we just have this additional bit which goes around the features , saying it 's currently a it 's a speech or a nonspeech . phd a : oh , ok . phd c : so there is no frame - dropping till the final features , like , including the deltas are computed . phd a : i see . phd c : and after the deltas are computed , you just pick up the ones that are marked silence and then drop them . phd a : mm - hmm . i see . i see . professor b : so it would be more or less the same thing with the neural net , i guess , actually . phd e : mm - hmm . phd c : so . yeah , that 's what that 's what that 's what , uh , this is doing right now . phd a : i see . ok . professor b : yeah . phd e : mm - hmm . professor b : um . ok . so , uh , what 's , uh ? that 's that 's a good set of work that that , uh phd c : just one more thing . like , should we do something f more for the noise estimation , because we still ? professor b : yeah . i was wondering about that . that was i i had written that down there . phd c : yeah . phd e : mm - hmm . professor b : um phd e : so , we , uh actually i did the first experiment . this is with just fifteen frames . um . we take the first fifteen frame of each utterance to it , professor b : yeah . phd e : and average their power spectra . um . i tried just plugging the , um , uh , guenter noise estimation on this system , and it uh , it got worse . um , but of course i did n't play with it . professor b : uh - huh ."
}