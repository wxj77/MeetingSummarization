{
    "query": "<s> what was the structure of the bayes-net discussed .",
    "answer": "grad b : what do you mean by `` differently weighted `` ? they do n't feed into anything really anymore . grad a : but i mean , why do we grad c : or i jus grad a : if we trusted the go - there node more th much more than we trusted the other ones , then we would conclude , even in this situation , that he wanted to go there . so , in that sense , we weight them equally right now . grad b : ok . makes sense . yeah . but grad c : so the but i guess the k the question that i was as er wondering or maybe robert was proposing to me is how do we d make the decision on as to which one to listen to ? grad a : yeah , so , the final d decision is the combination of these three . so again , it 's it 's some kind of , uh grad c : bayes - net . grad a : yeah , sure . grad c : ok so , then , the question i so then my question is t to you then , would be so is the only r reason we can make all these smaller bayes - nets , because we know we can only deal with a finite set of constructions ? cuz oth if we 're just taking arbitrary language in , we could n't have a node for every possible question , you know ? grad a : a decision node for every possible question , you mean ? grad c : well , i like , in the case of yeah . in the ca any piece of language , we would n't be able to answer it with this system , b if we just h cuz we would n't have the correct node . basically , w what you 're s proposing is a n where - is node , right ? grad a : yeah . grad c : and and if we and if someone says , you know , uh , something in mandarin to the system , we 'd - would n't know which node to look at to answer that question , grad a : so is yeah . yeah . grad c : right ? so , but but if we have a finite what ? grad b : i do n't see your point . what what what i am thinking , or what we 're about to propose here is we 're always gon na get the whole list of values and their posterior probabilities . and now we need an expert system or belief - net or something that interprets that , that looks at all the values and says , `` the winner is timing . now , go there . `` `` uh , go there , timing , now . `` or , `` the winner is info - on , function - off . `` so , he wants to know something about it , and what it does . nuh ? uh , regardless of of of the input . wh - regardle grad c : yeah , but but how does the expert but how does the expert system know how who which one to declare the winner , if it does n't know the question it is , and how that question should be answered ? grad b : based on the k what the question was , so what the discourse , the ontology , the situation and the user model gave us , we came up with these values for these decisions . grad c : yeah i know . but how do we weight what we get out ? as , which one i which ones are important ? so my i so , if we were to it with a bayes - net , we 'd have to have a node for every question that we knew how to deal with , that would take all of the inputs and weight them appropriately for that question . grad b : mm - hmm . grad c : does that make sense ? yay , nay ? grad a : um , i mean , are you saying that , what happens if you try to scale this up to the situation , or are we just dealing with arbitrary language ? grad c : we grad a : is that your point ? grad c : well , no . i i guess my question is , is the reason that we can make a node f or ok . so , lem me see if i 'm confused . are we going to make a node for every question ? does that make sense ? grad a : for every question ? grad c : or not . grad a : like grad c : every construction . grad a : hmm . i do n't not necessarily , i would think . i mean , it 's not based on constructions , it 's based on things like , uh , there 's gon na be a node for go - there or not , and there 's gon na be a node for enter , view , approach . grad c : wel w ok . so , someone asked a question . grad a : yeah . grad c : how do we decide how to answer it ? grad b : well , look at look face yourself with this pr question . you get this you 'll have y this is what you get . and now you have to make a decision . what do we think ? what does this tell us ? and not knowing what was asked , and what happened , and whether the person was a tourist or a local , because all of these factors have presumably already gone into making these posterior probabilities . what what we need is a just a mechanism that says , `` aha ! there is `` grad c : yeah . i just do n't think a `` winner - take - all `` type of thing is the grad a : i mean , in general , like , we wo n't just have those three , right ? we 'll have , uh , like , many , many nodes . so we have to , like so that it 's no longer possible to just look at the nodes themselves and figure out what the person is trying to say . grad b : yep . because there are interdependencies , right ? the uh uh , no . so if if for example , the go - there posterior possibility is so high , um , uh , w if it 's if it has reached reached a certain height , then all of this becomes irrelevant . so . if even if if the function or the history or something is scoring pretty good on the true node , true value grad c : wel i do n't know about that , cuz that would suggest that i mean grad b : he wants to go there and know something about it ? grad c : do they have to be mutual yeah . do they have to be mutually exclusive ? grad b : i think to some extent they are . or maybe they 're not . grad c : cuz i , uh the way you describe what they meant , they were n't mutu uh , they did n't seem mutually exclusive to me . grad b : well , if he does n't want to go there , even if the enter posterior proba so . go - there is no . enter is high , and info - on is high . grad c : well , yeah , just out of the other three , though , that you had in the those three nodes . the - d they did n't seem like they were mutually exclusive . grad b : no , there 's no . but it 's through the grad c : so th s so , yeah , but some so , some things would drop out , and some things would still be important . grad b : mm - hmm . grad c : but i guess what 's confusing me is , if we have a bayes - net to deal w another bayes - net to deal with this stuff , grad a : mm - hmm . grad c : you know , uh , is the only reason ok , so , i guess , if we have a ba - another bayes - net to deal with this stuff , the only r reason we can design it is cuz we know what each question is asking ? grad a : yeah . i think that 's true . grad c : and then , so , the only reason way we would know what question he 's asking is based upon oh , so if let 's say i had a construction parser , and i plug this in , i would know what each construction the communicative intent of the construction was grad a : mm - hmm . grad c : and so then i would know how to weight the nodes appropriately , in response . so no matter what they said , if i could map it onto a where - is construction , i could say , `` ah ! grad a : ge mm - hmm . grad c : well the the intent , here , was where - is `` ,"
}