{
    "query": "<s> summarize the discussion about fir filters and dealing with additive noise",
    "answer": "phd a : ok , we 're on . professor c : ok , what are we talking about today ? phd b : i do n't know . do you have news from the conference talk ? uh , that was programmed for yesterday i guess . professor c : uh phd d : yesterday professor c : uh phd d : yesterday morning on video conference . professor c : oh , i 'm sorry . grad e : oh . conference call . professor c : i know now i know what you 're talking about . no , nobody 's told me anything . phd b : alright . phd a : oh , this was the , uh , talk where they were supposed to try to decide phd b : to to decide what to do , phd a : ah , right . phd b : yeah . phd d : yeah . professor c : yeah . no , that would have been a good thing to find out before this meeting , that 's . no , i have no i have no idea . um , uh , so i mean , let 's let 's assume for right now that we 're just kind of plugging on ahead , phd b : yeah . professor c : because even if they tell us that , uh , the rules are different , uh , we 're still interested in doing what we 're doing . so what are you doing ? phd b : mm - hmm . uh , well , we 've a little bit worked on trying to see , uh , what were the bugs and the problem with the latencies . phd d : to improve phd b : so , we took first we took the lda filters and , uh , we designed new filters , using uh recursive filters actually . professor c : so when you say `` we `` , is that something sunil is doing or is that ? phd b : i 'm sorry ? professor c : who is doing that ? phd b : uh , us . yeah . professor c : oh , oh . oh , ok . phd b : so we took the filters the fir filters and we { comment } designed , uh , iir filters that have the same frequency response . phd d : but professor c : mm - hmm . phd b : well , similar , but that have shorter delays . professor c : mm - hmm . phd b : so they had two filters , one for the low frequency bands and another for the high frequency bands . and so we redesigned two filters . and the low frequency band has sixty - four milliseconds of delay , and the high frequency band filter has something like eleven milliseconds compared to the two hundred milliseconds of the iir filters . but it 's not yet test . so we have the filters but we still have to implement a routine that does recursive filtering and professor c : you you had a discussion with sunil about this though ? phd b : no . no . professor c : uh - huh . yeah , you should talk with him . phd b : yeah , yeah . professor c : yeah . no , i mean , because the the the the whole problem that happened before was coordination , phd b : mm - hmm . professor c : right ? so so you need to discuss with him what we 're doing , phd b : yeah . professor c : uh , cuz they could be doing the same thing and or something . phd b : mm - hmm . uh , i yeah , i do n't know if th that 's what they were trying to they were trying to do something different like taking , uh well , using filter that takes only a past professor c : right . phd b : and this is just a little bit different . but i will i will send him an email and tell him exactly what we are doing , so . professor c : yeah , yeah . um , i mean we just we just have to be in contact more . i think that the the fact that we we did that with had that thing with the latencies was indicative of the fact that there was n't enough communication . phd b : mm - hmm . alright . um , yeah . well , there is w one , um , remark about these filters , that they do n't have a linear phase . so , professor c : right . phd b : well , i do n't know , perhaps it perhaps it does n't hurt because the phase is almost linear but . um , and so , yeah , for the delay i gave you here , it 's it 's , uh , computed on the five hertz modulation frequency , which is the mmm , well , the most important for speech so . uh , this is the first thing . professor c : so that would be , uh , a reduction of a hundred and thirty - six milliseconds , phd d : the low f f phd b : yeah . professor c : which , uh what was the total we ended up with through the whole system ? phd b : three hundred and thirty . professor c : so that would be within ? phd b : yeah , but there are other points actually , uh , which will perhaps add some more delay . is that some other other stuff in the process were perhaps not very um perf well , not very correct , like the downsampling which w was simply dropping frames . professor c : yeah . phd b : um , so we will try also to add a nice downsampling having a filter that that professor c : uh - huh . phd b : well , a low - pass filter at at twenty - five hertz . uh , because wh when when we look at the lda filters , well , they are basically low - pass but they leave a lot of what 's above twenty - five hertz . professor c : yeah . phd b : um , and so , yeah , this will be another filter which would add ten milliseconds again . professor c : yeah . phd b : um , yeah , and then there 's a third thing , is that , um , basically the way on - line normalization was done uh , is just using this recursion on on the um , um , on the feature stream , professor c : yeah . phd b : and but this is a filter , so it has also a delay . uh , and when we look at this filter actually it has a delay of eighty - five milliseconds . so if we professor c : eighty - five . phd b : yeah . if we want to be very correct , so if we want to the estimation of the mean t t to to be well , the right estimation of the mean , we have to t to take eighty - five milliseconds in the future . mmm . professor c : hmm ! that 's a little bit of a problem . phd b : yeah . um , but , well , when we add up everything it 's it will be alright . we would be at six so , sixty - five , plus ten , plus for the downsampling , plus eighty - five for the on - line normalization . so it 's plus plus eighty for the neural net and pca . professor c : yeah , but then there 's oh . phd b : so it would be around two hundred and forty so , well , professor c : just just barely in there . phd b : plus plus the frames , but it 's ok . phd a : what 's the allowable ? professor c : two - fifty , unless they changed the rules . which there is there 's some discussion of . phd a : what were they thinking of changing it to ? professor c : but phd b : yeah . professor c : uh , well the people who had very low latency want it to be low uh , very very very narrow , uh , latency bound . and the people who have longer latency do n't . so . phd b : so , yeah . professor c : unfortunately we 're the main ones with long latency , but but , uh , phd b : yeah , and basically the best proposal had something like thirty or forty milliseconds of latency . professor c : you know , it 's yeah . phd b : so . well . professor c : yeah , so they were basically i mean , they were more or less trading computation for performance and we were , uh , trading latency for performance . and they were dealing with noise explicitly and we were n't , and so i think of it as complementary , that if we can put the phd a : think of it as what ? professor c : complementary . i think the best systems so , uh , everything that we did in in a way it was it was just adamantly insisting on going in with a brain damaged system , which is something actually , we 've done a lot over the last thirteen years . uh , which is we say , well this is the way we should do it . and then we do it . and then someone else does something that 's straight forward . so , w th w this was a test that largely had additive noise and we did we adde did absolutely nothing explicitly to handle ad additive noise . phd a : right . professor c : we just , uh , you know , trained up systems to be more discriminant . and , uh , we did this , uh , rasta - like filtering which was done in the log domain and was tending to handle convolutional noise . we did we actually did nothing about additive noise . so , um , the , uh , spectral sub subtraction schemes a couple places did seem to seem to do a nice job . and so , uh , we 're talking about putting putting some of that in while still keeping some of our stuff . i think you should be able to end up with a system that 's better than both but clearly the way that we 're operating for this other stuff does involved some latency to to get rid of most of that latency . to get down to forty or fifty milliseconds we 'd have to throw out most of what we 're doing . and and , uh , i do n't think there 's any good reason for it in the application actually . i mean , you 're you 're you 're speaking to a recognizer on a remote server and , uh , having a a a quarter second for some processing to clean it up . it does n't seem like it 's that big a deal . phd a : mm - hmm . professor c : these are n't large vocabulary things so the decoder should n't take a really long time , and . phd a : and i do n't think anybody 's gon na notice the difference between a quarter of a second of latency and thirty milliseconds of latency . professor c : so . no . what what does wa was your experience when you were doing this stuff with , uh , the the the surgical , uh , uh , microscopes and so forth . um , how long was it from when somebody , uh , finished an utterance to when , uh , something started happening ? phd a : um , we had a silence detector , so we would look for the end of an utterance based on the silence detector . professor c : mm - hmm . phd a : and i i ca n't remember now off the top of my head how many frames of silence we had to detect before we would declare it to be the end of an utterance . professor c : mm - hmm . mm - hmm . phd a : um , but it was , uh , i would say it was probably around the order of two hundred and fifty milliseconds . professor c : yeah , and that 's when you 'd start doing things . phd a : yeah , we did the back trace at that point to get the answer . professor c : yeah . of course that did n't take too long at that point . phd a : no , no it was pretty quick . professor c : yeah . phd a : so professor c : yeah , so you you so you had a phd a : this w professor c : so you had a a quarter second delay before , uh , plus some little processing time , phd a : right . professor c : and then the the microscope would start moving or something . phd a : right . professor c : yeah . phd a : right . professor c : and there 's physical inertia there , so probably the the motion itself was all phd a : and it felt to , uh , the users that it was instantaneous . i mean , as fast as talking to a person . it th i do n't think anybody ever complained about the delay . professor c : yeah , so you would think as long as it 's under half a second or something . phd a : yeah . professor c : uh , i 'm not an expert on that phd a : yeah . i do n't remember the exact numbers but it was something like that . professor c : yeah . phd a : i do n't think you can really tell . a person i do n't think a person can tell the difference between , uh , you know , a quarter of a second and a hundred milliseconds , and i 'm not even sure if we can tell the difference between a quarter of a second and half a second . professor c : yeah . phd a : i mean it just it feels so quick . professor c : yeah . i mean , basically if you yeah , if you said , uh , um , `` what 's the , uh , uh what 's the shortest route to the opera ? `` and it took half a second to get back to you , phd a : yeah . professor c : i mean , it would be f i mean , it might even be too abrupt . you might have to put in a s a s a delay . phd a : yeah . i mean , it may feel different than talking to a person professor c : yeah . phd a : because when we talk to each other we tend to step on each other 's utterances . so like if i 'm asking you a question , you may start answering before i 'm even done . professor c : yeah . phd a : so it it would probably feel different professor c : right . phd a : but i do n't think it would feel slow . professor c : right . well , anyway , i mean , i think we could cut we know what else , we could cut down on the neural net time by by , uh , playing around a little bit , going more into the past , or something like that . we t we talked about that . phd a : so is the latency from the neural net caused by how far ahead you 're looking ? professor c : mm - hmm . phd b : mm - hmm . professor c : and there 's also well , there 's the neural net and there 's also this , uh , uh , multi - frame , uh , uh , klt . phd a : was n't there was it in the , uh , recurrent neural nets where they were n't looking ahead at all ? professor c : they were n't looking ahead much . they p they looked ahead a little bit . phd a : a little bit . ok . professor c : yeah . yeah , i mean , you could do this with a recurrent net . and and then but you also could just , um , i mean , we have n't experimented with this but i imagine you could , um , uh , predict a , uh um , a label , uh , from more in the past than in than than in the future . i mean , we 've d we 've done some stuff with that before . i think it it works ok . phd b : mm - hmm . phd a : we 've always had usually we used the symmetric windows but i do n't think professor c : yeah , but we 've but we played a little bit with with asymmetric , guys . phd a : yeah . professor c : you can do it . so . so , that 's what that 's what you 're busy with , s messing around with this , phd b : uh , yeah ."
}