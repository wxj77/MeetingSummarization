{
    "query": "<s> summarize the meeting",
    "answer": "professor a : we 're going ? ok . sh - close your door on door on the way out ? grad b : ok . thanks . professor a : thanks . yeah . probably wan na get this other door , too . ok . so . um . what are we talking about today ? phd e : uh , well , first there are perhaps these uh meeting recorder digits that we tested . professor a : oh , yeah . that was kind of uh interesting . the both the uh the sri system and the oth and for one thing that that sure shows the difference between having a lot of uh training data or not , phd e : of data ? yeah . professor a : uh , the uh the best kind of number we have on the english uh on near microphone only is is uh three or four percent . phd e : mm - hmm . professor a : and uh it 's significantly better than that , using fairly simple front - ends on on the uh uh , with the sri system . phd e : mm - hmm . professor a : so i th i think that the uh but that 's that 's using uh a a pretty huge amount of data , mostly not digits , of course , but but then again well , yeah . in fact , mostly not digits for the actual training the h m ms whereas uh in this case we 're just using digits for training the h m phd e : yeah . right . professor a : did anybody mention about whether the the sri system is a is is doing the digits um the wor as a word model or as uh a sub s sub - phone states ? phd e : i guess it 's it 's uh allophone models , professor a : yeah . probably . phd e : so , well yeah . i think so , because it 's their very d huge , their huge system . professor a : yeah . phd e : and . but . so . there is one difference well , the sri system the result for the sri system that are represented here are with adaptation . so there is it 's their complete system and including on - line uh unsupervised adaptation . professor a : that 's true . phd e : and if you do n't use adaptation , the error rate is around fifty percent worse , i think , if i remember . yeah . professor a : it 's tha it 's that much , huh ? phd e : nnn . it 's yeah . it 's quite significant . professor a : oh . ok . phd e : yeah . professor a : still . phd e : mm - hmm . professor a : but but uh what what i think i 'd be interested to do given that , is that we we should uh take i guess that somebody 's gon na do this , right ? is to take some of these tandem things and feed it into the sri system , right ? phd e : yeah . professor a : yeah . phd e : we can do something like that . professor a : yeah . because phd e : yeah . but but i guess the main point is the data because uh i am not sure . our back - end is is fairly simple but until now , well , the attempts to improve it or have fail ah , well , i mean uh what chuck tried to to to do professor a : yeah , but he 's doing it with the same data , right ? i mean so to so there 's there 's there 's two things being affected . phd e : yeah . so it 's yeah . professor a : i mean . one is that that , you know , there 's something simple that 's wrong with the back - end . we 've been playing a number of states phd e : mm - hmm . professor a : uh i i do n't know if he got to the point of playing with the uh number of gaussians yet phd e : mm - hmm . professor a : but but uh , uh , you know . but , yeah , so far he had n't gotten any big improvement , phd e : mm - hmm . professor a : but that 's all with the same amount of data which is pretty small . phd e : yeah . professor a : and um . phd e : mmm . so , yeah , we could retrain some of these tandem on on huge professor a : well , you could do that , but i 'm saying even with it not with that part not retrained , just just using having the h m ms much better h m phd e : ah , yeah . just f for the hmm models . professor a : yeah . phd e : yeah . mm - hmm . mm - hmm . professor a : um . but just train those h m ms using different features , the features coming from our aurora stuff . phd e : yeah . yeah . but what would be interesting to see also is what what perhaps it 's not related , the amount of data but the um recording conditions . i do n't know . because it 's probably not a problem of noise , because our features are supposed to be robust to noise . professor a : well , yeah . phd e : it 's not a problem of channel , because there is um normalization with respect to the channel . so professor a : i i i 'm sorry . what what is the problem that you 're trying to explain ? phd e : the the fact that the result with the tandem and aurora system are uh so much worse . professor a : that the oh . so much worse ? oh . phd e : yeah . professor a : i uh but i 'm i 'm almost certain that it it i mean , that it has to do with the um amount of training data . phd e : it professor a : it it 's it 's orders of magnitude off . phd e : yeah but yeah . yeah but we train only on digits and it 's it 's a digit task , so . well . professor a : but but having a huge if if you look at what commercial places do , they use a huge amount of data . phd e : it mm - hmm . professor a : this is a modest amount of data . phd e : alright . yeah . professor a : so . i mean , ordinarily you would say `` well , given that you have enough occurrences of the digits , you can just train with digits rather than with , you know `` phd e : mm - hmm . mm - hmm . professor a : but the thing is , if you have a huge in other words , do word models but if you have a huge amount of data then you 're going to have many occurrences of similar uh allophones . phd e : right . mmm . professor a : and that 's just a huge amount of training for it . phd e : yeah . professor a : so it 's um i i think it has to be that , because , as you say , this is , you know , this is near - microphone , phd e : mm - hmm . professor a : it 's really pretty clean data . phd e : mm - hmm . professor a : um . now , some of it could be the fact that uh let 's see , in the in these multi - train things did we include noisy data in the training ? phd e : yeah . professor a : i mean , that could be hurting us actually , for the clean case . phd e : yeah . well , actually we see that the clean train for the aurora proposals are are better than the multi - train , professor a : it is if yeah . phd e : yeah . professor a : yeah . cuz this is clean data , and so that 's not too surprising . phd e : mm - hmm . professor a : but um . uh . so . phd e : well , o i guess what i meant is that well , let 's say if we if we add enough data to train on the um on the meeting recorder digits , i guess we could have better results than this . professor a : uh - huh . mm - hmm . phd e : and . what i meant is that perhaps we can learn something uh from this , what 's what 's wrong uh what what is different between ti - digits and these digits and professor a : what kind of numbers are we getting on ti - digits ? phd e : it 's point eight percent , so . professor a : oh . i see . phd e : four - fourier . professor a : so in the actual ti - digits database we 're getting point eight percent , phd e : yeah . yeah . professor a : and here we 're getting three or four three , let 's see , three for this ? phd e : mm - hmm . professor a : yeah . sure , but i mean , um point eight percent is something like double uh or triple what people have gotten who 've worked very hard at doing that . phd e : mm - hmm . professor a : and and also , as you point out , there 's adaptation in these numbers also . so if you , you know , put the ad adap take the adaptation off , then it for the english - near you get something like two percent . and here you had , you know , something like three point four . and i could easily see that difference coming from this huge amount of data that it was trained on . phd e : mm - hmm . professor a : so it 's phd e : mm - hmm . professor a : you know , i do n't think there 's anything magical here . phd e : yeah . professor a : it 's , you know , we used a simple htk system with a modest amount of data . and this is a a , you know , modern uh system uh has has a lot of nice points to it . phd e : yeah . mm - hmm . professor a : um . so . i mean , the htk is an older htk , even . so . yeah it it 's not that surprising . phd e : mm - hmm . professor a : but to me it just it just meant a practical point that um if we want to publish results on digits that that people pay attention to we probably should uh cuz we 've had the problem before that you get show some nice improvement on something that 's that 's uh , uh it seems like too large a number , and uh uh people do n't necessarily take it so seriously . phd e : mm - hmm . professor a : um . yeah . yeah . so the three point four percent for this uh is is uh so why is it it 's an interesting question though , still . why is why is it three point four percent for the d the digits recorded in this environment as opposed to the uh point eight percent for for for the original ti - digits database ? um . phd e : yeah . th that 's th that 's my point professor a : given given the same yeah . so ignore ignoring the the the sri system for a moment , phd e : i i i do n't i mm - hmm . professor a : just looking at the ti - di the uh tandem system , if we 're getting point eight percent , which , yes , it 's high . it 's , you know , it it 's not awfully high , phd e : mm - hmm . professor a : but it 's , you know it 's it 's high . um . why is it uh four times as high , or more ? phd e : yeah , i guess . professor a : right ? i mean , there 's even though it 's close - miked there 's still there really is background noise . phd e : mm - hmm . professor a : um . and uh i suspect when the ti - digits were recorded if somebody fumbled or said something wrong or something that they probably made them take it over . phd e : mm - hmm . professor a : it was not i mean there was no attempt to have it be realistic in any in any sense at all . phd e : well . yeah . and acoustically , it 's q it 's i listened . it 's quite different . ti - digit is it 's very , very clean and it 's like studio recording professor a : mm - hmm . phd e : whereas these meeting recorder digits sometimes you have breath noise and mmm . professor a : right . yeah . so i think they were phd e : it 's not controlled at all , i mean . professor a : bless you . grad b : thanks . professor a : i yeah . i think it 's it 's so . yes . phd e : mm - hmm . but professor a : it 's i think it 's it 's the indication it 's harder . phd e : yeah . professor a : uh . yeah and again , you know , i that 's true either way . i mean so take a look at the uh um , the sri results . i mean , they 're much much better , but still you 're getting something like one point three percent for uh things that are same data as in t ti - digits the same same text . phd e : mm - hmm . professor a : uh . and uh , i 'm sure the same same system would would get , you know , point point three or point four or something on the actual ti - digits . so this i think , on both systems the these digits are showing up as harder . phd e : mm - hmm . professor a : which i find sort of interesting cause i think this is closer to uh i mean it 's still read . but i still think it 's much closer to to what what people actually face , um when they 're they 're dealing with people saying digits over the telephone . i mean . i do n't think uh i mean , i 'm sure they would n't release the numbers , but i do n't think that uh the uh the the companies that that do telephone speech get anything like point four percent on their digits . i 'm i 'm i 'm sure they get uh , i mean , for one thing people do phone up who do n't have uh uh middle america accents and it 's a we we it 's it 's it 's us . phd e : mm - hmm . professor a : it has has many people who sound in many different ways . so . um . i mean . ok . that was that topic . what else we got ? did we end up giving up on on , any eurospeech submissions , phd e : but professor a : or ? i know thilo and dan ellis are are submitting something , but uh . phd e : yeah . i i guess e the only thing with these the meeting recorder and , well , so , i think , yeah i think we basically gave up . professor a : um . now , actually for the for the aur - uh phd e : but professor a : we do have stuff for aurora , right ? because because we have ano an extra month or something . phd e : yeah . yeah . yeah . so . yeah , for sure we will do something for the special session . professor a : yeah . well , that 's fine . so th so so we have a couple a couple little things on meeting recorder phd e : yeah . mm - hmm . professor a : and we have we do n't we do n't have to flood it with papers . we 're not trying to prove anything to anybody . so . that 's fine . um . anything else ? phd e : yeah . well . so . perhaps the point is that we 've been working on is , yeah , we have put the um the good vad in the system and it really makes a huge difference . um . so , yeah . i think , yeah , this is perhaps one of the reason why our system was not not the best , because with the new vad , it 's very the results are similar to the france telecom results and perhaps even better sometimes . um . so there is this point . uh . the problem is that it 's very big and we still have to think how to where to put it and um , professor a : mm - hmm . phd e : because it it well , this vad uh either some delay and we if we put it on the server side , it does n't work , because on the server side features you already have lda applied from the f from the terminal side and so you accumulate the delay so the vad should be before the lda which means perhaps on the terminal side and then smaller and professor a : so wha where did this good vad come from ? phd e : so . it 's um from ogi . so it 's the network trained it 's the network with the huge amounts on hidden of hidden units , and um nine input frames compared to the vad that was in the proposal which has a very small amount of hidden units and fewer inputs . professor a : this is the one they had originally ? phd e : yeah . professor a : oh . yeah , but they had to get rid of it because of the space , did n't they ? phd e : yeah . so . yeah . but the abso assumption is that we will be able to make a vad that 's small and that works fine . and . so we can professor a : well . so that 's a problem . yeah . phd e : yeah but nnn . professor a : but the other thing is uh to use a different vad entirely . i mean , uh i if if there 's a if if i i do n't know what the thinking was amongst the the the the etsi folk but um if everybody agreed sure let 's use this vad and take that out of there phd e : mm - hmm . mm - hmm . they just want , apparently they do n't want to fix the vad because they think there is some interaction between feature extraction and and vad or frame dropping but they still want to just to give some um requirement for this vad because it 's it will not be part of they do n't want it to be part of the standard . so . so it must be at least uh somewhat fixed but not completely . so there just will be some requirements that are still not uh not yet uh ready i think . professor a : determined . i see . but i was thinking that that uh s `` sure , there may be some interaction , but i do n't think we need to be stuck on using our or ogi 's vad . we could use somebody else 's if it 's smaller or phd e : yeah . professor a : you know , as long as it did the job . phd e : mm - hmm . professor a : so that 's good . phd e : uh . so there is this thing . there is um yeah . uh i designed a new a new filter because when i designed other filters with shorter delay from the lda filters , there was one filter with fif sixty millisecond delay and the other with ten milliseconds professor a : right . phd e : and uh hynek suggested that both could have sixty - five sixty - s i think it 's sixty - five . professor a : yeah . phd e : yeah . both should have sixty - five because professor a : you did n't gain anything , right ? phd e : yeah . and . so i did that and uh it 's running . so , let 's see what will happen . uh but the filter is of course closer to the reference filter . professor a : mm - hmm . phd e : mmm . um . yeah . i think professor a : so that means logically , in principle , it should be better . so probably it 'll be worse . or in the basic perverse nature uh of reality . yeah . ok . phd e : yeah . sure . grad c : yeah . phd e : yeah , and then we 've started to work with this of um voiced - unvoiced stuff . professor a : mm - hmm . phd e : and next week i think we will perhaps try to have um a new system with uh uh msg stream also see what what happens . so , something that 's similar to the proposal too , but with msg stream . professor a : mm - hmm . mm - hmm . phd d : no , i w i begin to play with matlab and to found some parameter robust for voiced - unvoiced decision . but only to play . and we they we found that maybe w is a classical parameter , the sq the variance between the um fft of the signal and the small spectrum of time we after the um mel filter bank . professor a : uh - huh . phd d : and , well , is more or less robust . is good for clean speech . is quite good for noisy speech . professor a : huh ? mm - hmm . phd d : but um we must to have bigger statistic with timit , professor a : mm - hmm . phd d : and is not ready yet to use on , professor a : yeah . phd d : well , i do n't know . professor a : yeah . phd e : yeah . so , basically we wa want to look at something like the ex the ex excitation signal and professor a : right . phd d : mm - hmm . phd e : which are the variance of it and phd d : i have here . i have here for one signal , for one frame . professor a : yeah . uh - huh . phd d : the the mix of the two , noise and unnoise , and the signal is this . clean , and this noise . these are the two the mixed , the big signal is for clean . professor a : well , i 'm s uh there 's none of these axes are labeled , so i do n't know what this what 's this axis ? phd d : uh this is uh this axis is nnn , `` frame `` . professor a : frame . phd d : mm - hmm . professor a : and what 's th what this ? phd d : uh , this is uh energy , log - energy of the spectrum . of the this is the variance , the difference between the spectrum of the signal and fft of each frame of the signal and this mouth spectrum of time after the f may fit for the two , professor a : for this one . for the noi phd d : this big , to here , they are to signal . this is for clean and this is for noise . professor a : oh . there 's two things on the same graph . phd d : yeah . i do n't know . i i think that i have d another graph , but i 'm not sure . professor a : so w which is clean and which is noise ? phd e : yeah . i think the lower one is noise . phd d : the lower is noise and the height is clean . professor a : ok . so it 's harder to distinguish phd d : it 's height . professor a : but it but it g phd e : yeah . professor a : with noise of course but but phd d : oh . i must to have . pity , but i do n't have two different professor a : and presumably when there 's a a phd e : so this should the the the t voiced portions . professor a : uh - huh . phd d : yeah , it is the height is voiced portion . phd e : the p the peaks should be voiced portion . phd d : and this is the noise portion . professor a : uh - huh . phd d : and this is more or less like this . but i meant to have see @ @ two two the picture . professor a : yeah . yeah . phd d : this is , for example , for one frame . the the spectrum of the signal . and this is the small version of the spectrum after ml mel filter bank . professor a : yeah . and this is the difference ? phd d : and this is i do n't know . this is not the different . this is trying to obtain with lpc model the spectrum but using matlab without going factor and s professor a : no pre - emphasis ? yeah . phd d : not pre - emphasis . nothing . professor a : yeah so it 's does n't do too well there . phd d : and the i think that this is good . this is quite similar . this is this is another frame . ho how i obtained the envelope , this envelope , with the mel filter bank . professor a : right . so now i wonder i mean , do you want to i know you want to get at something orthogonal from what you get with the smooth spectrum um . but if you were to really try and get a voiced - unvoiced , do you do you want to totally ignore that ? i mean , do you do you i mean , clearly a a very big very big cues for voiced - unvoiced come from uh spectral slope and so on , right ? phd e : mm - hmm . yeah . well , this would be this would be perhaps an additional parameter , professor a : yeah . phd e : simply is n't professor a : i see . phd e : yeah . phd d : yeah because when did noise clear in these section is clear professor a : mm - hmm . phd d : if s @ @ val value is indicative that is a voice frame and it 's low values professor a : yeah . yeah . well , you probably want i mean , certainly if you want to do good voiced - unvoiced detection , you need a few features . each each feature is by itself not enough . but , you know , people look at at slope and uh first auto - correlation coefficient , divided by power . or or uh um there 's uh i guess we prob probably do n't have enough computation to do a simple pitch detector or something ? i mean with a pitch detector you could have a have a an estimate of of what the uh . or maybe you could you just do it going through the p fft 's figuring out some um probable um harmonic structure . right . and and uh . phd d : you have read up and you have a paper , the paper that you s give me yesterday . they say that yesterday they are some problem phd e : oh , yeah . but yeah , but it 's not it 's , yeah , it 's it 's another problem . phd d : and the is another problem . phd e : yeah um . yeah , there is th this fact actually . if you look at this um spectrum , professor a : yeah . phd e : what 's this again ? is it the mel - filters ? phd d : yeah like this . of kind like this . phd e : yeah . ok . so the envelope here is the output of the mel - filters professor a : mm - hmm . phd e : and what we clearly see is that in some cases , and it clearly appears here , and the the harmonics are resolved by the f well , there are still appear after mel - filtering , professor a : mm - hmm . phd e : and it happens for high pitched voice because the width of the lower frequency mel - filters is sometimes even smaller than the pitch . professor a : yeah . phd e : it 's around one hundred , one hundred and fifty hertz nnn . professor a : right . phd e : and so what happens is that this uh , add additional variability to this envelope and um professor a : yeah . phd e : so we were thinking to modify the mel - spectrum to have something that that 's smoother on low frequencies . professor a : that 's as as a separate thing . yeah . phd e : yeah . this is a separate thing . professor a : separate thing ? phd d : yeah . professor a : yeah . yeah . maybe so . um . yeah . so , what yeah . what i was talking about was just , starting with the fft you could you could uh do a very rough thing to estimate estimate uh pitch . phd e : yeah . mm - hmm . professor a : and uh uh , given you know , given that , uh you could uh uh come up with some kind of estimate of how much of the low frequency energy was was explained by by uh uh those harmonics . phd e : mm - hmm . professor a : uh . it 's uh a variant on what you 're s what you 're doing . the i mean , the the the mel does give a smooth thing . but as you say it 's not that smooth here . and and so if you if you just you know subtracted off uh your guess of the harmonics then something like this would end up with quite a bit lower energy in the first fifteen hundred hertz or so and and our first kilohertz , even . phd e : mm - hmm . professor a : and um if was uh noisy , the proportion that it would go down would be if it was if it was unvoiced or something . phd e : mm - hmm . professor a : so you oughta be able to pick out voiced segments . at least it should be another another cue . so . anyway . phd e : mm - hmm . professor a : ok ? that 's what 's going on . uh . what 's up with you ? grad b : um our t i went to talk with uh mike jordan this this week professor a : mm - hmm . grad b : um and uh shared with him the ideas about um extending the larry saul work and um i asked him some questions about factorial h m so like later down the line when we 've come up with these these feature detectors , how do we how do we uh you know , uh model the time series that that happens um and and we talked a little bit about factorial h m ms and how um when you 're doing inference or w when you 're doing recognition , there 's like simple viterbi stuff that you can do for for these h m and the uh the great advantages that um a lot of times the factorial h m ms do n't um do n't over - alert the problem there they have a limited number of parameters and they focus directly on on uh the sub - problems at hand so you can imagine um five or so parallel um features um transitioning independently and then at the end you you uh couple these factorial h m ms with uh with uh undirected links um based on based on some more data . so he he seemed he seemed like really interested in in um in this and said said this is this is something very do - able and can learn a lot and um yeah , i 've just been continue reading um about certain things . professor a : mm - hmm . grad b : um thinking of maybe using um um m modulation spectrum stuff to um as features um also in the in the sub - bands professor a : mm - hmm . grad b : because it seems like the modulation um spectrum tells you a lot about the intelligibility of of certain um words and stuff so , um . yeah . just that 's about it . grad c : ok . and um so i 've been looking at avendano 's work and um uh i 'll try to write up in my next stat status report a nice description of what he 's doing , but it 's it 's an approach to deal with reverberation or that the aspect of his work that i 'm interested in the idea is that um normally an analysis frames are um too short to encompass reverberation effects um in full . you miss most of the reverberation tail in a ten millisecond window and so you you 'd like it to be that um the reverberation responses um simply convolved um in , but it 's not really with these ten millisecond frames cuz you j but if you take , say , a two millisecond um window i 'm sorry a two second window then in a room like this , most of the reverberation response is included in the window and the then it um then things are l more linear . it is it is more like the reverberation response is simply c convolved and um and you can use channel normalization techniques like uh in his thesis he 's assuming that the reverberation response is fixed . he just does um mean subtraction , which is like removing the dc component of the modulation spectrum and that 's supposed to d um deal uh deal pretty well with the um reverberation and um the neat thing is you ca n't take these two second frames and feed them to a speech recognizer um so he does this um method training trading the um the spectral resolution for time resolution and um come ca uh synthesizes a new representation which is with say ten second frames but a lower s um frequency resolution . so i do n't really know the theory . i guess it 's these are called `` time frequency representations `` and h he 's making the the time sh um finer grained and the frequency resolution um less fine grained . phd e : mm - hmm . grad c : s so i 'm i guess my first stab actually in continuing his work is to um re - implement this this thing which um changes the time and frequency resolutions cuz he does n't have code for me . so that that 'll take some reading about the theory . i do n't really know the theory . phd e : mm - hmm . grad c : oh , and um , another f first step is um , so the the way i want to extend his work is make it able to deal with a time varying reverberation response um and um we do n't really know how fast the um the reverberation response is varying the meeting recorder data um so um we we have this um block least squares um imp echo canceller implementation and um i want to try finding the the response , say , between a near mike and the table mike for someone using the echo canceller and looking at the echo canceller taps and then see how fast that varies from block to block . phd e : mm - hmm . grad c : that should give an idea of how fast the reverberation response is changing . phd e : mm - hmm . professor a : ok . um . i think we 're sort of done . phd e : yeah . professor a : so let 's read our digits and go home . grad c : um . s so um y you do i think you read some of the the zeros as o 's and some as zeros . professor a : yeah . grad c : is there a particular way we 're supposed to read them ? phd e : there are only zeros here . well . professor a : no . `` o `` `` o `` `` o `` `` o `` `` o `` `` o `` and `` zero `` are two ways that we say that digit . phd e : eee . yeah . professor a : so it 's phd e : but professor a : so it 's i phd e : perhaps in the sheets there should be another sign for the if we want to the the guy to say `` o `` or professor a : no . i mean . i think people will do what they say . phd e : it 's professor a : it 's ok . phd e : yeah . professor a : i mean in digit recognition we 've done before , you have you have two pronunciations for that value , `` o `` and `` zero `` . grad c : alright . phd e : but it 's perhaps more difficult for the people to prepare the database then , if because here you only have zeros professor a : no , they just write phd e : and and people pronounce `` o `` or zero professor a : they they write down oh . or they write down zero a and they and they each have their own pronunciation . phd e : yeah but if the sh the sheet was prepared with a different sign for the `` o `` . professor a : but people would n't know what that wa i mean there is no convention for it . phd e : ok . yeah . professor a : see . i mean , you 'd have to tell them `` ok when we write this , say it tha `` , you know , and you just they just want people to read the digits as you ordinarily would phd e : mm - hmm . yeah . professor a : and and people say it different ways . grad c : ok . is this a change from the last batch of of um forms ? because in the last batch it was spelled out which one you should read . phd e : yeah , it was orthographic , so . professor a : yes . that 's right . it was it was spelled out , and they decided they wanted to get at more the way people would really say things . grad c : oh . ok . professor a : that 's also why they 're they 're bunched together in these different groups . so so it 's yeah . so it 's it 's everything 's fine . ok . actually , let me just s since since you brought it up , i was just it was hard not to be self - conscious about that when it after we since we just discussed it . but i realized that that um when i 'm talking on the phone , certainly , and and saying these numbers , i almost always say zero . and uh cuz because uh i it 's two syllables . it 's it 's more likely they 'll understand what i said . so that that that 's the habit i 'm in , but some people say `` o `` and grad b : yeah i normally say `` o `` cuz it 's easier to say . professor a : yeah it 's shorter . yeah . so it 's so . so uh . now , do n't think about it . grad b : oh , no !"
}