{
    "query": "<s> what changes did the group say were needed ?",
    "answer": "phd f : right . uh , but i 'm not so much worried about the adaptation , actually , than than the , um , um the , uh , vtl estimation . grad e : right . phd f : if you have only one utterance per speaker you might actually screw up on estimating the the warping , uh , factor . so , um grad e : i strongly suspect that they have more speakers than we do . so , uh phd f : right . but it 's not the amount of speakers , it 's the num it 's the amount of data per speaker . grad e : right . so we we could probably do an extraction that was roughly equivalent . phd f : right . right . so grad e : so , although i i sort of know how to run it , there are a little a f few details here and there that i 'll have to dig out . phd f : ok . the key so th the system actually extracts the speaker id from the waveform names . grad e : right . i saw that . phd f : and there 's a there 's a script and that is actually all in one script . so there 's this one script that parses waveform names and extracts things like the , um , speaker , uh , id or something that can stand in as a speaker id . so , we might have to modify that script to recognize the , um , speakers , um , in the in the , uh , um , ti - digits database . grad e : right . right . and that , uh"
}