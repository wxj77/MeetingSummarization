{
    "query": "<s> what did the professor think about detecting smaller units of sound ?",
    "answer": "professor c : so that , by the way , basically is a is one of the units in our in our our neural network . grad e : the one o professor c : so that 's all it is . it 's a sig it 's a sigmoid , grad e : yeah . professor c : uh , with weighted sum at the input , which you train by gradient descent . grad e : right . yeah , so he uses , um , an em algorithm to to um train up these um parameters for the logistic regression . professor c : well , actually , yeah , grad e : the professor c : so i was using em to get the targets . so so you have this this this and gate what we were calling an and gate , but it 's a product product rule thing at the output . and then he uses , uh , i u and then feeding into that are i 'm sorry , there 's it 's an or at the output , is n't it ? yeah , grad e : mm - hmm . professor c : so that 's the product . and then , um , then he has each of these and things . and , um , but so they 're little neural neural units . um , and , um , they have to have targets . and so the targets come from em . phd a : and so are each of these , low level detectors { comment } are they , uh are these something that you decide ahead of time , like `` i 'm going to look for this particular feature or i 'm going to look at this frequency , `` or what what what are they looking at ? grad e : um phd a : what are their inputs ? grad e : uh right , so the ok , so at each for each sub - band { comment } there are basically , uh , several measures of snr and and correlation . phd a : ah , ok , ok . grad e : um , um and he said there 's like twenty of these per per sub - band . um , and for for every s every sub - band , e you you just pick ahead of time , um , `` i 'm going to have like five i independent logistic tests . `` phd a : mm - hmm . grad e : and you initialize these parameters , um , in some some way and use em to come up with your training targets for a for the the low - level detectors . phd a : mm - hmm . grad e : and then , once you get that done , you you you train the whole whole thing on maximum likelihood . um , and h he shows that using this this method to detect sonorance is it 's very robust compared to , um to typical , uh , full - band gaussian mixtures um estimations of of sonorance . phd a : mm - hmm . mm - hmm . grad e : and , uh so so that 's just that 's just one detector . so you can imagine building many of these detectors on different features . you get enough of these detectors together , um , then you have enough information to do , um , higher level discrimination , for example , discriminating between phones phd a : mm - hmm . grad e : and then you keep working your way up until you you build a full recognizer . phd a : mm - hmm . grad e : so , um , that 's that 's the direction which i 'm i 'm thinking about going in my quals . phd a : cool . professor c : you know , it has a number of properties that i really liked . i mean , one is the going towards , um , using narrow band information for , uh , ph phonetic features of some sort rather than just , uh , immediately going for the the typical sound units . phd a : right . professor c : another thing i like about it is that you t this thing is going to be trained explicitly trained for a product of errors rule , which is what , uh , allen keeps pointing out that fletcher observed in the twenties , phd a : mm - hmm . professor c : uh , for people listening to narrow band stuff . that 's friday 's talk , by the way . and then , um , uh , the third thing i like about it is , uh , and we 've played around with this in a different kind of way a little bit but it has n't been our dominant way of of operating anything , um , this issue of where the targets come from . so in our case when we 've been training it multi - band things , the way we get the targets for the individual bands is , uh , that we get the phonetic label for the sound there"
}