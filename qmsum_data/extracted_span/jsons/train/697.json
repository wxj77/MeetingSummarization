{
    "query": "<s> summarize the discussion on feature classification",
    "answer": "phd a : yeah . um , yeah . so basically we try to , uh , find good features that could be used for voicing detection , uh , but it 's still , uh on the , um t phd f : oh , well , i have the picture . phd a : we w basically we are still playing with matlab to to look at at what happened , phd c : what sorts of phd f : yeah . phd a : and phd c : what sorts of features are you looking at ? phd f : we have some phd a : so we would be looking at , um , the variance of the spectrum of the excitation , phd f : uh , um , this , this , and this . phd a : something like this , which is should be high for voiced sounds . uh , we phd c : wait a minute . i what does that mean ? the variance of the spectrum of excitation . phd a : yeah . so the so basically the spectrum of the excitation for a purely periodic sig signal shou sh professor b : ok . yeah , w what yo what you 're calling the excitation , as i recall , is you 're subtracting the the , um the mel mel mel filter , uh , spectrum from the fft spectrum . phd a : e that 's right . yeah . so professor b : right . phd a : yeah . phd f : mm - hmm . phd a : so we have the mel f filter bank , we have the fft , so we just professor b : so it 's it 's not really an excitation , but it 's something that hopefully tells you something about the excitation . phd a : yeah , that 's right . professor b : yeah , yeah . phd a : um yeah . phd f : we have here some histogram , phd a : e yeah , phd f : but they have a lot of overlap . phd a : but it 's it 's still yeah . so , well , for unvoiced portion we have something tha that has a mean around o point three , and for voiced portion the mean is o point fifty - nine . but the variance seem quite high . phd c : how do you know ? phd a : so mmm . phd c : how did you get your voiced and unvoiced truth data ? phd a : we used , uh , timit and we used canonical mappings between the phones phd f : yeah . we , uh , use timit on this , for phd a : th yeah . phd f : but if we look at it in one sentence , it apparently it 's good , i think . phd a : yeah , but yeah . uh , so it 's noisy timit . that 's right . yeah . grad e : it 's noisy timit . phd f : yeah . phd a : it seems quite robust to noise , so when we take we draw its parameters across time for a clean sentence and then nois the same noisy sentence , it 's very close . professor b : mm - hmm . phd a : yeah . so there are there is this . there could be also the , um something like the maximum of the auto - correlation function or which phd c : is this a a s a trained system ? or is it a system where you just pick some thresholds ? ho - how does it work ? phd a : right now we just are trying to find some features . and , phd c : mm - hmm . phd a : uh yeah . hopefully , i think what we want to have is to put these features in s some kind of , um well , to to obtain a statistical model on these features and to or just to use a neural network and hopefully these features w would help phd c : because it seems like what you said about the mean of the the voiced and the unvoiced { comment } that seemed pretty encouraging . phd a : mm - hmm . professor b : well , yeah , except the variance was big . phd c : right ? phd a : yeah . except the variance is quite high . professor b : right ? phd c : well , y phd a : yeah . phd c : well , y i i do n't know that i would trust that so much because you 're doing these canonical mappings from timit labellings . phd a : uh - huh . phd c : right ? so , really that 's sort of a cartoon picture about what 's voiced and unvoiced . so that could be giving you a lot of variance . phd a : yeah . phd c : i mean , i it it may be that that you 're finding something good and that the variance is sort of artificial because of how you 're getting your truth . phd a : mm - hmm . professor b : yeah . but another way of looking at it might be that i mean , what w we we are coming up with feature sets after all . so another way of looking at it is that um , the mel cepstru mel spectrum , mel cepstrum , any of these variants , um , give you the smooth spectrum . it 's the spectral envelope . by going back to the fft , you 're getting something that is more like the raw data . so the question is , what characterization and you 're playing around with this another way of looking at it is what characterization of the difference between the raw data and this smooth version is something that you 're missing that could help ? so , i mean , looking at different statistical measures of that difference , coming up with some things and just trying them out and seeing if you add them onto the feature vector does that make things better or worse in noise , where you 're really just i i the way i 'm looking at it is not so much you 're trying to f find the best the world 's best voiced - unvoiced , uh , uh , classifier , phd c : mm - hmm . professor b : but it 's more that , you know , uh , uh , try some different statistical characterizations of that difference back to the raw data phd c : right . professor b : and and m maybe there 's something there that the system can use . phd c : right . phd a : yeah . yeah , but ther more obvious is that yeah . the the more obvious is that that well , using the th the fft , um , you just it gives you just information about if it 's voiced or not voiced , ma mainly , i mean . but so , professor b : yeah . phd a : this is why we we started to look by having sort of voiced phonemes professor b : well , that 's the rea w w what i 'm arguing is that 's yeah . i mean , uh , what i 'm arguing is that that that 's givi you gives you your intuition . phd a : and mm - hmm . professor b : but in in reality , it 's you know , there 's all of this this overlap and so forth , grad e : oh , sorry . professor b : and but what i 'm saying is that may be ok , because what you 're really getting is not actually voiced versus unvoiced , both for the fac the reason of the overlap and and then , uh , th you know , structural reasons , uh , uh , like the one that chuck said , that that in fact , well , the data itself is that you 're working with is not perfect . phd a : yeah . mm - hmm . professor b : so , what i 'm saying is maybe that 's not a killer because you 're just getting some characterization , one that 's driven by your intuition about voiced - unvoiced certainly , phd a : mm - hmm . professor b : but it 's just some characterization of something back in the in the in the almost raw data , rather than the smooth version . phd a : mm - hmm . professor b : and your intuition is driving you towards particular kinds of , uh , statistical characterizations of , um , what 's missing from the spectral envelope . phd a : mm - hmm . professor b : um , obviously you have something about the excitation , um , and what is it about the excitation , and , you know and you 're not getting the excitation anyway , you know . so so i i would almost take a uh , especially if if these trainings and so forth are faster , i would almost just take a uh , a scattershot at a few different ways of look of characterizing that difference and , uh , you could have one of them but and and see , you know , which of them helps . phd a : mm - hmm . ok . phd c : so i is the idea that you 're going to take whatever features you develop and and just add them onto the future vector ? or , what 's the use of the the voiced - unvoiced detector ? phd a : uh , i guess we do n't know exactly yet . but , um yeah . th phd c : it 's not part of a vad system that you 're doing ? phd a : uh , no . no . phd c : oh , ok . phd a : no , the idea was , i guess , to to use them as as features . phd c : features . i see . phd a : uh yeah , it could be , uh it could be a neural network that does voiced and unvoiced detection , phd c : mm - hmm . phd a : but it could be in the also the big neural network that does phoneme classification . phd c : mm - hmm . phd a : mmm . yeah . professor b : but each one of the mixture components i mean , you have , uh , uh , variance only , so it 's kind of like you 're just multiplying together these , um , probabilities from the individual features within each mixture . so it 's so , uh , it seems l you know phd c : i think it 's a neat thing . uh , it seems like a good idea . professor b : yeah . um . yeah . i mean , i know that , um , people doing some robustness things a ways back were were just doing just being gross and just throwing in the fft and actually it was n't was n't was n't so bad . uh , so it would s and and you know that i it 's got ta hurt you a little bit to not have a a spectral , uh a s a smooth spectral envelope , so there must be something else that you get in return for that"
}