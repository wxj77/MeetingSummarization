{
    "query": "<s> summarize the meeting",
    "answer": "grad d : channel one . phd g : test . phd e : hello . grad d : channel three . phd g : test . phd a : uh - oh . professor f : so you think we 're going now , yes ? ok , good . alright going again uh so we 're gon na go around as before , and uh do do our digits . uh transcript one three one one dash one three three zero . { comment } three two three { comment } four seven six five { comment } five three one six two four one { comment } six seven { comment } seven { comment } eight { comment } nine zero nine four zero zero three { comment } zero one five eight { comment } one seven three five three { comment } two six eight zero { comment } three six two four three zero seven { comment } four { comment } five zero six nine four { comment } seven four { comment } eight five seven { comment } nine six one five { comment } o seven eight o two { comment } zero nine six zero four zero zero { comment } one { comment } two { comment } uh yeah , you do n't actually n need to say the name . grad c : ok , this is barry chen and i am reading transcript professor f : that 'll probably be bleeped out . so . that 's if these are anonymized , but yeah grad c : oh . { comment } ok . professor f : uh i mean not that there 's anything defamatory about uh eight five seven or or anything , but uh , anyway . uh so here 's what i have for i i was just jotting down things i think th w that we should do today . uh this is what i have for an agenda so far um , we should talk a little bit about the plans for the uh the field trip next week . uh a number of us are doing a field trip to uh uh ogi and uh mostly uh first though about the logistics for it . then maybe later on in the meeting we should talk about what we actually you know , might accomplish . uh uh , in and kind of go around see what people have been doing talk about that , a r progress report . um , essentially . um and then uh another topic i had was that uh uh uh dave here had uh said uh `` give me something to do . `` and i i have i have uh failed so far in doing that . and so maybe we can discuss that a little bit . if we find some holes in some things that that someone could use some help with , he 's he 's volunteering to help . phd a : i 've got to move a bunch of furniture . professor f : ok , always count on a serious comment from that corner . so , um , uh , and uh , then uh , talk a little bit about about disks and resource resource issues that that 's starting to get worked out . and then , anything else anybody has that is n't in that list ? uh grad d : i was just wondering , does this mean the battery 's dying and i should change it ? professor f : uh i think that means the battery 's o k . phd a : let me see . professor f : d do you grad d : oh ok , so th phd a : yeah , that 's good . you 're alright ? grad d : cuz it 's full . professor f : yeah . yeah . grad d : alright . professor f : yeah . yeah . it looks full of electrons . ok . plenty of electrons left there . ok , so , um , uh . ok , so , uh , i wanted to start this with this mundane thing . um uh i i it was it was kind of my bright idea to have us take a plane that leaves at seven twenty in the morning . grad c : oh , yeah , that 's right . professor f : um . uh this is uh the reason i did it uh was because otherwise for those of us who have to come back the same day it is really not much of a of a visit . uh so um the issue is how how how would we ever accomplish that ? uh what what what part of town do you live in ? grad c : um , i live in , um , the corner of campus . the , um , southeast corner . professor f : ok . ok , so would it be easier those of you who are not , you know , used to this area , it can be very tricky to get to the airport at at uh , you know , six thirty . um . so . would it be easier for you if you came here and i drove you ? yeah ? yeah , yeah , ok . phd g : yeah , perhaps , yeah . grad c : yeah . sure . phd e : yeah . professor f : ok , so if if everybody can get here at six . phd e : at six . professor f : yeah , i 'm afraid we need to do that to get there on time . grad c : six , ok . professor f : yeah , so . oh boy . anyway , so . phd a : will that be enough time ? professor f : yeah . yeah , so i 'll just pull up in front at six and just be out front . and , uh , and yeah , that 'll be plenty of time . it 'll take it it it wo n't be bad traffic that time of day and and uh phd a : i guess once you get past the bridge that that would be the worst . phd b : yeah , oakland . professor f : going to oakland . phd a : yeah . grad c : oakland . phd a : once you get past the turnoff to the bay bridge . professor f : bridge oh , the turnoff to the bridge phd a : yeah . professor f : wo n't even do that . phd b : yeah . professor f : i mean , just go down martin luther king . phd a : yeah . ok . mm - hmm . professor f : and then martin luther king to nine - eighty to eight - eighty , phd a : yeah . professor f : and it 's it 'd take us , tops uh thirty minutes to get there . phd a : oh , i professor f : so that leaves us fifty minutes before the plane it 'll just yeah . so great , ok so that 'll it 's i mean , it 's still not going to be really easy but well particularly for for uh for barry and me , we 're not we 're not staying overnight so we do n't need to bring anything particularly except for uh a pad of paper and so , and , uh you , two have to bring a little bit but uh you know , do n't do n't bring a footlocker and we 'll be ok so . grad c : s so just professor f : w you 're staying overnight . i figured you would n't need a great big suitcase , yeah . phd g : oh yeah . yeah . professor f : that 's sort of one night . so . anyway . ok . grad c : so , s six am , in front . professor f : six am in front . uh , i 'll be here . uh i 'll i 'll i 'll i 'll give you my phone number , if i 'm not here for a few m after a few minutes then grad c : wake you up . professor f : nah , i 'll be fine . i just , uh it for me it just means getting up a half an hour earlier than i usually do . not not not a lot , grad c : ok . wednesday . professor f : so ok , that was the real real important stuff . um , i i i figured maybe wait on the potential goals for the meeting uh until we talk about wh what 's been going on . so , uh , what 's been going on ? why do n't we start start over here . phd g : um . well , preparation of the french test data actually . so , it means that um , well , it is , uh , a digit french database of microphone speech , downsampled to eight kilohertz and i 've added noise to one part , with the actually the aurora - two noises . and , @ @ so this is a training part . and then the remaining part , i use for testing and with other kind of noises . so we can so this is almost ready . i 'm preparing the the htk baseline for this task . and , yeah . professor f : ok uh , so the htk base lines so this is using mel cepstra and so on , or ? yeah . ok . phd g : yeah . professor f : and again , i guess the p the plan is , uh , to uh then given this what 's the plan again ? phd g : the plan with these data ? professor f : with so so does i just remind me of what what you were going to do with the what what what what 's y you just described what you 've been doing . so if you could remind me of what you 're going to be doing . phd g : yeah . professor f : oh , this is yeah , yeah . phd g : uh , yeah . grad c : tell him about the cube . phd g : well . the cube ? i should tell him about the cube ? grad c : yeah . professor f : oh ! cube . yeah . phd g : yeah . phd e : fill in the cube . phd g : uh we actually we want to , mmm , uh , uh , analyze three dimensions , the feature dimension , the training data dimension , and the test data dimension . um . well , what we want to do is first we have number for each uh task . so we have the um , ti - digit task , the italian task , the french task and the finnish task . professor f : yeah ? phd g : so we have numbers with uh systems i mean i mean neural networks trained on the task data . and then to have systems with neural networks trained on , uh , data from the same language , if possible , with , well , using a more generic database , which is phonetically phonetically balanced , and . um . professor f : so - so we had talked i guess we had talked at one point about maybe , the language id corpus ? phd g : yeah . so . professor f : is that a possibility for that ? phd g : ye - uh yeah , but , uh these corpus , w w there is a callhome and a callfriend also , the callfriend is for language ind identification . well , anyway , these corpus are all telephone speech . so , um . this could be a a problem for why ? because uh , uh , the the speechdat databases are not telephone speech . they are downsampled to eight kilohertz but but they are not uh with telephone bandwidth . professor f : yeah . that 's really funny is n't it ? i mean cuz th this whole thing is for developing new standards for the telephone . grad c : telephone . professor f : yeah . phd g : yeah , but the the idea is to compute the feature before the before sending them to the well , you do n't do not send speech , you send features , computed on th the the device , professor f : mm - hmm . yeah , i know , but the reason phd g : or well . professor f : oh i see , so your point is that it 's it 's it 's uh the features are computed locally , and so they are n't necessarily telephone bandwidth , uh or telephone distortions . phd g : so you yeah . yeah . phd a : did you happen to find out anything about the ogi multilingual database ? professor f : yeah , that 's wh that 's wh that 's what i meant . phd g : yeah , it 's professor f : i said @ @ , there 's there 's there 's an ogi language id , not the not the , uh the callfriend is a is a , uh , ldc w thing , right ? phd g : yea - yeah , there are also two other databases . one they call the multi - language database , and another one is a twenty - two language , something like that . but it 's also telephone speech . phd a : oh , they are ? ok . phd g : uh . well , nnn . professor f : but i 'm not sure phd g : so professor f : i mean , we ' r e e the bandwidth should n't be such an issue right ? because e e this is downsampled and and filtered , right ? so it 's just the fact that it 's not telephone . and there are so many other differences between these different databases . i mean some of this stuff 's recorded in the car , and some of it 's i mean there 's there 's many different acoustic differences . so i 'm not sure if . i mean , unless we 're going to include a bunch of car recordings in the in the training database , i 'm not sure if it 's completely rules it out phd g : yeah . professor f : if our if we if our major goal is to have phonetic context and you figure that there 's gon na be a mismatch in acoustic conditions does it make it much worse f to sort of add another mismatch , if you will . uh , i i i i guess the question is how important is it to for us to get multiple languages uh , in there . phd g : yeah , but mm - hmm . um . yeah . well , actually , for the moment if we w do not want to use these phone databases , we we already have uh english , spanish and french uh , with microphone speech . professor f : mm - hmm . yeah . so that 's what you 're thinking of using is sort of the multi the equivalent of the multiple ? phd g : well . yeah , for the multilingual part we were thinking of using these three databases . professor f : and for the difference in phonetic context that you ? provide that . phd g : well , this uh , actually , these three databases are um generic databases . phd e : yeah . phd g : so w f for for uh italian , which is close to spanish , french and , i i uh , ti - digits we have both uh , digits training data and also more general training data . so . mmm . professor f : well , we also have this broadcast news that we were talking about taking off the disk , which is is microphone data for for english . phd g : yeah . yeah , perhaps yeah , there is also timit . professor f : yeah . phd g : we could use timit . professor f : right . yeah , so there 's plenty of stuff around . ok , so anyway , th the basic plan is to , uh , test this cube . yes . phd g : yeah . phd e : to fill in the cube . professor f : to fill i fill it in , yeah . ok . phd g : yeah , and perhaps , um we were thinking that perhaps the cross - language issue is not , uh , so big of a issue . well , w w we perhaps we should not focus too much on that cross - language stuff . i mean , uh , training training a net on a language and testing a for another language . professor f : uh - huh . but that 's phd g : mmm . perhaps the most important is to have neural networks trained on the target languages . but , uh , with a general database general databases . u so that th well , the the guy who has to develop an application with one language can use the net trained o on that language , or a generic net , professor f : uh , depen it depen it depends how you mean `` using the net `` . phd g : but not trained on a professor f : so , if you 're talking about for producing these discriminative features that we 're talking about you ca n't do that . because because the what they 're asking for is is a feature set . right ? and so , uh , we 're the ones who have been weird by by doing this training . but if we say , `` no , you have to have a different feature set for each language , `` i think this is ver gon na be very bad . phd g : yeah . you think so . grad c : that 's professor f : so oh yeah . yeah . i mean , in principle , i mean conceptually , it 's sort of like they want a re @ @ { comment } well , they want a replacement for mel cepstra . so , we say `` ok , this is the year two thousand , we 've got something much better than mel cepstra . it 's , you know , gobbledy - gook . `` ok ? and so we give them these gobbledy - gook features but these gobbledy - gook features are supposed to be good for any language . cuz you do n't know who 's gon na call , and you know , i mean so it 's it 's it 's , uh , uh how do you know what language it is ? somebody picks up the phone . so thi this is their image . someone picks up the phone , right ? phd g : well , i { comment } chh professor f : and and he he picks up the ph phd g : yeah , but the the application is there is a target language for the application . professor f : yeah . y y y phd g : so , if a professor f : well . but , no but , y you you pick up the phone , phd g : well . professor f : you talk on the phone , phd g : yeah ? professor f : and it sends features out . ok , so the phone does n't know what a what what your language is . phd g : yeah , if yeah . if it 's th in the phone , but professor f : but that 's the image that they have . phd g : well , it that that could be th at the server 's side , professor f : it could be , phd g : and , well . mmm , yeah . professor f : but that 's the image they have , right ? so that 's that 's i mean , one could argue all over the place about how things really will be in ten years . but the particular image that the cellular industry has right now is that it 's distributed speech recognition , where the , uh , uh , probabilistic part , and and s semantics and so forth are all on the servers , and you compute features of the uh , on the phone . so that 's that 's what we 're involved in . we might might or might not agree that that 's the way it will be in ten years , but that 's that 's that 's what they 're asking for . so so i think that th th it is an important issue whether it works cross - language . now , it 's the ogi , uh , folks ' perspective right now that probably that 's not the biggest deal . and that the biggest deal is the , um envir acoustic - environment mismatch . and they may very well be right , but i i was hoping we could just do a test and determine if that was true . if that 's true , we do n't need to worry so much . maybe maybe we have a couple languages in the training set and that gives us enough breadth uh , uh , that that that the rest does n't matter . um , the other thing is , uh , this notion of training to uh which i i guess they 're starting to look at up there , { comment } training to something more like articulatory features . uh , and if you have something that 's just good for distinguishing different articulatory features that should just be good across , you know , a wide range of languages . phd g : yeah . professor f : uh , but yeah , so i do n't th i know unfortunately i do n't i see what you 're comi where you 're coming from , i think , but i do n't think we can ignore it . phd g : so we we really have to do test with a real cross - language . i mean , tr for instance training on english and testing on italian , or or we can train or else , uh , can we train a net on , uh , a range of languages and which can include the test the test @ @ the target language , grad c : test on an unseen . phd g : or professor f : yeah , so , um , there 's there 's , uh this is complex . so , ultimately , uh , as i was saying , i think it does n't fit within their image that you switch nets based on language . now , can you include , uh , the the target language ? phd g : yeah . professor f : um , from a purist 's standpoint it 'd be nice not to because then you can say when because surely someone is going to say at some point , `` ok , so you put in the german and the finnish . uh , now , what do you do , uh , when somebody has portuguese ? `` you know ? um , and uh , however , you are n't it is n't actually a constraint in this evaluation . so i would say if it looks like there 's a big difference to put it in , then we 'd make note of it , and then we probably put in the other , because we have so many other problems in trying to get things to work well here that that , you know , it 's not so bad as long as we we note it and say , `` look , we did do this `` . phd a : and so , ideally , what you 'd wan na do is you 'd wan na run it with and without the target language and the training set for a wide range of languages . professor f : uh . yeah . phd g : yeah , perhaps . yeah . phd a : and that way you can say , `` well , `` you know , `` we 're gon na build it for what we think are the most common ones `` , professor f : yeah . phd g : yeah . phd a : but if that somebody uses it with a different language , you know , `` here 's what 's you 're l here 's what 's likely to happen . `` professor f : yeah , cuz the truth is , is that it 's it 's not like there are i mean , al although there are thousands of languages , uh , from uh , uh , the point of view of cellular companies , there are n't . phd a : right . professor f : there 's you know , there 's fifty or something , you know ? so , uh , an and they are n't you know , with the exception of finnish , which i guess it 's pretty different from most most things . uh , it 's it 's , uh most of them are like at least some of the others . and so , our guess that spanish is like italian , and and so on . i guess finnish is a is is a little bit like hungarian , supposedly , right ? phd a : i do n't know anything about finnish . professor f : or is i think well , i kn oh , well i know that h uh , h i mean , i 'm not a linguist , but i guess hungarian and finnish and one of the one of the languages from the former soviet union are in this sort of same family . but they 're just these , you know , uh countries that are pretty far apart from one another , have i guess , people rode in on horses and brought their phd g : the yeah . grad c : oh , my turn . professor f : your turn . grad c : oh , ok . um , let 's see , i i spent the last week , uh , looking over stephane 's shoulder . and and understanding some of the data . i re - installed , um , um , htk , the free version , so , um , everybody 's now using three point o , which is the same version that , uh , ogi is using . professor f : oh , good . grad c : yeah . so , without without any licensing big deals , or anything like that . and , um , so we 've been talking about this this , uh , cube thing , and it 's beginning more and more looking like the , uh , the borge cube thing . it 's really gargantuan . um , but i i 'm am i professor f : so are are you going to be assimilated ? phd a : resistance is futile . grad c : exactly . um , yeah , so i i 've been looking at , uh , uh , timit stuff . um , the the stuff that we 've been working on with timit , trying to get a , um a labels file so we can , uh , train up a train up a net on timit and test , um , the difference between this net trained on timit and a net trained on digits alone . um , and seeing if if it hurts or helps . professor f : mm - hmm . grad c : anyway . professor f : and again , when y just to clarify , when you 're talking about training up a net , you 're talking about training up a net for a tandem approach ? grad c : yeah , yeah . um . mm - hmm . professor f : and and the inputs are plp and delta and that sort of thing , grad c : well , the inputs are one dimension of the cube , professor f : or ? grad c : which , um , we 've talked about it being , uh , plp , um , m f c cs , um , j - jrasta , jrasta - lda professor f : yeah , but your initial things you 're making one choice there , grad c : yeah , professor f : right ? grad c : right . professor f : which is plp , or something ? grad c : um , i i have n't i have n't decided on on the initial thing . professor f : yeah . grad c : probably probably something like plp . yeah . professor f : yeah . um , so so you take plp and you you , uh , do it uh , you you , uh , use htk with it with the transformed features using a neural net that 's trained . and the training could either be from digits itself or from timit . grad c : right . professor f : and that 's the and , and th and then the testing would be these other things which which which might be foreign language . grad c : right . right . professor f : i see . i i i get in the picture about the cube . grad c : yeah . maybe ok . uh - huh . professor f : ok . um , i mean , those listening to this will not have a picture either , so , um , i guess i 'm i 'm not any worse off . but but at some point somebody should just show me the cube . it sounds s i i get i think i get the general idea of it , grad c : yeah , yeah , professor f : yeah . phd a : so , when you said that you were getting the labels for timit , { comment } um , are y what do you mean by that ? grad c : b may mm - hmm . oh , i 'm just i 'm just , uh , transforming them from the , um , the standard timit transcriptions into into a nice long huge p - file to do training . phd a : mmm . were the digits , um , hand - labeled for phones ? grad c : um , the the digits phd a : or were they those labels automatically derived ? grad c : oh yeah , those were those were automatically derived by by dan using , um , embedded embedded training and alignment . professor f : ah , but which dan ? grad c : uh , ellis . right ? professor f : ok . ok . grad c : yeah . so . phd a : i was just wondering because that test you 're t grad c : uh - huh . phd a : i i think you 're doing this test because you want to determine whether or not , uh , having s general speech performs as well as having specific speech . grad c : that 's right . professor f : well , especially when you go over the different languages again , because you 'd the different languages have different words for the different digits , phd a : mm - hmm . and i was professor f : so it 's phd a : yeah , so i was just wondering if the fact that timit you 're using the hand - labeled stuff from timit might be confuse the results that you get . professor f : i i think it would , but but on the other hand it might be better . phd a : right , but if it 's better , it may be better because it was hand - labeled . professor f : oh yeah , but still @ @ probably use it . phd a : yeah . ok . professor f : i mean , you know , i i i guess i 'm sounding cavalier , but i mean , i think the point is you have , uh , a bunch of labels and and they 're han hand uh hand - marked . uh , i guess , actually , timit was not entirely hand - marked . it was automatically first , and then hand hand - corrected . phd a : oh , ok . professor f : but but , um , uh , it it , um , it might be a better source . so , i it 's you 're right . it would be another interesting scientific question to ask , `` is it because it 's a broad source or because it was , you know , carefully ? `` phd a : mm - hmm . professor f : uh . and that 's something you could ask , but given limited time , i think the main thing is if it 's a better thing for going across languages on this training tandem system , phd a : yeah . right . professor f : then it 's probably phd a : what about the differences in the phone sets ? grad c : uh , between languages ? phd a : no , between timit and the the digits . grad c : oh , um , right . well , there 's a mapping from the sixty - one phonemes in timit to to fifty - six , the icsi fifty - six . phd e : sixty - one . phd a : oh , ok . i see . grad c : and then the digits phonemes , um , there 's about twenty twenty - two or twenty - four of them ? is that right ? phd a : out of that fifty - six ? grad c : out of that fifty - six . phd a : oh , ok . grad c : yeah . so , it 's it 's definitely broader , yeah . phd g : but , actually , the issue of phoneti phon uh phone phoneme mappings will arise when we will do severa use several languages phd e : yeah . phd g : because you well , some phonemes are not , uh , in every languages , and so we plan to develop a subset of the phonemes , uh , that includes , uh , all the phonemes of our training languages , phd a : mm - hmm . phd g : and use a network with kind of one hundred outputs or something like that . professor f : mm - hmm . you mean a superset , sort of . phd g : uh , yeah , professor f : yeah . yeah . phd g : superset , phd e : yeah . i th i looks the sampa sampa phone . phd g : yeah . phd e : sampa phone ? for english uh american english , and the the the language who have more phone are the english . phd g : yeah . phd e : of the these language . but n for example , in spain , the spanish have several phone that d does n't appear in the e english and we thought to complete . but for that , it needs we must r h do a lot of work because we need to generate new tran transcription for the database that we have . professor f : mm - hmm . mm - hmm . phd b : other than the language , is there a reason not to use the timit phone set ? cuz it 's larger ? as opposed to the icsi phone set ? grad c : oh , you mean why map the sixty - one to the fifty - six ? phd b : yeah . grad c : i do n't know . i have professor f : um , i forget if that happened starting with you , or was it o or if it was eric , afterwards who did that . but i think , basically , there were several of the phones that were just hardly ever there . phd a : yeah , and i think some of them , they were making distinctions between silence at the end and silence at the beginning , when really they 're both silence . i th i think it was things like that that got it mapped down to fifty - six . professor f : yeah , especially in a system like ours , which is a discriminative system . you know , you 're really asking this net to learn . phd b : yeah . phd a : yeah . professor f : it 's it 's kind of hard . phd a : there 's not much difference , really . and the ones that are gone , i think are i think there was they also in timit had like a glottal stop , which was basically a short period of silence , phd b : mm - hmm . phd a : and so . phd b : well , we have that now , too , right ? phd a : i do n't know . phd b : yeah . professor f : i it 's actually pretty common that a lot of the recognition systems people use have things like like , say thirty - nine , phone symbols , right ? uh , and then they get the variety by by bringing in the context , the phonetic context . uh . so we actually have an unusually large number in in what we tend to use here . um . so , a a actually maybe now you 've got me sort of intrigued . what there 's can you describe what what 's on the cube ? grad c : yeah , w i th i think that 's a good idea professor f : i mean grad c : to to talk about the whole cube professor f : yeah , yeah . phd e : yeah . yeah . grad c : and maybe we could sections in the cube for people to work on . professor f : yeah . yeah . grad c : um , ok . uh , do you wan na do it ? professor f : ok , so even even though the meeting recorder does n't does n't , uh and since you 're not running a video camera we wo n't get this , but if you use a board it 'll help us anyway . uh , point out one of the limitations of this medium , but you 've got the wireless on , grad c : yeah , i have the wireless . professor f : right ? yeah , so you can walk around . grad c : ok . can y can you walk around too ? no . ok , well , um , professor f : uh , he ca n't , actually , but grad c : s basically , the the cube will have three dimensions . professor f : he 's tethered . grad c : the first dimension is the the features that we 're going to use . and the second dimension , um , is the training corpus . and that 's the training on the discriminant neural net . um and the last dimension happens to be professor f : yeah and again yeah . so the the training for htk is always that 's always set up for the individual test , right ? that there 's some training data and some test data . so that 's different than this . grad c : right , right . this is this is for for ann only . and , yeah , the training for the htk models is always , uh , fixed for whatever language you 're testing on . professor f : right . grad c : and then , there 's the testing corpus . so , then i think it 's probably instructive to go and and and show you the features that we were talking about . um , so , let 's see . help me out with with what ? plp ? ok . phd g : uh , jrasta . grad c : jrasta . phd g : and jrasta - lda . grad c : jrasta - lda . phd g : um , multi - band . grad c : multi - band . phd g : so there would be multi - band before , um before our network , i mean . grad c : yeah , just the multi - band features , right ? phd g : and grad c : yeah . phd g : yeah . professor f : uh - huh . ah . ah . phd g : so , something like , uh , s tct within bands and well . and then multi - band after networks . meaning that we would have , uh , neural networks , uh , discriminant neural networks for each band . uh , yeah . and using the the outputs of these networks or the linear outputs or something like that . uh , yeah . phd a : what about mel cepstrum ? or is that grad c : oh , um phd a : you do n't include that because it 's part of the base or something ? phd e : yeah databases . professor f : well , y you do have a baseline system that 's m that 's mel cepstra , phd e : yeah . professor f : right ? phd e : mm - hmm . phd g : but , uh , well , not for the the ann . i mean so , yeah , we could we could add mfcc also . grad c : we could add professor f : probably should . i mean at least at least conceptually , you know , it does n't meant you actually have to do it , phd g : yeah . phd e : yeah . professor f : but conceptually it makes sense as a as a base line . phd a : it 'd be an interesting test just to have just to do mfcc with the neural net phd e : without the phd a : and everything else the same . phd e : yeah . phd a : compare that with just m - mfcc without the the net . phd g : yeah . phd e : mm - hmm . grad c : i think i think dan did some of that . um , in his previous aurora experiments . and with the net it 's it 's wonderful . without the net it 's just baseline . professor f : um , i think ogi folks have been doing that , too . d because i think that for a bunch of their experiments they used , uh , mel cepstra , actually . grad c : yeah . yeah . professor f : um , of course that 's there and this is here and so on . ok ? grad c : ok . um , for the training corpus corpus , um , we have , um , the the d digits from the various languages . um , english spanish um , french what else do we have ? phd g : and the finnish . grad c : finnish . phd a : where did th where did that come from ? phd e : and italian . phd a : digits ? phd e : uh , no , italian no . italian no . grad c : oh . italian . phd e : i italian yes . italian ? professor f : italian . phd a : is that was that distributed with aurora , or ? grad c : one l or two l 's ? phd a : where did that ? professor f : the newer one . phd g : so english , uh , finnish and italian are aurora . professor f : yeah . phd g : and spanish and french is something that we can use in addition to aurora . uh , well . professor f : yeah , so carmen brought the spanish , and stephane brought the french . grad c : ok . and , um , oh yeah , and professor f : is it french french or belgian french ? there 's a phd g : it 's , uh , french french . grad c : french french . phd e : like mexican spain and spain . professor f : yeah . phd b : or swiss . phd e : i think that is more important , phd b : swiss - german . phd e : mexican spain . because more people professor f : yeah . yeah , probably so . phd e : yeah . professor f : yeah . yeah , herve always insists that belgian is i is absolutely pure french , has nothing to do with but he says those those those parisians talk funny . phd g : yeah , yeah , yeah . they have an accent . professor f : yeah they they do , yeah . yeah . but then he likes belgian fries too , so . ok . grad c : and then we have , uh , um , broader broader corpus , um , like timit . timit so far , phd e : and spanish too . grad c : right ? spanish oh , spanish stories ? phd e : albayzin is the name . phd a : what about ti - digits ? grad c : um , ti - digits uh all these aurora f d data p data is from is derived from ti - digits . phd a : uh - huh . oh . oh ok . grad c : um , basically , they they corrupted it with , uh , different kinds of noises at different snr levels . phd a : ah . i see . grad c : yeah . professor f : y and i think stephane was saying there 's there 's some broader s material in the french also ? phd g : yeah , we cou we could use yeah . the french data . phd e : spanish stories ? grad c : sp - not spanish stories ? phd e : no . no . albayz professor f : spanish grad c : spanish something . phd e : yeah . phd b : did the aurora people actually corrupt it themselves , or just specify the signal and the signal - t grad c : they they corrupted it , um , themselves , but they also included the the noise files for us , right ? or phd g : yeah . grad c : so we can go ahead and corrupt other things . professor f : i 'm just curious , carmen i mean , i could n't tell if you were joking or i is it is it mexican spanish , phd e : no no no no . professor f : or is it phd e : no no no no . professor f : oh , no , no . it 's it 's spanish from spain , spanish . phd e : spanish from spain . professor f : yeah , ok . grad c : from spain . professor f : alright . spanish from spain . yeah , we 're really covered there now . ok . and the french from france . phd g : yeah , the no , the french is f yeah , from , uh , paris , grad c : oh , from paris , ok . professor f : yeah . grad c : and timit 's from lots of different places . professor f : from ti . from i it 's from texas . so may maybe it 's phd b : from the deep south . professor f : so - s so it 's not really from the us either . grad c : yeah . professor f : is that ? ok . grad c : yeah . ok . and , um , with within the training corporas um , we 're , uh , thinking about , um , training with noise . so , incorporating the same kinds of noises that , um , aurora is in incorporating in their , um in their training corpus . um , i do n't think we we 're given the , uh the unseen noise conditions , though , right ? professor f : i think what they were saying was that , um , for this next test there 's gon na be some of the cases where they have the same type of noise as you were given before hand and some cases where you 're not . grad c : like mm - hmm . ok . phd g : mm - hmm . professor f : so , presumably , that 'll be part of the topic of analysis of the the test results , is how well you do when it 's matching noise and how well you do where it 's not . grad c : right . professor f : i think that 's right . grad c : so , i guess we ca n't train on on the the unseen noise conditions . professor f : well , not if it 's not seen , grad c : right . if not if it 's unseen . professor f : yeah . grad c : yeah . professor f : ok . i mean , i i i i it does seem to me that a lot of times when you train with something that 's at least a little bit noisy it can it can help you out in other kinds of noise even if it 's not matching just because there 's some more variance that you 've built into things . but , but , uh , phd g : mm - hmm . professor f : uh , exactly how well it will work will depend on how near it is to what you had ahead of time . so . ok , so that 's your training corpus , phd g : mm - hmm . professor f : and then your testing corpus ? grad c : um , the testing corporas are , um , just , um , the same ones as aurora testing . and , that includes , um , the english spa - um , italian . finnish . phd e : finnish . grad c : uh , we ' r we 're gon na get german , right ? ge - { comment } at the final test will have german . professor f : well , so , yeah , the final test , on a guess , is supposed to be german and danish , phd g : uh , yeah . professor f : right ? grad c : right . phd g : the s yeah , the spanish , perhaps , grad c : spanish . oh yeah , we can we can test on s spanish . phd g : we will have . yeah . but the the aurora spanish , i mean . grad c : oh yeah . mm - hmm . professor f : oh , there 's a there 's spanish testing in the aurora ? phd g : uh , not yet , but , uh , yeah , uh , e phd e : yeah , it 's preparing . phd g : pre they are preparing it , phd e : they are preparing . phd g : and , well , according to hynek it will be we will have this at the end of november , or um . professor f : ok , so , uh , something like seven things in each , uh each column . phd g : yeah professor f : so that 's , uh , three hundred and forty - three , uh , different systems that are going to be developed . there 's three of you . grad c : yeah . one hundred each , about . professor f : uh , so that 's hundred and hundred and fourteen each . grad d : what a what about noise conditions ? professor f : what ? grad d : w do n't we need to put in the column for noise conditions ? professor f : are you just trying to be difficult ? grad d : no , i just do n't understand . grad c : well , th uh , when when i put these testings on there , i 'm assumi professor f : i 'm just kidding . yeah . grad c : there - there 's three three tests . um , type - a , type - b , and type - c . and they 're all they 're all gon na be test tested , um , with one training of the htk system . um , there 's a script that tests all three different types of noise conditions . test - a is like a matched noise . test - b is a is a slightly mismatched . and test - c is a , um , mismatched channel . grad d : and do we do all our training on clean data ? grad c : um , no , no , phd e : also , we can clean that . grad c : we 're we 're gon na be , um , training on the noise files that we do have . professor f : so , um yeah , so i guess the question is how long does it take to do a a training ? i mean , it 's not totally crazy t i mean , these are a lot of these are built - in things and we know we have programs that compute plp , we have msg , we have jra you know , a lot of these things will just kind of happen , wo n't take uh a huge amount of development , it 's just trying it out . so , we actually can do quite a few experiments . grad c : mm - hmm . professor f : but how how long does it take , do we think , for one of these { comment } trainings ? grad c : that 's a good question . phd a : what about combinations of things ? professor f : oh yeah , that 's right . i mean , cuz , so , for instance , i think the major advantage of msg yeah , good point . a major advantage of msg , i see , th that we 've seen in the past is combined with plp . phd e : yeah . grad c : now , this is turning into a four - dimensional cube ? phd a : well , you just select multiple things on the one dimension . phd b : or you just add it to the features . grad c : just phd e : here . grad c : oh , yeah . ok . professor f : yeah , so , i mean , you do n't wan na , uh let 's see , seven choose two would be , uh , twenty - one different combinations . um . phd b : it 's not a complete set of combinations , though , professor f : probably phd b : right ? it 's not a complete set of combinations , though , professor f : what ? phd b : right ? professor f : yeah , i hope not . yeah , there 's grad c : that would be professor f : uh , yeah , so plp and msg i think we definitely wan na try cuz we 've had a lot of good experience with putting those together . phd e : mm - hmm . professor f : um . yeah . phd a : when you do that , you 're increasing the size of the inputs to the net . do you have to reduce the hidden layer , or something ? professor f : well , so i mean , so i it does n't increase the number of trainings . phd a : no , no , i 'm i 'm just wondering about number of parameters in the net . do you have to worry about keeping that the same , or ? professor f : uh , i do n't think so . phd b : there 's a computation limit , though , is n't there ? professor f : yeah , i mean , it 's just more compu excuse me ? phd b : is n't there like a limit on the computation load , or d latency , or something like that for aurora task ? professor f : oh yeah , we have n't talked about any of that at all , have we ? yeah , so , there 's not really a limit . what it is is that there 's there 's , uh it 's just penalty , you know ? that that if you 're using , uh , a megabyte , then they 'll say that 's very nice , but , of course , it will never go on a cheap cell phone . um . and , u uh , i think the computation is n't so much of a problem . i think it 's more the memory . uh , and , expensive cell phones , exa expensive hand - helds , and so forth , are gon na have lots of memory . so it 's just that , uh , these people see the the cheap cell phones as being still the biggest market , so . phd b : mm - hmm . professor f : um . but , yeah , i was just realizing that , actually , it does n't explode out , um it 's not really two to the seventh . but it 's but but i i it does n't really explode out the number of trainings cuz these were all trained individually . right ? so , uh , if you have all of these nets trained some place , then , uh , you can combine their outputs and do the kl transformation and so forth grad c : mm - hmm . professor f : and and , uh so , what it it blows out is the number of uh testings . and , you know and the number of times you do that last part . but that last part , i think , is so has got ta be pretty quick , so . uh . right ? i mean , it 's just running the data through phd a : but wh what about a net that 's trained on multiple languages , though ? professor f : well , you got ta do the kl transformation , phd g : eight y professor f : but phd a : is that just separate nets for each language then combined , or is that actually one net trained on ? phd e : necessary to put in . professor f : good question . phd g : uh , probably one net . well . uh . professor f : one would think one net , but we 've i do n't think we 've tested that . right ? phd g : so , in the broader training corpus we can we can use , uh , the three , or , a combination of of two two languages . phd e : database three . phd a : in one net . mm - hmm . phd g : yeah . professor f : yeah , so , i guess the first thing is if w if we know how much a how long a a training takes , if we can train up all these these combinations , uh , then we can start working on testing of them individually , and in combination . right ? grad c : mm - hmm . professor f : because the putting them in combination , i think , is not as much computationally as the r training of the nets in the first place . right ? phd g : yeah . professor f : so y you do have to compute the kl transformation . uh , which is a little bit , but it 's not too much . phd g : it 's not too much , professor f : yeah . so it 's phd g : but yeah . but there is the testing also , which implies training , uh , the htk models phd e : the the model the htk model . phd g : and , well , professor f : uh , right . phd g : it 's professor f : right . so if you do have lots of combinations , it 's phd g : yeah . but it 's it 's it 's not so long . it @ @ yeah . professor f : how long does it take for an , uh , htk training ? phd g : it 's around six hours , i think . phd e : it depends on the phd g : for training and testing , yeah . phd e : more than six hours . phd g : more . phd e : for the italian , yes . maybe one day . phd g : one day ? phd e : yeah . professor f : for htk ? phd e : well . professor f : really ? running on what ? phd e : uh , m mfcc . professor f : no , i 'm sorry , ru running on what machine ? phd e : uh , ravioli . professor f : uh , i do n't know what ravioli is . is it is it an ultra - five , or is it a ? phd e : mmm um . who is that ? phd a : i do n't know . grad c : i do n't know . phd e : i do n't know . phd b : i do n't know what a ravioli is . phd e : i do n't know . grad c : i do n't know . phd b : we can check really quickly , i guess . phd g : yeah , i i think it 's - it 's - it 's not so long because , well , the ti - digits test data is about , uh how many hours ? uh , th uh , thirty hours of speech , i think , professor f : it 's a few hours . yeah . right , phd g : something like that . and it p well . professor f : so , i mean , clearly , there there 's no way we can even begin to do an any significant amount here unless we use multiple machines . phd g : it 's six hours . professor f : right ? so so w we i mean there 's plenty of machines here and they 're n they 're often not in in a great great deal of use . so , i mean , i think it 's it 's key that that the that you look at , uh , you know , what machines are fast , what machines are used a lot uh , are we still using p - make ? is that ? grad c : oh , i do n't know how w how we would p - make this , though . um . professor f : well , you have a i mean , once you get the basic thing set up , you have just all the uh , a all these combinations , grad c : yeah . professor f : right ? grad c : mm - hmm . professor f : um . it 's it 's let 's say it 's six hours or eight hours , or something for the training of htk . how long is it for training of of , uh , the neural net ? grad c : the neural net ? um . phd g : i would say two days . phd a : depends on the corpuses , right ? phd e : it depends . phd b : it s also depends on the net . phd g : yeah . grad c : yeah . phd e : depends on the corpus . phd b : how big is the net ? phd e : for albayzin i trained on neural network , uh , was , um , one day also . professor f : uh , but on what machine ? grad c : on a spert board . phd e : uh . i i think the neural net spert . grad c : y you did a you did it on a spert board . professor f : ok , again , we do have a bunch of spert boards . grad c : yeah . professor f : and i think there there there 's i think you folks are probably go the ones using them right now . phd a : is it faster to do it on the spert , or ? professor f : uh , do n't know . grad c : it 's it 's still a little faster on the professor f : used to be . phd a : is it ? grad c : yeah , yeah . ad - adam adam did some testing . or either adam or or dan did some testing and they found that the spert board 's still still faster . phd a : mm - hmm . grad c : and the benefits is that , you know , you run out of spert and then you can do other things on your your computer , professor f : mm - hmm . phd a : mm - hmm . grad c : and you do n't professor f : yeah . so you could be we have quite a few spert boards . you could set up , uh , you know , ten different jobs , or something , to run on spert different spert boards and and have ten other jobs running on different computers . so , it 's got to take that sort of thing , or or we 're not going to get through any significant number of these . grad c : yeah . professor f : so this is yeah , i mean , i kind of like this because what it no uh , no , what i like about it is we we we do have a problem that we have very limited time . you know , so , with very limited time , we actually have really quite a quite a bit of computational resource available if you , you know , get a look across the institute and how little things are being used . and uh , on the other hand , almost anything that really i you know , is is new , where we 're saying , `` well , let 's look at , like we were talking before about , uh , uh , voiced - unvoiced - silence detection features and all those sort `` that 's phd e : yeah . professor f : i think it 's a great thing to go to . but if it 's new , then we have this development and and and learning process t to to go through on top of just the the all the all the work . so , i i i do n't see how we 'd do it . so what i like about this is you basically have listed all the things that we already know how to do . phd e : yeah . professor f : and and all the kinds of data that we , at this point , already have . and , uh , you 're just saying let 's look at the outer product of all of these things and see if we can calculate them . a a am i am i interpreting this correctly ? is this sort of what what you 're thinking of doing in the short term ? phd g : yeah . professor f : so so then i think it 's just the the missing piece is that you need to , uh , you know you know , talk to talk to , uh , chuck , talk to , uh , adam , uh , sort out about , uh , what 's the best way to really , you know , attack this as a as a as a mass problem in terms of using many machines . uh , and uh , then , you know , set it up in terms of scripts and so forth , and uh , in in kind o some kind of structured way . uh . um , and , you know , when we go to , uh , ogi next week , uh , we can then present to them , you know , what it is that we 're doing . and , uh , we can pull things out of this list that we think they are doing sufficiently , grad c : mmm . mm - hmm . professor f : that , you know , we 're not we wo n't be contributing that much . um . and , uh then , uh , like , we 're there . phd b : how big are the nets you 're using ? grad c : um , for the for nets trained on digits , { comment } um , we have been using , uh , four hundred order hidden units . and , um , for the broader class nets we 're we 're going to increase that because the , um , the digits nets only correspond to about twenty phonemes . phd b : uh - huh . professor f : broader class ? grad c : um , the broader broader training corpus nets like timit . um , w we 're gon na professor f : oh , it 's not actually broader class , it 's actually finer class , but you mean y you mean more classes . grad c : right . right . yeah . more classes . right , right . more classes . professor f : yeah . grad c : that 's what i mean . professor f : yeah . yeah . grad c : mm - hmm . and . yeah . professor f : carmen , did you do you have something else to add ? we you have n't talked too much , and phd e : d i begin to work with the italian database to nnn , to with the f front - end and with the htk program and the @ @ . and i trained eh , with the spanish two neural network with plp and with lograsta plp . i do n't know exactly what is better if if lograsta or jrasta . professor f : well , um , jrasta has the potential to do better , but it does n't always . it 's i i jrasta is more complicated . it 's it 's , uh instead of doing rasta with a log , you 're doing rasta with a log - like function that varies depending on a j parameter , uh , which is supposed to be sensitive to the amount of noise there is . so , it 's sort of like the right transformation to do the filtering in , is dependent on how much noise there is . phd e : hm - hmm . professor f : and so in jrasta you attempt to do that . it 's a little complicated because once you do that , you end up in some funny domain and you end up having to do a transformation afterwards , which requires some tables . and , uh , phd e : hm - hmm . professor f : so it 's it 's it 's a little messier , uh , there 's more ways that it can go wrong , uh , but if if if you 're careful with it , it can do better . phd e : it 's a bit i 'll do better . professor f : so , it 's so . phd e : um , and i think to to to recognize the italian digits with the neural netw spanish neural network , and also to train another neural network with the spanish digits , the database of spanish digits . and i working that . professor f : yeah . phd e : but prepa to prepare the the database are difficult . was for me , n it was a difficult work last week with the labels because the the program with the label obtained that i have , the albayzin , is different w to the label to train the neural network . and that is another work that we must to do , to to change . professor f : i i did n't understand . phd e : uh , for example albayzin database was labeled automatically with htk . it 's not hand it 's not labels by hand . professor f : oh , `` l labeled `` . phd e : labels . professor f : i 'm sorry , phd e : i 'm sorry , professor f : i have a p i had a problem with the pronunciation . phd e : i 'm sorry . the labels . i 'm sorry . the labels . professor f : yeah , ok . phd e : oh , also that professor f : so , ok , so let 's start over . so , ti timi timit 's hand - labeled , and and you 're saying about the spanish ? phd e : the spanish labels ? that was in different format , that the format for the em the program to train the neural network . professor f : oh , i see . phd e : i necessary to convert . and someti well phd a : so you 're just having a problem converting the labels . phd e : it 's it 's yeah . yeah , but n yes , because they have one program , feacalc , but no , l labecut , l labecut , but do n't does n't , eh , include the htk format to convert . professor f : mm - hmm . phd e : and , i do n't know what . i ask e even i ask to dan ellis what i can do that , and h they he say me that h he does does n't any any s any form to to do that . and at the end , i think that with labecut i can transfer to ascii format , and htk is an ascii format . and i m do another , uh , one program to put ascii format of htk to ase ay ac ascii format to exceed professor f : mm - hmm . phd e : and they used labcut to to pass . professor f : ok , yeah . phd e : actually that was complicated , professor f : so you phd e : but well , i know how we can did that do that . professor f : sure . so it 's just usual kind of uh sometimes say housekeeping , right ? to get these get these things sorted out . phd e : yeah . professor f : so it seems like there 's there 's some peculiarities of the , uh of each of these dimensions that are getting sorted out . and then , um , if if you work on getting the , uh , assembly lines together , and then the the pieces sort of get ready to go into the assembly line and gradually can start , you know , start turning the crank , more or less . and , uh , uh , we have a lot more computational capability here than they do at ogi , so i think that i if what 's what 's great about this is it sets it up in a very systematic way , so that , uh , once these all of these , you know , mundane but real problems get sorted out , we can just start turning the crank phd e : mm - hmm . professor f : and and push all of us through , and then finally figure out what 's best . grad c : yeah . um , i i was thinking two things . uh , the first thing was , um we we actually had thought of this as sort of like , um not not in stages , { comment } but more along the the time axis . just kind of like one stream at a time , professor f : mm - hmm . grad c : je - je - je - je - je { comment } check out the results and and go that way . professor f : oh , yeah , yeah , sure . no , i 'm just saying , i 'm just thinking of it like loops , grad c : uh - huh . professor f : right ? and so , y y y if you had three nested loops , that you have a choice for this , a choice for this , and a choice for that , grad c : yeah . mm - hmm . professor f : right ? and you 're going through them all . that that 's what i meant . grad c : right , right . professor f : and , uh , the thing is that once you get a better handle on how much you can realistically do , uh , um , concurrently on different machines , different sperts , and so forth , uh , and you see how long it takes on what machine and so forth , you can stand back from it and say , `` ok , if we look at all these combinations we 're talking about , and combinations of combinations , and so forth , `` you 'll probably find you ca n't do it all . grad c : mm - hmm . ok . professor f : ok , so then at that point , uh , we should sort out which ones do we throw away . grad c : mm - hmm . professor f : which of the combinations across you know , what are the most likely ones , and and , uh , i still think we could do a lot of them . i mean , it would n't surprise me if we could do a hundred of them or something . but , probably when you include all the combinations , you 're actually talking about a thousand of them or something , and that 's probably more than we can do . uh , but a hundred is a lot . and and , uh , um yeah . grad c : yeah , and the the second thing was about scratch space . and i think you sent an email about , um , e scratch space for for people to work on . and i know that , uh , stephane 's working from an nt machine , so his his home directory exists somewhere else . professor f : his his stuff is somewhere else , yeah . yeah , i mean , my point i i want to yeah , thanks for bring it back to that . my th i want to clarify my point about that that that chuck repeated in his note . um . we 're over the next year or two , we 're gon na be upgrading the networks in this place , grad c : mm - hmm . professor f : but right now they 're still all te pretty much all ten megabit lines . and we have reached the this the machines are getting faster and faster . so , it actually has reached the point where it 's a significant drag on the time for something to move the data from one place to another . grad c : mm - hmm . professor f : so , you you do n't w especially in something with repetitive computation where you 're going over it multiple times , you do do n't want to have the the data that you 're working on distant from where it 's being where the computation 's being done if you can help it . grad c : mm - hmm . professor f : uh . now , we are getting more disk for the central file server , which , since it 's not a computational server , would seem to be a contradiction to what i just said . but the idea is that , uh , suppose you 're working with , uh , this big bunch of multi multilingual databases . um , you put them all in the central ser at the cen central file server . grad c : mm - hmm . professor f : then , when you 're working with something and accessing it many times , you copy the piece of it that you 're working with over to some place that 's close to where the computation is and then do all the work there . and then that way you you wo n't have the the network you wo n't be clogging the network for yourself and others . that 's the idea . so , uh , it 's gon na take us it may be too late for this , uh , p precise crunch we 're in now , but , uh , we 're , uh it 's gon na take us a couple weeks at least to get the , uh , uh , the amount of disk we 're gon na be getting . we 're actually gon na get , uh , i think four more , uh , thirty - six gigabyte drives and , uh , put them on another another disk rack . we ran out of space on the disk rack that we had , so we 're getting another disk rack and four more drives to share between , uh primarily between this project and the meetings meetings project . um . but , uh , we 've put another i guess there 's another eighteen gigabytes that 's that 's in there now to help us with the immediate crunch . but , uh , are you saying so i do n't know where you 're stephane , where you 're doing your computations . if i so , you 're on an nt machine , so you 're using some external machine phd g : yeah , it , uh well , to it 's nutmeg and mustard , i think , professor f : do you know these yet ? phd g : i do n't know what kind . phd a : nuh - uh . professor f : yeah , ok . uh , are these are these , uh , computational servers , or something ? i 'm i 've been kind of out of it . phd g : yeah , i think , yeah . i think so . professor f : unfortunately , these days my idea of running comput of computa doing computation is running a spread sheet . uh , have n't been have n't been doing much computing personally , so . um . yeah , so those are computational servers . so i guess the other question is what disk there i space there is there on the computational servers . phd a : right . yeah , i 'm not sure what 's available on is it you said nutmeg and what was the other one ? phd g : mustard . phd a : mustard . ok . professor f : yeah , well , you 're the you 're the disk czar now . phd a : right , right . well , i 'll check on that . professor f : yeah . yeah , so basically , uh , chuck will be the one who will be sorting out what disk needs to be where , and so on , and i 'll be the one who says , `` ok , spend the money . `` so . which , i mean , n these days , uh , if you 're talking about scratch space , it does n't increase the , uh , need for backup , and , uh , i think it 's not that big a d and the the disks themselves are not that expensive . right now it 's phd a : what you can do , when you 're on that machine , is , uh , just go to the slash - scratch directory , and do a df minus k , and it 'll tell you if there 's space available . phd g : yeah . phd a : uh , and if there is then , uh professor f : but was n't it , uh i think dave was saying that he preferred that people did n't put stuff in slash - scratch . it 's more putting in d s xa or xb or , phd a : well , there 's different there , um , there 's professor f : right ? phd a : right . so there 's the slash - x - whatever disks , and then there 's slash - scratch . and both of those two kinds are not backed up . and if it 's called `` slash - scratch `` , it means it 's probably an internal disk to the machine . um . and so that 's the kind of thing where , like if um , ok , if you do n't have an nt , but you have a a a unix workstation , and they attach an external disk , { comment } it 'll be called `` slash - x - something `` uh , if it 's not backed up and it 'll be `` slash - d - something `` if it is backed up . and if it 's inside the machine on the desk , it 's called `` slash - scratch `` . but the problem is , if you ever get a new machine , they take your machine away . it 's easy to unhook the external disks , put them back on the new machine , but then your slash - scratch is gone . so , you do n't wan na put anything in slash - scratch that you wan na keep around for a long period of time . but if it 's a copy of , say , some data that 's on a server , you can put it on slash - scratch because , um , first of all it 's not backed up , and second it does n't matter if that machine disappears and you get a new machine because you just recopy it to slash - scratch . so tha that 's why i was saying you could check slash - scratch on those on on , um , mustard and and nutmeg to see if if there 's space that you could use there . professor f : i see . phd a : you could also use slash - x - whatever disks on mustard and nutmeg . phd g : yeah , yeah . phd a : um . yeah , and we do have i mean , yeah , so so you yeah , it 's better to have things local if you 're gon na run over them lots of times so you do n't have to go to the network . professor f : right , so es so especially if you 're right , if you 're if you 're taking some piece of the training corpus , which usually resides in where chuck is putting it all on the on the , uh , file server , uh , then , yeah , it 's fine if it 's not backed up because if it g g gets wiped out or something , y i mean it is backed up on the other disk . so , phd a : mm - hmm . professor f : yeah , ok . phd a : yeah , so , one of the things that i need to i 've started looking at uh , is this the appropriate time to talk about the disk space stuff ? professor f : sure . phd a : i 've started looking at , um , disk space . dan david , um , put a new , um , drive onto abbott , that 's an x disk , which means it 's not backed up . so , um , i 've been going through and copying data that is , you know , some kind of corpus stuff usually , that that we 've got on a cd - rom or something , onto that new disk to free up space on other disks . and , um , so far , um , i 've copied a couple of carmen 's , um , databases over there . we have n't deleted them off of the slash - dc disk that they 're on right now in abbott , um , uh , but we i would like to go through sit down with you about some of these other ones and see if we can move them onto , um , this new disk also . there 's there 's a lot more space there , phd g : yeah , ok . phd a : and it 'll free up more space for doing the experiments and things . so , anything that that you do n't need backed up , we can put on this new disk . um , but if it 's experiments and you 're creating files and things that you 're gon na need , you probably wan na have those on a disk that 's backed up , just in case something { comment } goes wrong . so . um so far i 've i 've copied a couple of things , but i have n't deleted anything off of the old disk to make room yet . um , and i have n't looked at the any of the aurora stuff , except for the spanish . so i i guess i 'll need to get together with you and see what data we can move onto the new disk . phd g : yeah , ok . professor f : um , yeah , i i just an another question occurred to me is is what were you folks planning to do about normalization ? phd g : um . well , we were thinking about using this systematically for all the experiments . um . professor f : this being ? phd g : so , but uh . so that this could be another dimension , but we think perhaps we can use the the best , uh , um , uh , normalization scheme as ogi is using , so , with parameters that they use there , professor f : yeah , i think that 's a good idea . phd g : u u professor f : i mean it 's i i we we seem to have enough dimensions as it is . so probably if we sort of take their phd g : yeah , yeah , yeah . professor f : probably the on - line line normalization because then it { comment } it 's if we do anything else , we 're gon na end up having to do on - line normalization too , so we may as well just do on - line normalization . phd g : mm - hmm . professor f : so . um . so that it 's plausible for the final thing . good . um . so , i guess , yeah , th the other topic i maybe we 're already there , or almost there , is goals for the for next week 's meeting . uh . i i i it seems to me that we wan na do is flush out what you put on the board here . uh . you know , maybe , have it be somewhat visual , a little bit . grad c : ok . like a s like a slide ? professor f : uh , so w we can say what we 're doing , yeah . and , um , also , if you have sorted out , um , this information about how long i roughly how long it takes to do on what and , you know , what we can how many of these trainings , uh , uh , and testings and so forth that we can realistically do , uh , then one of the big goals of going there next week would be to to actually settle on which of them we 're gon na do . and , uh , when we come back we can charge in and do it . um . anything else that i a a actually started out this this field trip started off with with , uh , stephane talking to hynek , so you may have you may have had other goals , uh , for going up , and any anything else you can think of would be we should think about accomplishing ? i mean , i 'm just saying this because maybe there 's things we need to do in preparation . phd g : oh , i think basically , this is this is , uh , yeah . professor f : ok . ok . uh . alright . and uh and the other the the last topic i had here was , um , uh d dave 's fine offer to to , uh , do something on this . i mean he 's doing he 's working on other things , but to to do something on this project . so the question is , `` where where could we , uh , uh , most use dave 's help ? `` phd g : um , yeah , i was thinking perhaps if , um , additionally to all these experiments , which is not really research , well i mean it 's , uh , running programs professor f : yeah . phd g : and , um , trying to have a closer look at the perhaps the , um , speech , uh , noise detection or , uh , voiced - sound - unvoiced - sound detection and which could be important in i for noise noise phd a : i think that would be a i think that 's a big big deal . because the you know , the thing that sunil was talking about , uh , with the labels , uh , labeling the database when it got to the noisy stuff ? the that that really throws things off . you know , having the noise all of a sudden , your your , um , speech detector , i mean the the , um what was it ? what was happening with his thing ? he was running through these models very quickly . he was getting lots of , uh , uh insertions , is what it was , in his recognitions . professor f : the only problem i mean , maybe that 's the right thing the only problem i have with it is exactly the same reason why you thought it 'd be a good thing to do . um , i i think that let 's fall back to that . but i think the first responsibility is sort of to figure out if there 's something that , uh , an an additional uh , that 's a good thing you remove the mike . go ahead , good . uh , uh . what an additional clever person could help with when we 're really in a crunch for time . right ? cuz dave 's gon na be around for a long time , phd e : yeah . professor f : right ? he 's he 's gon na be here for years . and so , um , phd g : yeah . professor f : over years , if he 's if he 's interested in , you know , voiced - unvoiced - silence , he could do a lot . but if there if in fact there 's something else that he could be doing , that would help us when we 're we 're sort of uh strapped for time we have we we 've , you know , only , uh , another another month or two to you know , with the holidays in the middle of it , um , to to get a lot done . if we can think of something some piece of this that 's going to be the very fact that it is sort of just work , and i and it 's running programs and so forth , is exactly why it 's possible that it some piece of could be handed to someone to do , because it 's not uh , yeah , so that that 's the question . and we do n't have to solve it right this s second , but if we could think of some some piece that 's that 's well defined , that he could help with , he 's expressing a will willingness to do that . phd a : what about training up a , um , a multilingual net ? phd e : yes , maybe to , mmm , put together the the label the labels between timit and spanish or something like that . phd g : yeah . yeah , so defining the superset , and , uh , joining the data and mmm . phd e : yeah . phd g : yeah . professor f : uh . yeah , that 's something that needs to be done in any event . phd e : yeah . professor f : so what we were just saying is that that , um i was arguing for , if possible , coming up with something that that really was development and was n't research because we we 're we have a time crunch . and so , uh , if there 's something that would would save some time that someone else could do on some other piece , then we should think of that first . see the thing with voiced - unvoiced - silence is i really think that that it 's to do to do a a a a poor job is is pretty quick , uh , or , you know , a so - so job . you can you can you can throw in a couple fea we know what what kinds of features help with it . you can throw something in . you can do pretty well . but i remember , in fact , when you were working on that , and you worked on for few months , as i recall , and you got to , say ninety - three percent , and getting to ninety - four really really hard . phd a : mm - hmm . another year . professor f : yeah , yeah . so , um and th th the other tricky thing is , since we are , uh , even though we 're not we do n't have a strict prohibition on memory size , and and computational complexity , uh , clearly there 's some limitation to it . so if we have to if we say we have to have a pitch detector , say , if we if we 're trying to incorporate pitch information , or at least some kind of harmonic harmonicity , or something , this is another whole thing , take a while to develop . anyway , it 's a very very interesting topic . i mean , one i think one of the a lot of people would say , and i think dan would also , uh , that one of the things wrong with current speech recognition is that we we really do throw away all the harmonicity information . uh , we try to get spectral envelopes . reason for doing that is that most of the information about the phonetic identity is in the spectral envelopes are not in the harmonic detail . but the harmonic detail does tell you something . like the fact that there is harmonic detail is is real important . so . um . so , uh . so i think yeah . so wh that so the the other suggestion that just came up was , well what about having him work on the , uh , multilingual super f superset kind of thing . uh , coming up with that and then , you know , training it training a net on that , say , um , from from , uh from timit or something . is that or uh , for multiple databases . what what would you what would you think it would wh what would this task consist of ? phd g : yeah , it would consist in , uh , well , um , creating the the superset , and , uh , modifying the lab labels for matching the superset . uh . professor f : uh , creating a superset from looking at the multiple languages , phd g : well , creating the mappings , actually . professor f : and then creating i m changing labels on timit ? phd g : yeah . professor f : or on or on multiple language multiple languages ? phd e : no . the multiple language . phd g : yeah , yeah , with the @ @ three languages , phd e : maybe for the other language because timit have more phone . professor f : yeah . phd a : so you 'd have to create a mapping from each language to the superset . phd e : yeah . mm - hmm . phd g : from each language to the superset , phd e : yeah . phd g : yeah . grad c : there 's , um carmen was talking about this sampa thing , and it 's , um , it 's an effort by linguists to come up with , um , a machine readable ipa , um , sort of thing , right ? and , um , they they have a web site that stephane was showing us that has , um has all the english phonemes and their sampa correspondent , um , phoneme , professor f : yeah . grad c : and then , um , they have spanish , they have german , they have all all sorts of languages , um , mapping mapping to the sampa phonemes , which phd e : yeah , the tr the transcription , though , for albayzin is n the transcription are of sampa the same , uh , how you say , symbol that sampa appear . phd b : sampa ? what does `` sampa `` mean ? professor f : mm - hmm . hmm . phd e : but i do n't know if timit o how is timit . phd b : so , i mean professor f : what phd b : i 'm sorry . professor f : go ahead . phd b : i was gon na say , does that mean ipa is not really international ? grad c : no , it 's it 's saying phd a : it uses special diacritics and stuff , which you ca n't do with ascii characters . grad c : y ca n't print on ascii . phd e : yeah . phd a : so the sampa 's just mapping those . phd b : oh , i see . got it . professor f : what , uh has ogi done anything about this issue ? do they have do they have any kind of superset that they already have ? phd g : i do n't think so . well , they they they 're going actually the the other way , defining uh , phoneme clusters , apparently . well . professor f : aha . that 's right . uh , and that 's an interesting way to go too . phd a : so they just throw the speech from all different languages together , then cluster it into sixty or fifty or whatever clusters ? phd g : i think they 've not done it , uh , doing , uh , multiple language yet , but what they did is to training , uh , english nets with all the phonemes , and then training it in english nets with , uh , kind of seventeen , i think it was seventeen , uh , broad classes . phd a : automatically derived mm - hmm . automatically derived broad classes , or ? phd g : yeah . yeah , i think so . phd a : uh - huh . phd g : uh , and , yeah . and the result was that apparently , when testing on cross - language it was better . i think so . but hynek did n't add did n't have all the results when he showed me that , so , well . professor f : so that does make an interesting question , though . phd g : but professor f : is there 's some way that we should tie into that with this . um . right ? i mean , if if in fact that is a better thing to do , should we leverage that , rather than doing , um , our own . right ? so , if i if if they s i mean , we have i we have the the trainings with our own categories . and now we 're saying , `` well , how do we handle cross - language ? `` and one way is to come up with a superset , but they are als they 're trying coming up with clustered , and do we think there 's something wrong with that ? phd g : i think that there 's something wrong professor f : ok . what w phd g : or well , because well , for the moment we are testing on digits , and e i perhaps u using broad phoneme classes , it 's it 's ok for um , uh classifying the digits , but as soon as you will have more words , well , words can differ with only a single phoneme , and which could be the same , uh , class . professor f : i see . phd g : well . so . professor f : right . although , you are not using this for the phd g : so , i 'm professor f : you 're using this for the feature generation , though , not the phd g : yeah , but you will ask the net to put one for th th the phoneme class professor f : yeah . phd g : and so . phd a : so you 're saying that there may not be enough information coming out of the net to help you discriminate the words ? professor f : yeah . phd g : well . yeah , yeah . mmm . phd b : fact , most confusions are within the phone phone classes , right ? i think , uh , larry was saying like obstruents are only confused with other obstruents , et cetera , et cetera . professor f : yeah . yeah . yeah . phd g : yeah , this is another p yeah , another point . professor f : yeah . grad c : so so , maybe we could look at articulatory type stuff , professor f : but that 's what i thought they were gon na grad c : right ? professor f : did they not do that , or ? phd g : i do n't think so . well , professor f : so phd g : they were talking about , perhaps , but they d professor f : they 're talking about it , but that 's sort of a question whether they did phd g : w yeah . professor f : because that 's that 's the other route to go . grad c : mm - hmm . professor f : instead of this , you know grad c : superclass . professor f : instead of the the the the superclass thing , which is to take so suppose y you do n't really mark arti to really mark articulatory features , you really wan na look at the acoustics and and see where everything is , and we 're not gon na do that . so , uh , the second class way of doing it is to look at the , uh , phones that are labeled and translate them into acoustic uh , uh articulatory , uh , uh , features . so it wo n't really be right . you wo n't really have these overlapping things and so forth , phd a : so the targets of the net are these ? professor f : but phd a : articulatory features . professor f : articulatory feature . phd a : but that implies that you can have more than one on at a time ? professor f : right . that 's right . phd a : ah . ok . professor f : you either do that or you have multiple nets . phd a : i see . professor f : um . and , um i do n't know if our software this if the qu versions of the quicknet that we 're using allows for that . do you know ? grad c : allows for ? professor f : multiple targets being one ? grad c : oh , um , we have gotten soft targets to to work . professor f : ok . so that that 'll work , yeah . grad c : yeah . professor f : ok . so , um , that 's another thing that could be done is that we could we could , uh , just translate instead of translating to a superset , just translate to articulatory features , some set of articulatory features and train with that . now the fact even though it 's a smaller number , it 's still fine because you have the the , uh , combinations . so , in fact , it has every , you know it had has has every distinction in it that you would have the other way . phd g : yeah . professor f : but it should go across languages better . phd a : we could do an interesting cheating experiment with that too . we could i do n't know , if you had uh the phone labels , you could replace them by their articulatory features and then feed in a vector with those uh , things turned on based on what they 're supposed to be for each phone to see if it if you get a big win . do you know what i 'm saying ? so , um , i mean , if your net is gon na be outputting , uh , a vector of basically of well , it 's gon na have probabilities , but let 's say that they were ones and zeros , then y and you know for each , um , i do n't know if you know this for your testing data , but if you know for your test data , you know , what the string of phones is and and you have them aligned , then you can just instead of going through the net , just create the vector for each phone and feed that in to see if that data helps . eh , eh , what made me think about this is , i was talking with hynek and he said that there was a guy at a t - andt who spent eighteen months working on a single feature . and because they had done some cheating experiments professor f : this was the guy that we were just talking a that we saw on campus . so , this was larry saul who did this did this . phd a : oh , ok . professor f : he used sonorants . phd a : right , ok , professor f : was what he was doing . phd a : right . and they they had done a cheating experiment or something , right ? professor f : yeah . phd a : and determined that professor f : he he di he did n't mention that part . phd a : well , hynek said that that , i guess before they had him work on this , they had done some experiment where if they could get that one feature right , it dramatically improved the result . professor f : but . i see . ok . phd a : so i was thinking , you know it made me think about this , that if it 'd be an interesting experiment just to see , you know , if you did get all of those right . professor f : should be . because if you get all of them in there , that defines all of the phones . so that 's that 's equivalent to saying that you 've got got all the phones right . phd a : right . professor f : so , if that does n't help , there 's phd a : yeah . professor f : although , yeah , it would be make an interesting cheating experiment because we are using it in this funny way , phd a : yeah . professor f : where we 're converting it into features . phd a : and then you also do n't know what error they 've got on the htk side . you know ? it sort of gives you your the best you could hope for , kind of . professor f : yeah . grad c : mmm . mmm , i see . phd b : the soft training of the nets still requires the vector to sum to one , though , right ? grad c : to sum up to one . phd b : so you ca n't really feed it , like , two articulatory features that are on at the same time with ones cuz it 'll kind of normalize them down to one half or something like that , for instance . phd g : but perhaps you have the choice of the final nonl grad c : right . nonlinearity ? phd g : uh , nonlinearity , yeah . is it always softmax grad c : it 's sig no , it 's actually sigmoid - x phd g : or ? yeah . grad c : for the phd g : so if you choose sigmoid it 's o it 's ok ? grad c : you , um professor f : did we just run out of disk , grad c : i think i think apparently , the , uh professor f : or ? phd b : why do n't you just choose linear ? right ? grad c : what 's that ? phd b : linear outputs ? grad c : linear outputs ? phd b : is n't that what you 'll want ? if you 're gon na do a kl transform on it . grad c : right , right . right , but during the training , we would train on sigmoid - x phd b : oh , you yeah ? grad c : and then at the end just chop off the final nonlinearity ."
}