{
    "query": "<s> summarize the discussion about dealing with smaller features of recordings",
    "answer": "grad e : um . well , i 've i 've talked to some of you already . um , but i 'm , uh , looking into extending the work done by larry saul and john allen and uh mazin rahim . um , they they have a system that 's , uh , a multi - band , um , system but their multi - band is is a little different than the way that we 've been doing multi - band in the past , where um where we 've been @ @ { comment } uh taking um sub - band features and i training up these neural nets and on on phonetic targets , and then combining them some somehow down the line , um , they 're they 're taking sub - band features and , um , training up a detector that detects for , um , these phonetic features for example , um , he presents um , uh , a detector to detect sonorance . and so what what it basically is is , um it 's there 's at the lowest level , there it 's it 's an or ga i mean , it 's an and gate . so , uh , on each sub - band you have several independent tests , to test whether um , there 's the existence of sonorance in a sub - band . and then , um , it c it 's combined by a soft and gate . and at the at the higher level , for every if , um the higher level there 's a soft or gate . uh , so if if this detector detects um , the presence of of sonorance in any of the sub - bands , then the detect uh , the or gate at the top says , `` ok , well this frame has evidence of sonorance . `` phd a : what are what are some of the low level detectors that they use ? grad e : and these are all oh , ok . well , the low level detectors are logistic regressions . um , and the , uh professor c : so that , by the way , basically is a is one of the units in our in our our neural network . grad e : the one o professor c : so that 's all it is . it 's a sig it 's a sigmoid , grad e : yeah . professor c : uh , with weighted sum at the input , which you train by gradient descent . grad e : right . yeah , so he uses , um , an em algorithm to to um train up these um parameters for the logistic regression . professor c : well , actually , yeah , grad e : the professor c : so i was using em to get the targets . so so you have this this this and gate what we were calling an and gate , but it 's a product product rule thing at the output . and then he uses , uh , i u and then feeding into that are i 'm sorry , there 's it 's an or at the output , is n't it ? yeah , grad e : mm - hmm . professor c : so that 's the product . and then , um , then he has each of these and things . and , um , but so they 're little neural neural units . um , and , um , they have to have targets . and so the targets come from em . phd a : and so are each of these , low level detectors { comment } are they , uh are these something that you decide ahead of time , like `` i 'm going to look for this particular feature or i 'm going to look at this frequency , `` or what what what are they looking at ? grad e : um phd a : what are their inputs ? grad e : uh right , so the ok , so at each for each sub - band { comment } there are basically , uh , several measures of snr and and correlation . phd a : ah , ok , ok . grad e : um , um and he said there 's like twenty of these per per sub - band . um , and for for every s every sub - band , e you you just pick ahead of time , um , `` i 'm going to have like five i independent logistic tests . `` phd a : mm - hmm . grad e : and you initialize these parameters , um , in some some way and use em to come up with your training targets for a for the the low - level detectors . phd a : mm - hmm . grad e : and then , once you get that done , you you you train the whole whole thing on maximum likelihood . um , and h he shows that using this this method to detect sonorance is it 's very robust compared to , um to typical , uh , full - band gaussian mixtures um estimations of of sonorance . phd a : mm - hmm . mm - hmm ."
}