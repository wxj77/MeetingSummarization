{
    "query": "<s> summarize the meeting",
    "answer": "phd a : ok , we 're going . phd d : damn . professor c : and uh hans - uh , hans - guenter will be here , um , i think by next next tuesday or so . phd b : oh , ok . phd d : mm - hmm . professor c : so he 's he 's going to be here for about three weeks , phd b : oh ! that 's nice . phd a : just for a visit ? professor c : and , uh uh , we 'll see . we might might end up with some longer collaboration or something . phd a : cool . professor c : so he 's gon na look in on everything we 're doing phd d : mm - hmm . professor c : and give us his his thoughts . and so it 'll be another another good person looking at things . phd b : oh . hmm . grad e : th - that 's his spectral subtraction group ? professor c : yeah , grad e : is that right ? professor c : yeah . grad e : oh , ok . so i guess i should probably talk to him a bit too ? professor c : oh , yeah . yeah . yeah . no , he 'll be around for three weeks . he 's , uh , um , very , very , easygoing , easy to talk to , and , uh , very interested in everything . phd a : really nice guy . professor c : yeah , yeah . phd b : yeah , we met him in amsterdam . professor c : yeah , yeah , he 's been here before . phd b : oh , ok . professor c : i mean , he 's he 's he 's he 's phd a : wh - back when i was a grad student he was here for a , uh , uh a year or { comment } n six months . phd b : i have n't noticed him . professor c : n nine months . phd a : something like that . professor c : something like that . phd a : yeah . professor c : yeah . yeah . he 's he 's done a couple stays here . yeah . phd a : so , um , { comment } i guess we got lots to catch up on . and we have n't met for a couple of weeks . we did n't meet last week , morgan . um , i went around and talked to everybody , and it seemed like they they had some new results but rather than them coming up and telling me i figured we should just wait a week and they can tell both you know , all of us . so , um , why do n't we why do n't we start with you , dave , and then , um , we can go on . grad e : oh , ok . so , um , since we 're looking at putting this , um mean log m magnitude spectral subtraction , um , into the smartkom system , i i did a test seeing if , um , it would work using past only { comment } and plus the present to calculate the mean . so , i did a test , um , where i used twelve seconds from the past and the present frame to , um , calculate the mean . and phd a : twelve seconds twelve twelve seconds back from the current frame , is that what you mean ? grad e : uh twelve seconds , um , counting back from the end of the current frame , phd a : ok , ok . grad e : yeah . so it was , um , twen i think it was twenty - one frames and that worked out to about twelve seconds . phd a : mm - hmm . grad e : and compared to , um , do using a twelve second centered window , i think there was a drop in performance but it was just a slight drop . professor c : mm - hmm . grad e : is is that right ? professor c : um , yeah , i mean , it was pretty it was pretty tiny . yeah . grad e : uh - huh . so that was encouraging . and , um , that that um , that 's encouraging for for the idea of using it in an interactive system like and , um , another issue i 'm i 'm thinking about is in the smartkom system . so say twe twelve seconds in the earlier test seemed like a good length of time , but what happens if you have less than twelve seconds ? and , um so i w bef before , um back in may , i did some experiments using , say , two seconds , or four seconds , or six seconds . in those i trained the models using mean subtraction with the means calculated over two seconds , or four seconds , or six seconds . and , um , here , i was curious , what if i trained the models using twelve seconds but i f i gave it a situation where the test set i was subtracted using two seconds , or four seconds , or six seconds . and , um so i did that for about three different conditions . and , um i mean , i th i think it was , um , four se i think i think it was , um , something like four seconds and , um , six seconds , and eight seconds . something like that . and it seems like it it it hurts compared to if you actually train the models { comment } using th that same length of time but it it does n't hurt that much . um , u usually less than point five percent , although i think i did see one where it was a point eight percent or so rise in word error rate . but this is , um , w where , um , even if i train on the , uh , model , and mean subtracted it with the same length of time as in the test , it the word error rate is around , um , ten percent or nine percent . so it does n't seem like that big a d a difference . professor c : but it but looking at it the other way , is n't it what you 're saying that it did n't help you to have the longer time for training , if you were going to have a short time for grad e : that that 's true . um , professor c : i mean , why would you do it , if you knew that you were going to have short windows in testing . phd a : yeah , it seems like for your i mean , in normal situations you would never get twelve seconds of speech , right ? i 'm not e u phd b : you need twelve seconds in the past to estimate , right ? or l or you 're looking at six sec seconds in future and six in professor c : yeah . grad e : um , t twelve s professor c : no , total . grad e : n n uh for the test it 's just twelve seconds in the past . phd b : no , it 's all oh , ok . phd a : is this twelve seconds of uh , regardless of speech or silence ? or twelve seconds of speech ? grad e : of of speech . phd b : mm - hmm . professor c : the other thing , um , which maybe relates a little bit to something else we 've talked about in terms of windowing and so on is , that , um , i wonder if you trained with twelve seconds , and then when you were two seconds in you used two seconds , and when you were four seconds in , you used four seconds , and when you were six and you basically build up to the twelve seconds . so that if you have very long utterances you have the best , grad e : yeah . professor c : but if you have shorter utterances you use what you can . grad e : right . and that 's actually what we 're planning to do in professor c : ok . yeah . grad e : but s so i g so i guess the que the question i was trying to get at with those experiments is , `` does it matter what models you use ? does it matter how much time y you use to calculate the mean when you were , um , tra doing the training data ? `` professor c : right . but i mean the other thing is that that 's i mean , the other way of looking at this , going back to , uh , mean cepstral subtraction versus rasta kind of things , is that you could look at mean cepstral subtraction , especially the way you 're doing it , uh , as being a kind of filter . and so , the other thing is just to design a filter . you know , basically you 're you 're you 're doing a high - pass filter or a band - pass filter of some sort and and just design a filter . and then , you know , a filter will have a certain behavior and you loo can look at the start up behavior when you start up with nothing . grad e : mm - hmm . professor c : and and , you know , it will , uh , if you have an iir filter for instance , it will , um , uh , not behave in the steady - state way that you would like it to behave until you get a long enough period , but , um , uh , by just constraining yourself to have your filter be only a subtraction of the mean , you 're kind of , you know , tying your hands behind your back because there 's filters have all sorts of be temporal and spectral behaviors . grad e : mm - hmm . professor c : and the only thing , you know , consistent that we know about is that you want to get rid of the very low frequency component . phd b : but do you really want to calculate the mean ? and you neglect all the silence regions { comment } or you just use everything that 's twelve seconds , and grad e : um , you do you mean in my tests so far ? phd b : ye - yeah . grad e : most of the silence has been cut out . just there 's just inter - word silences . phd b : mm - hmm . and they are , like , pretty short . shor grad e : pretty short . phd b : yeah , ok . grad e : yeah . phd b : yeah . mm - hmm . so you really need a lot of speech to estimate the mean of it . grad e : well , if i only use six seconds , it still works pretty well . phd b : yeah . yeah . uh - huh . grad e : i saw in my test before . i was trying twelve seconds cuz that was the best in my test before and that increasing past twelve seconds did n't seem to help . phd b : hmm . huh . grad e : th um , yeah , i guess it 's something i need to play with more to decide how to set that up for the smartkom system . like , may maybe if i trained on six seconds it would work better when i only had two seconds or four seconds , and professor c : yeah . yeah . and , um yeah , and again , if you take this filtering perspective and if you essentially have it build up over time . i mean , if you computed means over two and then over four , and over six , essentially what you 're getting at is a kind of , uh , ramp up of a filter anyway . and so you may may just want to think of it as a filter . but , uh , if you do that , then , um , in practice somebody using the smartkom system , one would think { comment } if they 're using it for a while , it means that their first utterance , instead of , you know , getting , uh , a forty percent error rate reduction , they 'll get a uh , over what , uh , you 'd get without this , uh , um , policy , uh , you get thirty percent . and then the second utterance that you give , they get the full you know , uh , full benefit of it if it 's this ongoing thing . phd a : oh , so you you cache the utterances ? that 's how you get your , uh professor c : well , i 'm saying in practice , yeah , phd a : ah . ok . professor c : that 's if somebody 's using a system to ask for directions or something , you know , they 'll say something first . and and to begin with if it does n't get them quite right , ma m maybe they 'll come back and say , `` excuse me ? `` phd a : mm - hmm . professor c : uh , or some i mean it should have some policy like that anyway . phd a : mm - hmm . professor c : and and , uh , uh , in any event they might ask a second question . and it 's not like what he 's doing does n't , uh , improve things . it does improve things , just not as much as he would like . and so , uh , there 's a higher probability of it making an error , uh , in the first utterance . phd a : what would be really cool is if you could have uh , this probably users would never like this but if you had could have a system where , before they began to use it they had to introduce themselves , verbally . professor c : mm - hmm . phd a : you know . `` hi , my name is so - and - so , professor c : yeah . phd a : i 'm from blah - blah - blah . `` and you could use that initial speech to do all these adaptations and professor c : right . grad e : mm - hmm . professor c : oh , the other thing i guess which which , uh , i do n't know much about as much as i should about the rest of the system but but , um , could n't you , uh , if you if you sort of did a first pass i do n't know what kind of , uh , uh , capability we have at the moment for for doing second passes on on , uh , uh , some kind of little small lattice , or a graph , or confusion network , or something . but if you did first pass with , um , the with either without the mean sub subtraction or with a a very short time one , and then , um , once you , uh , actually had the whole utterance in , if you did , um , the , uh , uh , longer time version then , based on everything that you had , um , and then at that point only used it to distinguish between , you know , top n , um , possible utterances or something , you you might it might not take very much time . i mean , i know in the large vocabulary stu uh , uh , systems , people were evaluating on in the past , some people really pushed everything in to make it in one pass but other people did n't and had multiple passes . and , um , the argument , um , against multiple passes was u u has often been `` but we want to this to be r you know have a nice interactive response `` . and the counterargument to that which , say , uh , bbn i think had , { comment } was `` yeah , but our second responses are second , uh , passes and third passes are really , really fast `` . phd a : mm - hmm . professor c : so , um , if if your second pass takes a millisecond who cares ? um . grad e : s so , um , the the idea of the second pass would be waiting till you have more recorded speech ? or ? professor c : yeah , so if it turned out to be a problem , that you did n't have enough speech because you need a longer longer window to do this processing , then , uh , one tactic is you know , looking at the larger system and not just at the front - end stuff { comment } is to take in , um , the speech with some simpler mechanism or shorter time mechanism , grad e : mm - hmm . professor c : um , do the best you can , and come up with some al possible alternates of what might have been said . and , uh , either in the form of an n - best list or in the form of a lattice , or or confusion network , or whatever . grad e : mm - hmm . professor c : and then the decoding of that is much , much faster or can be much , much faster if it is n't a big bushy network . and you can decode that now with speech that you 've actually processed using this longer time , uh , subtraction . so i mean , it 's it 's common that people do this sort of thing where they do more things that are more complex or require looking over more time , whatever , in some kind of second pass . grad e : mm - hmm . ok . professor c : um , and again , if the second pass is really , really fast uh , another one i 've heard of is is in in connected digit stuff , um , going back and l and through backtrace and finding regions that are considered to be a d a digit , but , uh , which have very low energy . grad e : mm - hmm . ok . professor c : so , uh i mean , there 's lots of things you can do in second passes , at all sorts of levels . anyway , i 'm throwing too many things out . but . phd a : so is that , uh that it ? grad e : i guess that 's it . phd a : ok , uh , do you wan na go , sunil ? phd b : yep . um , so , the last two weeks was , like so i 've been working on that wiener filtering . and , uh , found that , uh , s single like , i just do a s normal wiener filtering , like the standard method of wiener filtering . and that does n't actually give me any improvement over like i mean , uh , b it actually improves over the baseline but it 's not like it does n't meet something like fifty percent or something . so , i 've been playing with the v phd a : improves over the base line mfcc system ? yeah . phd b : yeah . yeah . yeah . so , um so that 's the improvement is somewhere around , like , thirty percent over the baseline . professor c : is that using in combination with something else ? phd b : no , just just one stage wiener filter professor c : with with a phd b : which is a standard wiener filter . professor c : no , no , but i mean in combination with our on - line normalization or with the lda ? phd b : yeah , yeah , yeah , yeah . so i just plug in the wiener filtering . professor c : oh , ok . phd b : i mean , in the s in our system , where phd a : oh , ok . phd b : so , i di i di professor c : so , does it g does that mean it gets worse ? or ? phd b : no . it actually improves over the baseline of not having a wiener filter in the whole system . like i have an lda f lda plus on - line normalization , and then i plug in the wiener filter in that , professor c : yeah ? phd b : so it improves over not having the wiener filter . so it improves but it it does n't take it like be beyond like thirty percent over the baseline . so professor c : but that 's what i 'm confused about , cuz i think i thought that our system was more like forty percent without the wiener filtering . phd b : no , it 's like , uh , phd a : is this with the v new vad ? phd b : well , these are not no , it 's the old vad . so my baseline was , uh , nine this is like w the baseline is ninety - five point six eight , and eighty - nine , and professor c : so i mean , if you can do all these in word errors it 's a lot a lot easier actually . phd b : what was that ? sorry ? professor c : if you do all these in word error rates it 's a lot easier , right ? phd b : oh , ok , ok , ok . errors , right , i do n't have . professor c : ok , cuz then you can figure out the percentages . phd b : it 's all accuracies . professor c : yeah . phd d : the baseline is something similar to a w i mean , the t the the baseline that you are talking about is the mfcc baseline , right ? phd b : the t yeah , there are two baselines . phd d : or ? phd b : ok . so the baseline one baseline is mfcc baseline that when i said thirty percent improvement it 's like mfcc baseline . phd d : mm - hmm . professor c : so so so what 's it start on ? the mfcc baseline is is what ? is at what level ? phd b : it 's the it 's just the mel frequency and that 's it . professor c : no , what 's what 's the number ? phd b : uh , so i i do n't have that number here . ok , ok , ok , i have it here . uh , it 's the vad plus the baseline actually . i 'm talking about the the mfcc plus i do a frame dropping on it . so that 's like the word error rate is like four point three . like ten point seven . professor c : four point three . what 's ten point seven ? phd b : it 's a medium misma ok , sorry . there 's a well ma well matched , medium mismatched , and a high matched . so i do n't have the like the professor c : yeah . phd b : so professor c : ok , four point three , ten point seven , phd b : and forty forty . professor c : and phd b : forty percent is the high mismatch . and that becomes like four point three professor c : not changed . phd b : yeah , it 's like ten point one . still the same . and the high mismatch is like eighteen point five . professor c : eighteen point five . phd b : five . professor c : and what were you just describing ? phd b : oh , the one is this one is just the baseline plus the , uh , wiener filter plugged into it . professor c : but where 's the , uh , on - line normalization and so on ? phd b : oh , ok . so sorry . so , with the with the on - line normalization , the performance was , um , ten ok , so it 's like four point three . uh , and again , that 's the ba the ten point , uh , four and twenty point one . that was with on - line normalization and lda . so the h well matched has like literally not changed by adding on - line or lda on it . but the i mean , even the medium mismatch is pretty much the same . and the high mismatch was improved by twenty percent absolute . professor c : ok , and what kind of number an and what are we talking about here ? phd b : it 's the it - it 's italian . professor c : is this ti - digits phd b : i 'm talking about italian , professor c : or italian ? phd b : yeah . professor c : and what did so , what was the , um , uh , corresponding number , say , for , um , uh , the alcatel system for instance ? phd b : mmm . professor c : do you know ? phd d : yeah , so it looks to be , um phd b : you have it ? phd d : yep , it 's three point four , uh , eight point , uh , seven , and , uh , thirteen point seven . phd b : so thanks . phd d : mm - hmm . phd b : so , uh , this is the single stage wiener filter , with the noise estimation was based on first ten frames . professor c : mm - hmm . phd b : actually i started with using the vad to estimate the noise and then i found that it works it does n't work for finnish and spanish because the vad endpoints are not good to estimate the noise because it cuts into the speech sometimes , so i end up overestimating the noise and getting a worse result . so it works only for italian by u for using a vad to estimate noise . professor c : mm - hmm . phd b : it works for italian because the vad was trained on italian . professor c : mm - hmm . phd b : so , uh so this was , uh and so this was giving um , this this was like not improving a lot on this baseline of not having the wiener filter on it . and , so , uh , i ran this stuff with one more stage of wiener filtering on it but the second time , what i did was i estimated the new wiener filter based on the cleaned up speech , and did , uh , smoothing in the frequency to to reduce the variance professor c : mm - hmm . phd b : i mean , i have i 've i 've observed there are , like , a lot of bumps in the frequency when i do this wiener filtering which is more like a musical noise or something . and so by adding another stage of wiener filtering , the results on the speechdat - car was like , um so , i still do n't have the word error rate . i 'm sorry about it . but the overall improvement was like fifty - six point four six . this was again using ten frames of noise estimate and two stage of wiener filtering . and the rest is like the lda plu and the on - line normalization all remaining the same . uh , so this was , like , compared to , uh , uh fifty - seven is what you got by using the french telecom system , right ? phd d : no , i do n't think so . is it on italian ? phd b : no , this is over the whole speechdat - car . so phd d : oh , yeah , fifty - seven phd b : point phd d : right . phd b : yeah , so the new the new wiener filtering schema is like some fifty - six point four six which is like one percent still less than what you got using the french telecom system . phd d : uh - huh . mm - hmm . professor c : but it 's a pretty similar number in any event . phd b : it 's very similar . professor c : yeah . but again , you 're you 're more or less doing what they were doing , right ? phd b : it 's it 's different in a sense like i 'm actually cleaning up the cleaned up spectrum which they 're not doing . they 're d what they 're doing is , they have two stage stages of estimating the wiener filter , but the final filter , what they do is they they take it to their time domain by doing an inverse fourier transform . professor c : yeah . phd b : and they filter the original signal using that fil filter , professor c : uh - huh . phd b : which is like final filter is acting on the input noisy speech rather than on the cleaned up . so this is more like i 'm doing wiener filter twice , but the only thing is that the second time i 'm actually smoothing the filter and then cleaning up the cleaned up spectrum first level . and so that that 's that 's what the difference is . and actually i tried it on s the original clean i mean , the original spectrum where , like , i the second time i estimate the filter but actually clean up the noisy speech rather the c s first output of the first stage and that does n't seems to be a giving , i mean , that much improvement . i i didn did n't run it for the whole case . and and what i t what i tried was , by using the same thing but uh , so we actually found that the vad is very , like , crucial . i mean , just by changing the vad itself gives you the a lot of improvement professor c : mm - hmm . phd b : by instead of using the current vad , if you just take up the vad output from the channel zero , { comment } when instead of using channel zero and channel one , because that was the p that was the reason why i was not getting a lot of improvement for estimating { comment } the noise . so i just used the channel zero vad to estimate the noise so that it gives me some reliable mar markers for this noise estimation . professor c : what 's a channel zero vad ? i 'm i 'm confused about that . phd b : so , it 's like phd d : so it 's the close - talking microphone . phd b : yeah , the close - talking without professor c : oh , oh , oh , oh . phd b : so because the channel zero and channel one are like the same speech , but only w i mean , the same endpoints . but the only thing is that the speech is very noisy for channel one , so you can actually use the output of the channel zero for channel one for the vad . i mean , that 's like a cheating method . professor c : right . i mean , so a are they going to pro what are they doing to do , do we know yet ? about as far as what they 're what the rules are going to be and what we can use ? phd d : yeah , so actually i received a a new document , describing this . phd b : yeah , that 's phd d : and what they did finally is to , mmm , uh , not to align the utterances but to perform recognition , um , only on the close - talking microphone , phd b : which is the channel zero . phd d : and to take the result of the recognition to get the boundaries uh , of speech . professor c : so it 's not like that 's being done in one place or one time . phd d : and professor c : that 's that 's just a rule and we 'd you you were permitted to do that . is is that it ? phd d : uh , i think they will send , um , files but we we do n't well , apparently professor c : oh , so they will send files so everybody will have the same boundaries to work with ? phd d : yeah . yeah . phd b : but actually their alignment actually is not seems to be improving in like on all cases . phd d : oh , i yeah , so what happened here is that , um , the overall improvement that they have with this method so well , to be more precise , what they have is , they have these alignments and then they drop the beginning silence and and the end silence but they keep , uh , two hundred milliseconds before speech and two hundred after speech . and they keep the speech pauses also . um , and the overall improvement over the mfcc baseline so , when they just , uh , add this frame dropping in addition it 's r uh , forty percent , right ? professor c : mm - hmm . phd d : fourteen percent , i mean . professor c : mm - hmm . phd b : yeah , which is phd d : um , which is , um , t which is the overall improvement . but in some cases it does n't improve at all . like , uh , y do you remember which case ? professor c : mm - hmm . phd b : it gives like negative well , in in like some italian and ti - digits , phd d : yeah , some @ @ . phd b : right ? phd d : right . phd b : yeah . so by using the endpointed speech , actually it 's worse than the baseline in some instances , which could be due to the word pattern . phd d : mmm . yeah . professor c : yeah , phd d : and yeah , the other thing also is that fourteen percent is less than what you obtain using a real vad . phd b : yeah , our neural net phd d : so with without cheating like this . phd b : yeah , yeah . phd d : so uh so i think this shows that there is still work uh , well , working on the vad is still still important i think . professor c : yeah , c phd d : uh phd a : can i ask just a a high level question ? can you just say like one or two sentences about wiener filtering and why why are people doing that ? what 's what 's the deal with that ? phd b : ok , so the wiener filter , it 's it 's like it 's like you try to minimize i mean , so the basic principle of wiener filter is like you try to minimize the , uh , d uh , difference between the noisy signal and the clean signal if you have two channels . like let 's say you have a clean t signal and you have an additional channel where you know what is the noisy signal . phd a : mm - hmm . phd b : and then you try to minimize the error between these two . phd a : mm - hmm . phd b : so that 's the basic principle . and you get you can do that i mean , if if you have only a c noisy signal , at a level which you , you w try to estimate the noise from the w assuming that the first few frames are noise or if you have a w voice activity detector , uh , you estimate the noise spectrum . phd a : mm - hmm . phd b : and then you phd a : do you assume the noise is the same ? phd b : yeah . in yeah , after the speech starts . phd a : uh - huh . phd b : so but that 's not the case in , uh , many many of our cases but it works reasonably well . phd a : i see . phd b : and and then you what you do is you , uh b fff . so again , i can write down some of these eq oh , ok . yeah . and then you do this uh , this is the transfer function of the wiener filter , so `` sf `` is a clean speech spectrum , power spectrum phd a : mm - hmm . phd b : and `` n `` is the noisy power spectrum . and so this is the transfer function . professor c : actually , i guess phd b : yeah . professor c : yeah . phd b : and then you multiply your noisy power spectrum with this . you get an estimate of the clean power spectrum . phd a : i see . ok . phd b : so but the thing is that you have to estimate the sf from the noisy spectrum , what you have . so you estimate the nf from the initial noise portions and then you subtract that from the current noisy spectrum to get an estimate of the sf . so sometimes that becomes zero because you do you do n't have a true estimate of the noise . so the f filter will have like sometimes zeros in it phd a : mm - hmm . phd b : because some frequency values will be zeroed out because of that . and that creates a lot of discontinuities across the spectrum because @ @ the filter . so , uh , so that 's what that was just the first stage of wiener filtering that i tried . phd a : so is this , um , basically s uh , similar to just regular spectral subtraction ? phd b : it professor c : it 's all pretty related , phd b : yeah . professor c : yeah . it 's it 's there 's a di there 's a whole class of techniques where you try in some sense to minimize the noise . phd a : uh - huh . professor c : and it 's typically a mean square sense , uh uh uh , i in in in some way . and , uh uh , spectral subtraction is is , uh uh , one approach to it . phd a : do people use the wiener filtering in combination with the spectral subtraction typically , or is i are they sort of competing techniques ? phd b : not seen . they are very s similar techniques . phd a : yeah . o oh , ok . phd b : so it 's like i have n't seen anybody using s wiener filter with spectral subtraction . phd d : mm - hmm . phd a : i see , i see . professor c : i mean , in the long run you 're doing the same thing phd a : mm - hmm . phd b : yeah . professor c : but y but there you make different approximations , and in spectral subtraction , for instance , there 's a a an estimation factor . you sometimes will figure out what the noise is and you 'll multiply that noise spectrum times some constant and subtract that rather than and sometimes people even though this really should be in the power domain , sometimes people s work in the magnitude domain because it it it works better . phd a : mm - hmm . professor c : and , uh , uh , you know . phd a : so why did you choose , uh , wiener filtering over some other one of these other techniques ? phd b : uh , the reason was , like , we had this choice of using spectral subtraction , wiener filtering , and there was one more thing which i which i 'm trying , is this sub space approach . so , stephane is working on spectral subtraction . phd a : oh , ok . phd b : so i picked up phd a : so you 're sort of trying @ @ them all . phd b : y yeah , we just wanted to have a few noise production compensation techniques phd a : i see . oh , ok . phd b : and then pick some from that phd a : mm - hmm . phd b : pick one . professor c : i m i mean yeah , i mean , there 's car - carmen 's working on another , on the vector taylor series . phd b : va yeah , vad . w yeah . professor c : so they were just kind of trying to cover a bunch of different things with this task and see , you know , what are what are the issues for each of them . phd a : ah , ok . that makes sense . phd b : yeah . phd a : yeah . mm - hmm . mm - hmm . cool , thanks . phd b : so so one of one of the things that i tried , like i said , was to remove those zeros in the fri filter by doing some smoothing of the filter . professor c : yeah . phd a : mm - hmm . phd b : like , you estimate the edge of square and then you do a f smoothing across the frequency so that those zeros get , like , flattened out . phd a : mm - hmm . phd b : and that does n't seems to be improving by trying it on the first time . so what i did was like i p did this and then you i plugged in the one more the same thing but with the smoothed filter the second time . phd a : mm - hmm . phd b : and that seems to be working . phd a : mm - hmm . phd b : so that 's where i got like fifty - six point five percent improvement on speechdat - car with that . and so the other thing what i tried was i used still the ten frames of noise estimate but i used this channel zero vad to drop the frames . so i 'm not still not estimating . and that has taken the performance to like sixty - seven percent in speechdat - car , which is which which like sort of shows that by using a proper vad you can just take it to further , better levels . and so . phd a : so that 's sort of like , you know , best - case performance ? phd b : yeah , so far i 've seen sixty - seven i mean , no , i have n't seen s like sixty - seven percent . and , uh , using the channel zero vad to estimate the noise also seems to be improving but i do n't have the results for all the cases with that . so i used channel zero vad to estimate noise as a lesser 2 x frame , which is like , everywhere i use the channel zero vad . and that seems to be the best combination , uh , rather than using a few frames to estimate and then drop a channel . professor c : so i 'm i 'm still a little confused . is that channel zero information going to be accessible during this test . phd b : nnn , no . this is just to test whether we can really improve by using a better vad . professor c : mm - hmm . mm - hmm . phd b : i mean so this is like the noise compensation f is fixed phd d : mm - hmm . phd b : but you make a better decision on the endpoints . that 's , like seems to be professor c : mm - hmm . phd b : so we c so i mean , which which means , like , by using this technique what we improve just the vad we can just take the performance by another ten percent or better . so , that that was just the , uh , reason for doing that experiment . and , w um yeah , but this all these things , i have to still try it on the ti - digits , which is like i 'm just running . and there seems to be not improving a a lot on the ti - digits , so i 'm like investigating that , why it 's not . and , um , um well after that . so , uh so the other the other thing is like i 've been i 'm doing all this stuff on the power spectrum . so tried this stuff on the mel as well mel and the magnitude , and mel magnitude , and all those things . but it seems to be the power spectrum seems to be getting the best result . so , one of one of reasons i thought like doing the averaging , after the filtering using the mel filter bank , that seems to be maybe helping rather than trying it on the mel filter ba filtered outputs . professor c : mm - hmm . mm - hmm . phd b : so just th professor c : ma makes sense . phd b : yeah , th that 's that 's the only thing that i could think of why why it 's giving improvement on the mel . and , yep . so that 's it . professor c : uh , how about the subspace stuff ? phd b : subspace , { comment } i 'm i 'm like that 's still in a little bit in the back burner because i 've been p putting a lot effort on this to make it work , on tuning things and other stuff . so i was like going parallely but not much of improvement . i 'm just have some skeletons ready , need some more time for it . phd a : tha - that it ? phd b : yep . yep . phd a : cool . do you wan na go , stephane ? phd d : uh , yeah . so , i 've been , uh , working still on the spectral subtraction . um , so to r to remind you a little bit of of what i did before , is just to apply some spectral subtraction with an overestimation factor also to get , um , an estimate of the noise , uh , spectrum , and subtract this estimation of the noise spectrum from the , uh , signal spectrum , { comment } but subtracting more when the snr is is , uh , low , which is a technique that it 's often used . phd a : `` subtracting more `` , meaning ? phd d : so you overestimate the noise spectrum . you multiply the noise spectrum by a factor , uh , which depends on the snr . phd a : oh , ok . i see . phd d : so , above twenty db , it 's one , so you just subtract the noise . phd a : mm - hmm . phd d : and then it 's b generally well , i use , actually , a linear , uh , function of the snr , phd a : mm - hmm . phd d : which is bounded to , like , two or three , { comment } when the snr is below zero db . phd a : mm - hmm . mm - hmm . phd d : um , doing just this , uh , either on the fft bins or on the mel bands , um , t does n't yield any improvement professor c : oh ! um , uh , what are you doing with negative , uh , powers ? phd d : o yeah . so there is also a threshold , of course , because after subtraction you can have negative energies , phd a : mm - hmm . phd d : and so what i i just do is to put , uh to to add to put the threshold first and then to add a small amount of noise , which right now is speech - shaped . um phd a : speech - shaped ? phd d : yeah , so it 's a it has the overall overall energy , uh pow it has the overall power spectrum of speech . so with a bump around one kilohertz . phd a : so when y when you talk about there being something less than zero after subtracting the noise , is that at a particular frequency bin ? phd d : i uh - huh . yeah . there can be frequency bins with negative values . phd a : and so when you say you 're adding something that has the overall shape of speech , is that in a in a particular frequency bin ? or you 're adding something across all the frequencies when you get these negatives ? phd d : for each frequencies i a i 'm adding some , uh , noise , but the a the amount of the amount of noise i add is not the same for all the frequency bins . phd a : ah ! ok . i gotcha . right . phd d : uh . right now i do n't think if it makes sense to add something that 's speech - shaped , because then you have silence portion that have some spectra similar to the sp the overall speech spectra . phd a : mm - hmm . phd d : but yeah . so this is something i can still work on , phd a : so what does that mean ? phd d : but hmm . phd a : i 'm trying to understand what it means when you do the spectral subtraction and you get a negative . it means that at that particular frequency range you subtracted more energy than there was actually phd d : that means that mm - hmm . yeah . so so yeah , you have an an estimation of the noise spectrum , but sometimes , of course , it 's as the noise is not perfectly stationary , sometimes this estimation can be , uh , too small , so you do n't subtract enough . but sometimes it can be too large also . if if the noise , uh , energy in this particular frequency band drops for some reason . phd a : mm - hmm . mm - hmm . so in in an ideal word i world { comment } if the noise were always the same , then , when you subtracted it the worst that i you would get would be a zero . i mean , the lowest you would get would be a zero , cuz i if there was no other energy there you 're just subtracting exactly the noise . professor c : right . phd d : mm - hmm , professor c : yep , there 's all there 's all sorts of , uh , deviations from the ideal here . phd d : yeah . professor c : i mean , for instance , you 're you 're talking about the signal and noise , um , at a particular point . and even if something is sort of stationary in ster terms of statistics , there 's no guarantee that any particular instantiation or piece of it is exactly a particular number or bounded by a particular range . phd d : mm - hmm . professor c : so , you 're figuring out from some chunk of of of the signal what you think the noise is . then you 're subtracting that from another chunk , phd a : mm - hmm . professor c : and there 's absolutely no reason to think that you 'd know that it would n't , uh , be negative in some places . phd d : mm - hmm . hmm . professor c : uh , on the other hand that just means that in some sense you 've made a mistake because you certainly have stra subtracted a bigger number than is due to the noise . phd a : mm - hmm . professor c : um also , we speak the whole where all this stuff comes from is from an assumption that signal and noise are uncorrelated . and that certainly makes sense in s in in a statistical interpretation , that , you know , over , um , all possible realizations that they 're uncorrelated phd a : mm - hmm . professor c : or assuming , uh , ergodicity that i that i um , across time , uh , it 's uncorrelated . but if you just look at a quarter second , uh , and you cross - multiply the two things , uh , you could very well , uh , end up with something that sums to something that 's not zero . so in fact , the two signals could have some relation to one another . and so there 's all sorts of deviations from ideal in this . and and given all that , you could definitely end up with something that 's negative . but if down the road you 're making use of something as if it is a power spectrum , um , then it can be bad to have something negative . now , the other thing i wonder about actually is , what if you left it negative ? what happens ? phd b : is that the log ? professor c : i mean , because um , are you taking the log before you add them up to the mel ? phd b : after that . no , after . professor c : right . so the thing is , i wonder how if you put your thresholds after that , i wonder how often you would end up with , uh with negative values . phd b : but you will but you end up reducing some neighboring frequency bins @ @ in the average , right ? when you add the negative to the positive value which is the true estimate . professor c : yeah . but nonetheless , uh , you know , these are it 's another f kind of smoothing , right ? that you 're doing . phd b : yeah . professor c : right . so , you 've done your best shot at figuring out what the noise should be , and now i then you 've subtracted it off . and then after that , instead of instead of , uh , uh , leaving it as is and adding things adding up some neighbors , you artificially push it up . which is , you know , it 's there 's no particular reason that that 's the right thing to do either , right ? phd b : yeah , yeah . professor c : so , um , uh , i in fact , what you 'd be doing is saying , `` well , we 're d we 're we 're going to definitely diminish the effect of this frequency in this little frequency bin in the in the overall mel summation `` . it 's just a thought . i d i do n't know if it would be phd a : sort of the opposite of that would be if if you find out you 're going to get a negative number , you do n't do the subtraction for that bin . phd b : yeah . uh - huh . that is true . professor c : nnn , yeah , phd d : mm - hmm . professor c : although phd a : that would be almost the opposite , right ? instead of leaving it negative , you do n't do it . if your if your subtraction 's going to result in a negative number , you you do n't do subtraction in that . professor c : yeah , but that means that in a situation where you thought that that the bin was almost entirely noise , you left it . phd a : yeah . yeah , i 'm just saying that 's like the opposite . phd b : we just yeah . professor c : yeah . phd a : yeah . professor c : well , yeah that 's that 's the opposite , phd d : mm - hmm . professor c : yeah . phd d : and , yeah , some people also if it 's a negative value they , uh , re - compute it using inter interpolation from the edges and bins . phd b : for frames , frequency bins . professor c : yeah . phd d : well , there are different things that you can do . professor c : people can also , uh , reflect it back up and essentially do a full wave rectification instead of a instead of half wave . but it was just a thought that that it might be something to try . phd d : mm - hmm . mm - hmm . yep . well , actually i tried , something else based on this , um , is to to put some smoothing , um , because it seems to to help or it seems to help the wiener filtering professor c : mm - hmm . phd d : and , mmm so what i did is , uh , some kind of nonlinear smoothing . actually i have a recursion that computes yeah , let me go back a little bit . actually , when you do spectral subtraction you can , uh , find this this equivalent in the s in the spectral domain . you can uh compute , y you can say that d your spectral subtraction is a filter , um , and the gain of this filter is the , um , signal energy minus what you subtract , divided by the signal energy . and this is a gain that varies over time , and , you know , of course , uh , depending on the s on the noise spectrum and on the speech spectrum . and what happen actually is that during low snr values , the gain is close to zero but it varies a lot . mmm , and this this is the cause of musical noise and all these the { comment } the fact you we go below zero one frame and then you can have an energy that 's above zero . professor c : mm - hmm . phd d : and mmm . so the smoothing is i did a smoothing actually on this gain , uh , trajectory . but it 's the smoothing is nonlinear in the sense that i tried to not smooth if the gain is high , because in this case we know that , uh , the estimate of the gain is correct because we we are not close to to to zero , um , and to do more smoothing if the gain is low . mmm . um . yeah . so , well , basically that 's this idea , and it seems to give pretty good results , uh , although i 've just just tested on italian and finnish . and on italian it seems my result seems to be a little bit better than the wiener filtering , phd b : mm - hmm . yeah , the one you showed yesterday . phd d : right ? phd b : right ? professor c : yeah . phd d : uh , i do n't know if you have these improvement the detailed improvements for italian , finnish , and spanish there phd b : fff . no , i do n't have , for each , phd d : or you have just have your own . phd b : i i just just have the final number here . phd d : mm - hmm . professor c : so these numbers he was giving before with the four point three , and the ten point one , and so forth , those were italian , right ? phd b : yeah , yeah , yeah . so so , no , professor c : yeah . phd d : uh phd b : i actually did n't give you the number which is the final one , phd d : uh , no , we 've phd b : which is , after two stages of wiener filtering . i mean , that was i just well , like the overall improvement is like fifty - six point five . so , professor c : right . phd d : mm - hmm . phd b : i mean , his number is still better than what i got in the two stages of wiener filtering . phd d : yeah . professor c : right . phd d : on italian . but on finnish it 's a little bit worse , apparently . phd b : mm - hmm . phd d : um professor c : but do you have numbers in terms of word error rates on on italian ? so just so you have some sense of reference ? phd d : yeah . uh , so , it 's , uh , three point , uh , eight . professor c : uh - huh . phd d : am i right ? phd b : oh , ok . yeah , right , ok . phd d : and then , uh , d uh , nine point , uh , one . professor c : mm - hmm . phd d : and finally , uh , sixteen point five . professor c : and this is , um , spectral subtraction plus what ? phd d : plus plus nonlinear smoothing . well , it 's the system it 's exactly the sys the same system as sunil tried , professor c : on - line normalization and lda ? phd d : but professor c : yeah . yeah . phd d : yeah . but instead of double stage wiener filtering , it 's it 's this smoothed spectral subtraction . um , yeah . phd a : what is it the , um , france telecom system uses professor c : right . phd a : for do they use spectral subtraction , or wiener filtering , or ? phd b : they use spectral subtraction , right . phd d : for what ? phd b : french telecom . phd d : it it 's wiener filtering , phd b : oh , it 's it 's wiener filtering . phd d : am i right ? phd b : sorry . phd d : well , it 's some kind of wiener filtering phd b : yeah , filtering . yeah , it 's not exactly wiener filtering but some variant of wiener filtering . phd d : yeah . phd a : i see . phd b : yeah . professor c : yeah , plus , uh , i guess they have some sort of cepstral normalization , as well . phd b : s they have like yeah , th the just noise compensation technique is a variant of wiener filtering , phd d : mm - hmm . phd b : plus they do some some smoothing techniques on the final filter . the th they actually do the filtering in the time domain . phd d : yeah . phd b : so they would take this hf squared back , taking inverse fourier transform . and they convolve the time domain signal with that . phd a : oh , i see . phd b : and they do some smoothing on that final filter , impulse response . phd d : but they also have two two different smoothing @ @ . phd b : i mean , i 'm i 'm @ @ . phd d : one in the time domain and one in the frequency domain by just taking the first , um , coefficients of the impulse response . so , basically it 's similar . i mean , what you did , it 's similar phd b : it 's similar in the smoothing and phd d : because you have also two two kind of smoothing . phd b : yeah . phd d : one in the time domain , and one in the frequency domain , phd b : yeah . the frequency domain . phd d : yeah . phd a : does the smoothing in the time domain help phd d : um phd a : well , do you get this musical noise stuff with wiener filtering or is that only with , uh , spectral subtraction ? phd b : no , you get it with wiener filtering also . phd d : yeah . phd a : does the smoothing in the time domain help with that ? or some other smoothing ? phd b : oh , no , you still end up with zeros in the s spectrum . sometimes . phd d : yeah . professor c : i mean , it 's not clear that these musical noises hurt us in recognition . we do n't know if they do . phd b : yeah . professor c : i mean , they they sound bad . phd a : mm - hmm . phd b : yeah , i know . professor c : but we 're not listening to it , usually . phd d : mm - hmm . uh , actually the the smoothing that i did do here reduced the musical noise . well , it phd b : mm - hmm . yeah , yeah , the phd d : well , i can not you can not hear beca well , actually what i d did not say is that this is not in the fft bins . this is in the mel frequency bands . um so , it could be seen as a f a a smoothing in the frequency domain because i used , in ad mel bands in addition and then the other phase of smoothing in the time domain . mmm . but , when you look at the spectrogram , if you do n't have an any smoothing , you clearly see , like in silence portions , and at the beginning and end of speech , you see spots of high energy randomly distributed over the the spectrogram . phd a : mm - hmm . mm - hmm . phd d : um phd a : that 's the musical noise ? phd d : which is musical noise , phd a : mm - hmm . phd d : yeah , if if it if you listen to it uh , if you do this in the fft bins , then you have spots of energy randomly distributing . and if you f if you re - synthesize these spot sounds as , like , sounds , phd a : mm - hmm . phd d : uh professor c : well , none of these systems , by the way , have i mean , y you both are are working with , um , our system that does not have the neural net , phd d : and professor c : right ? phd b : yeah . phd d : mm - hmm . professor c : ok . so one would hope , presumably , that the neural net part of it would would improve things further as as they did before . phd d : yeah . yeah . um yeah , although if if we , um , look at the result from the proposals , { comment } one of the reason , uh , the n system with the neural net was , um , more than well , around five percent better , is that it was much better on highly mismatched condition . i 'm thinking , for instance , on the ti - digits trained on clean speech and tested on noisy speech . professor c : mm - hmm . phd d : uh , for this case , the system with the neural net was much better . professor c : mm - hmm . phd d : but not much on the in the other cases . professor c : yeah . phd d : and if we have no , uh , spectral subtraction or wiener filtering , um , i the system is uh , we thought the neural neural network is much better than before , even in these cases of high mismatch . so , maybe the neural net will help less but , um professor c : maybe . phd a : could you train a neural net to do spectral subtraction ? professor c : yeah , it could do a nonlinear spectral subtraction phd d : mm - hmm . professor c : but i do n't know if it i mean , you have to figure out what your targets are . phd a : yeah , i was thinking if you had a clean version of the signal and and a noisy version , and your targets were the m f - uh , you know , whatever , frequency bins phd d : mm - hmm . professor c : right . phd d : mm - hmm . professor c : yeah , well , that 's not so much spectral subtraction then , phd d : mm - hmm . professor c : but but but it 's but at any rate , yeah , people , uh phd a : people do that ? professor c : y yeah , in fact , we had visitors here who did that i think when you were here ba way back when . phd d : mm - hmm . professor c : uh , people d done lots of experimentation over the years with training neural nets . and it 's not a bad thing to do . it 's another approach . m i mean , it 's it , um phd d : mm - hmm . professor c : the objection everyone always raises , which has some truth to it is that , um , it 's good for mapping from a particular noise to clean but then you get a different noise . phd a : mm - hmm . professor c : and the experiments we saw that visitors did here showed that it there was at least some , um , { comment } gentleness to the degradation when you switched to different noises . it did seem to help . so that you 're right , that 's another another way to go . phd a : how did it compare on i mean , for for good cases where it it uh , stuff that it was trained on ? did it do pretty well ? professor c : oh , yeah , it did very well . yeah . phd d : mm - hmm . professor c : but to some extent that 's kind of what we 're doing . i mean , we 're not doing exactly that , we 're not trying to generate good examples but by trying to do the best classifier you possibly can , for these little phonetic categories , phd a : mm - hmm . you could say it 's sort of built in . professor c : it 's yeah , it 's kind of built into that . and and that 's why we have found that it it does help . phd a : mm - hmm . professor c : um so , um , yeah , i mean , we 'll just have to try it . but i i would i would i would imagine that it will help some . i mean , it we 'll just have to see whether it helps more or less the same , but i would imagine it would help some . phd d : mm - hmm . professor c : so in any event , all of this i was just confirming that all of this was with a simpler system . phd d : yeah , yeah . um , yeah , so this is th the , um well , actually , this was kind of the first try with this spectral subtraction plus smoothing , professor c : mm - hmm . phd d : and i was kind of excited by the result . professor c : mm - hmm . phd d : um , then i started to optimize the different parameters . and , uh , the first thing i tried to optimize is the , um , time constant of the smoothing . and it seems that the one that i chose for the first experiment was the optimal one , so uh , professor c : it 's amazing how often that happens . phd d : um , so this is the first thing . um yeah , another thing that i it 's important to mention is , um , that this has a this has some additional latency . um . because when i do the smoothing , uh , it 's a recursion that estimated the means , so of the g of the gain curve . and this is a filter that has some latency . and i noticed that it 's better if we take into account this latency . so , instead o of using the current estimated mean to , uh , subtract the current frame , it 's better to use an estimate that 's some somewhere in the future . um phd a : and that 's what causes the latency ? ok . phd b : you mean , the m the mean is computed o based on some frames in the future also ? professor c : mm - hmm . phd d : yeah . phd b : or or no ? phd d : it 's the recursion , so it 's it 's the center recursion , right ? phd b : mm - hmm . phd d : um and the latency of this recursion is around fifty milliseconds . professor c : one five ? one five ? five zero ? phd d : five zero , professor c : five zero . phd d : yeah . professor c : yeah . phd b : i 'm sorry , why why is that delay coming ? like , you estimate the mean ? phd d : yeah , the mean estimation has some delay , right ? phd b : oh , yeah . phd d : i mean , the the filter that that estimates the mean has a time constant . phd b : it is n't ok , so it 's like it looks into the future also . ok . phd d : yeah . professor c : what if you just look into the past ? phd d : it 's , uh , not as good . it 's not bad . professor c : how m by how much ? phd d : um , it helps a lot over the ba the baseline but , mmm professor c : by how much ? phd d : it it 's around three percent , um , relative . professor c : worse . phd d : yeah . yeah . um , mmm so , uh professor c : it 's depending on how all this stuff comes out we may or may not be able to add any latency . phd d : yeah , but yeah . so , yeah , it depends . uh , y actually , it 's it 's l it 's three percent . right . mmm . yeah , b but i do n't think we have to worry too much on that right now while you kno . mm - hmm . professor c : um , s yeah , i mean , i think the only thing is that phd d : so professor c : i would worry about it a little . phd d : mm - hmm . professor c : because if we completely ignore latency , and then we discover that we really have to do something about it , we 're going to be find ourselves in a bind . phd d : mm - hmm . professor c : so , um , you know , maybe you could make it twenty - five . you know what i mean ? phd d : yeah . professor c : yeah , just , you know , just be be a little conservative phd d : oh yes . professor c : because we may end up with this crunch where all of a sudden we have to cut the latency in half or something . phd d : s mm - hmm . yeah . um . so , yeah , there are other things in the , um , algorithm that i did n't , uh , @ @ a lot yet , which phd a : sorry . a quick question just about the latency thing . if if there 's another part of the system that causes a latency of a hundred milliseconds , is this an additive thing ? or c or is yours hidden in that ? phd d : mm - hmm . phd a : uh phd d : no , it 's it 's added . phd a : it 's additive . ok . phd d : mm - hmm . phd b : we can ok . we can do something in parallel also , in some like some cases like , if you wanted to do voice activity detection . phd a : uh - huh . phd b : and we can do that in parallel with some other filtering you can do . so you can make a decision on that voice activity detection and then you decide whether you want to filter or not . phd d : yeah . phd b : but by then you already have the sufficient samples to do the filtering . phd a : mm - hmm . phd b : so so , sometimes you can do it anyway . phd a : i mean , could n't , uh i could n't you just also i mean , i if you know that the l the largest latency in the system is two hundred milliseconds , do n't you could n't you just buffer up that number of frames and then everything uses that buffer ? phd b : yeah . phd a : and that way it 's not additive ? professor c : well , in fact , everything is sent over in buffers cuz of is n't it the tcp buffer some ? phd b : you mean , the the data , the super frame or something ? phd d : mm - hmm . professor c : yeah , yeah . phd d : yeah . phd b : yeah , but that has a variable latency because the last frame does n't have any latency phd d : mm - hmm . phd b : and first frame has a twenty framed latency . so you ca n't r rely on that latency all the time . professor c : yeah . phd b : because i mean the transmission over over the air interface is like a buffer . phd d : yeah . phd b : twenty frame phd a : yeah . phd b : twenty four frames . phd a : yeah . phd b : so but the only thing is that the first frame in that twenty - four frame buffer has a twenty - four frame latency . and the last frame does n't have any latency . phd a : mm - hmm . phd b : because it just goes as phd a : yeah , i was n't thinking of that one in particular phd b : yeah . phd a : but more of , you know , if if there is some part of your system that has to buffer twenty frames , uh , ca n't the other parts of the system draw out of that buffer and therefore not add to the latency ? professor c : yeah . yeah . and and that 's sort of one of the all of that sort of stuff is things that they 're debating in their standards committee . phd a : oh ! hmm . phd d : mm - hmm . yeah . so , um , there is uh , { comment } these parameters that i still have to to look at . like , i played a little bit with this overestimation factor , uh , but i still have to to look more at this , um , at the level of noise i add after . uh , i know that adding noise helped , um , the system just using spectral subtraction without smoothing , but i do n't know right now if it 's still important or not , and if the level i choose before is still the right one . same thing for the shape of the the noise . maybe it would be better to add just white noise instead of speech shaped noise . professor c : that 'd be more like the jrasta thing in a sense . yeah . phd d : mm - hmm . um , yep . uh , and another thing is to yeah , for this i just use as noise estimate the mean , uh , spectrum of the first twenty frames of each utterance . i do n't remember for this experiment what did you use for these two stage phd b : i used ten just ten frames . yeah , because phd d : the ten frames ? phd b : i mean , the reason was like in ti - digits i do n't have a lot . i had twenty frames most of the time . phd d : mm - hmm . um . but , so what 's this result you told me about , the fact that if you use more than ten frames you can improve by t phd b : well , that 's that 's using the channel zero . if i use a channel zero vad to estimate the noise . phd d : oh , ok . phd b : which phd d : but this is ten frames plus plus phd b : channel zero dropping . phd d : channel uh , no , these results with two stage wiener filtering is ten frames phd b : t oh , this phd d : but possibly more . i mean , if channel one vad gives you phd b : f yeah . mm - hmm . yeah . phd d : yeah . ok . yeah , but in this experiment i did i did n't use any vad . i just used the twenty first frame to estimate the noise . and so i expected it to be a little bit better , if , uh , i use more more frames . um . ok , that 's it for spectral subtraction . the second thing i was working on is to , um , try to look at noise estimation , { comment } mmm , and using some technique that does n't need voice activity detection . um , and for this i u simply used some code that , uh , i had from from belgium , which is technique that , um , takes a bunch of frame , um , and for each frequency bands of this frame , takes a look at the minima of the energy . and then average these minima and take this as an an energy estimate of the noise for this particular frequency band . and there is something more to this actually . what is done is that , uh , these minima are computed , um , based on , um , high resolution spectra . so , i compute an fft based on the long , uh , signal frame which is sixty - four millisecond phd a : so you have one minimum for each frequency ? phd d : what what i what i d uh , i do actually , is to take a bunch of to take a tile on the spectrogram and this tile is five hundred milliseconds long and two hundred hertz wide . and this tile uh , in this tile appears , like , the harmonics if you have a voiced sound , because it 's it 's the ftt bins . and when you take the m the minima of of these this tile , when you do n't have speech , these minima will give you some noise level estimate , if you have voiced speech , these minima will still give you some noise estimate because the minima are between the harmonics . and if you have other other kind of speech sounds then it 's not the case , but if the time frame is long enough , uh , like s five hundred milliseconds seems to be long enough , { comment } you still have portions which , uh , are very close whi which minima are very close to the noise energy . professor c : i 'm confused . you said five hundred milliseconds but you said sixty - four milliseconds . which is which ? what ? phd d : sixty - four milliseconds is to compute the fft , uh , bins . professor c : yeah , phd d : the the fft . professor c : yeah . phd d : um , actually it 's better to use sixty - four milliseconds because , um , if you use thirty milliseconds , then , uh , because of the this short windowing and at low pitch , uh , sounds , the harmonics are not , wha uh , correctly separated . professor c : mm - hmm . phd d : so if you take these minima , it b they will overestimate the noise a lot . professor c : so you take sixty - four millisecond f f ts and then you average them { comment } over five hundred ? or ? uh , what do you do over five hundred ? phd d : so i take to i take a bunch of these sixty - four millisecond frame to cover five hundred milliseconds , professor c : ah . ok . phd d : and then i look for the minima , professor c : i see . phd d : on the on on the bunch of uh fifty frames , right ? professor c : i see . phd d : mmm . so the interest of this is that , as y with this technique you can estimate u some reasonable noise spectra with only five hundred milliseconds of of signal , so if the the n the noise varies a lot , uh , you can track better track the noise , professor c : mm - hmm . phd d : which is not the case if you rely on the voice activity detector . so even if there are no no speech pauses , you can track the noise level . the only requirement is that you must have , in these five hundred milliseconds segment , { comment } you must have voiced sound at least . cuz this these will help you to to track the the noise level . um . so what i did is just to simply replace the vad - based , uh , noise estimate by this estimate , first on speechdat - car well , only on speechdat - car actually . and it 's , uh , slightly worse , like one percent relative compared to the vad - based estimates . um , i think the reason why it 's not better , is that the speechdat - car noises are all stationary . um . so , u y y there really is no need to have something that 's adaptive professor c : mm - hmm . phd d : and uh , well , they are mainly stationary . um . but , i expect s maybe some improvement on ti - digits because , nnn , in this case the noises are all sometimes very variable . uh , so i have to test it . mmm . professor c : but are you comparing with something e i 'm i 'm p s a little confused again , i it uh , when you compare it with the v a d - based , phd d : mm - hmm . professor c : vad - is this is this the ? phd d : it 's it 's the france - telecom - based spectra , s uh , wiener filtering and vad . so it 's their system but just i replace their noise estimate by this one . professor c : oh , you 're not doing this with our system ? phd d : in i i 'm not no , no . yeah , it 's our system but with just the wiener filtering from their system . right ? mmm . yeah . actually , th the best system that we still have is , uh , our system but with their noise compensation scheme , right ? professor c : right . but phd d : so i 'm trying to improve on this , and by by replacing their noise estimate by , uh , something that might be better . professor c : ok . but the spectral subtraction scheme that you reported on also re requires a a noise estimate . phd d : yeah . yeah . professor c : could n't you try this for that ? phd d : but i di professor c : do you think it might help ? phd d : not yet , because i did this in parallel , professor c : i see , phd d : and i was working on one and the other . professor c : i see . yeah . phd b : yeah . phd d : yeah , for for sure i will . i can try also , mmm , the spectral subtraction . phd b : so i 'm also using that n new noise estimate technique on this wiener filtering what i 'm trying . so i i have , like , some experiments running , i do n't have the results . phd d : mm - hmm . professor c : yeah . yeah . phd b : i do n't estimate the f noise on the ten frames but use his estimate . professor c : yeah . phd d : mm - hmm . um . yeah . i , um , also implemented a sp um spectral whitening idea which is in the , um , ericsson proposal . uh , the idea is just to um , flatten the log , uh , spectrum , um , and to flatten it more if the the probability of silence is higher . so in this way , you can also reduce somewhat reduce the musical noise and you reduce the variability if you have different noise shapes , because the the spectrum becomes more flat in the silence portions . um . yeah . with this , no improvement , uh , but there are a lot of parameters that we can play with and , um actually , this this could be seen as a soft version of the frame dropping because , um , you could just put the threshold and say that `` below the threshold , i will flatten comp completely flatten the the spectrum `` . and above this threshold , uh , keep the same spectrum . so it would be like frame dropping , because during the silence portions which are below the threshold of voice activity probability , { comment } uh , w you would have some kind of dummy frame which is a perfectly flat spectrum . and this , uh , whitening is something that 's more soft because , um , you whiten you just , uh , have a function the whitening is a function of the speech probability , so it 's not a hard decision . professor c : mm - hmm . phd d : um , so i think maybe it can be used together with frame dropping and when we are not sure about if it 's speech or silence , well , maybe it has something do with this . professor c : it 's interesting . i mean , um , you know , in in jrasta we were essentially adding in , uh , white uh , white noise dependent on our estimate of the noise . phd d : mm - hmm . professor c : on the overall estimate of the noise . uh , i think it never occurred to us to use a probability in there . phd d : mm - hmm . professor c : you could imagine one that that that made use of where where the amount that you added in was , uh , a function of the probability of it being s speech or noise . phd d : mm - hmm . mm - hmm . yeah , w yeah , right now it 's a constant that just depending on the the noise spectrum . phd b : there 's professor c : yeah . phd d : mm - hmm . mm - hmm . professor c : cuz that that brings in sort of powers of classifiers that we do n't really have in , uh , this other estimate . so it could be it could be interesting . phd d : mm - hmm . mm - hmm . professor c : what what what point does the , uh , system stop recording ? how much phd a : it 'll keep going till i guess when they run out of disk space , professor c : it went a little long ? i mean , disk phd a : but i think we 're ok . phd d : yeah . uh yeah , so there are with this technique there are some i just did something exactly the same as as the ericsson proposal but , um , the probability of speech is not computed the same way . and i think , i for yeah , for a lot of things , actually a g a good speech probability is important . like for frame dropping you improve , like you can improve from ten percent as sunil showed , if you use the channel zero speech probabilities . professor c : mm - hmm . mm - hmm . phd d : for this it might help , um professor c : mm - hmm . phd d : s so , yeah . uh , so yeah , the next thing i started to do is to , uh , try to develop a better voice activity detector . and , um i d um yeah , for this i think we can maybe try to train the neural network for voice activity detection on all the data that we have , including all the speechdat - car data . um and so i 'm starting to obtain alignments on these databases . um , and the way i mi i do that is that i just use the htk system but i train it only on the close - talking microphone . and then i aligned i obtained the viterbi alignment of the training utterances . um it seems to be , uh i actually what i observed is that for italian it does n't seem th - there seems to be a problem . phd b : no . so , it does n't seems to help by their use of channel zero or channel one . phd d : well . because what ? phd b : uh , you mean their d the frame dropping , right ? yeah , it does n't phd d : yeah . yeah . so , u but actually the vad was trained on italian also , phd b : italian . phd d : so um , the c the current vad that we have was trained on , uh , t spine , right ? phd b : ti - digits . phd d : italian , and ti - digits with noise and uh , yeah . and it seems to work on italian but not on the finnish and spanish data . so , maybe one reason is that s s finnish and spanish noise are different . and actually we observed we listened to some of the utterances and sometimes for finnish there is music in the recordings and strange things , right ? phd b : yeah . phd d : um yeah , so the idea was to train all the databases and obtain an alignment to train on these databases , and , um , also to , um , try different kind of features , uh , as input to the vad network . and we came up with a bunch of features that we want to try like , um , the spectral slope , the , um , the degree o degree of voicing with the features that , uh , we started to develop with carmen , um , e with , uh , the correlation between bands and different kind of features , phd b : yeah . mm - hmm . phd d : and yeah . phd b : the energy also . phd d : the energy . phd b : yeah . professor c : yeah , right . phd d : yeah . of course . yeah . professor c : ok . well , hans - guenter will be here next week so i think he 'll be interested in all all of these things . and , so . phd d : mm - hmm . phd a : ok , shall we , uh , do digits ? professor c : yeah . phd a : want to go ahead , morgan ?"
}