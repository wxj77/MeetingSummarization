{
    "query": "<s> what was the current technique and its limitations ?",
    "answer": "phd a : cuz there 's no adaptation yet . so there 's i think there 's some issues about u we probably want to adapt at least the foreground speaker . but , i guess andreas tried adapting both the foreground and a background generic speaker , and that 's actually a little bit of a f funky model . like , it gives you some weird alignments , just because often the background speakers match better to the foreground than the foreground speaker . phd f : oh phd d : yeah . phd a : so there 's some things there , especially when you get lots of the same words , uh , occurring in the phd f : well , the i i think you can do better by uh , cloning so we have a reject phone . and you and what we wanted to try with you know , once we have this paper written and have a little more time , uh , t cloning that reject model and then one copy of it would be adapted to the foreground speaker to capture the rejects in the foreground , like fragments and stuff , and the other copy would be adapted to the background speaker . phd a : right . i mean , in general we actually phd f : and phd a : right now the words like partial words are reject models and you normally allow those to match to any word . phd f : mm - hmm . phd a : but then the background speech was also a reject model , and so this constraint of not allowing rejects in between you know , it needs to differentiate between the two . so just sort of working through a bunch of debugging kinds of issues . phd f : right . phd a : and another one is turns , like people starting with `` well i think `` and someone else is `` well how about `` . so the word `` well `` is in this in this segment multiple times , and as soon as it occurs usually the aligner will try to align it to the first person who says it . but then that constraint of sort of uh , proximity constraint will push it over to the person who really said it in general . grad e : is the proximity constraint a hard constraint , or did you do some sort of probabilistic weighting distance , or ? phd f : we we did n't phd a : right now it 's a kluge . phd f : no . we w ok . we it 's straightforward to actually just have a a penalty that does n't completely disallows it but discourages it . but , um , we just did n't have time to play with , you know , tuning yet another yet another parameter . grad e : the ve level . yeah . phd a : yeah . phd f : and really the reason we ca n't do it is just that we do n't have a we do n't have ground truth for these . so , we would need a hand - marked , um , word - level alignments or at least sort of the boundaries of the speech betw you know , between the speakers . um , and then use that as a reference and tune the parameters of the of the model , uh , to op to get the best performance . phd a : yeah . professor b : g given i i mean , i wa i wa i was gon na ask you anyway , uh , how you assessed that things were better . phd f : mm - hmm . phd a : i looked at them . i spent two days um , in waves oh , it was painful because the thing is , you know the alignments share a lot in common , so and you 're yo you 're looking at these segments where there 's a lot of speech . i mean , a lot of them have a lot of words . not by every speaker professor b : yeah . phd a : but by some speaker there 's a lot of words . no , not"
}