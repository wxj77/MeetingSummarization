{
    "query": "<s> what was the professor 's take on the 12 second mean ?",
    "answer": "professor c : yeah , and again , if you take this filtering perspective and if you essentially have it build up over time . i mean , if you computed means over two and then over four , and over six , essentially what you 're getting at is a kind of , uh , ramp up of a filter anyway . and so you may may just want to think of it as a filter . but , uh , if you do that , then , um , in practice somebody using the smartkom system , one would think { comment } if they 're using it for a while , it means that their first utterance , instead of , you know , getting , uh , a forty percent error rate reduction , they 'll get a uh , over what , uh , you 'd get without this , uh , um , policy , uh , you get thirty percent . and then the second utterance that you give , they get the full you know , uh , full benefit of it if it 's this ongoing thing . phd a : oh , so you you cache the utterances ? that 's how you get your , uh professor c : well , i 'm saying in practice , yeah , phd a : ah . ok . professor c : that 's if somebody 's using a system to ask for directions or something , you know , they 'll say something first . and and to begin with if it does n't get them quite right , ma m maybe they 'll come back and say , `` excuse me ? `` phd a : mm - hmm . professor c : uh , or some i mean it should have some policy like that anyway . phd a : mm - hmm . professor c : and and , uh , uh , in any event they might ask a second question . and it 's not like what he 's doing does n't , uh , improve things . it does improve things , just not as much as he would like . and so , uh , there 's a higher probability of it making an error , uh , in the first utterance . phd a : what would be really cool is if you could have uh , this probably users would never like this but if you had could have a system where , before they began to use it they had to introduce themselves , verbally . professor c : mm - hmm . phd a : you know . `` hi , my name is so - and - so , professor c : yeah . phd a : i 'm from blah - blah - blah . `` and you could use that initial speech to do all these adaptations and professor c : right . grad e : mm - hmm . professor c : oh , the other thing i guess which which , uh , i do n't know much about as much as i should about the rest of the system but but , um , could n't you , uh , if you if you sort of did a first pass i do n't know what kind of , uh , uh , capability we have at the moment for for doing second passes on on , uh , uh , some kind of little small lattice , or a graph , or confusion network , or something . but if you did first pass with , um , the with either without the mean sub subtraction or with a a very short time one , and then , um , once you , uh , actually had the whole utterance in , if you did , um , the , uh , uh , longer time version then , based on everything that you had , um , and then at that point only used it to distinguish between , you know , top n , um , possible utterances or something , you you might it might not take very much time . i mean , i know in the large vocabulary stu uh , uh , systems , people were evaluating on in the past , some people really pushed everything in to make it in one pass but other people did n't and had multiple passes . and , um , the argument , um , against multiple passes was u u has often been `` but we want to this to be r you know have a nice interactive response `` . and the counterargument to that which , say , uh , bbn i think had , { comment } was `` yeah , but our second responses are second , uh , passes and third passes are really , really fast `` . phd a : mm - hmm . professor c : so , um , if if your second pass takes a millisecond who cares ? um . grad e : s so , um , the the idea of the second pass would be waiting till you have more recorded speech ? or ? professor c : yeah , so if it turned out to be a problem , that you did n't have enough speech because you need a longer longer window to do this processing , then , uh , one tactic is you know , looking at the larger system and not just at the front - end stuff { comment } is to take in , um , the speech with some simpler mechanism or shorter time mechanism , grad e : mm - hmm . professor c : um , do the best you can , and come up with some al possible alternates of what might have been said . and , uh , either in the form of an n - best list or in the form of a lattice , or or confusion network , or whatever . grad e : mm - hmm . professor c : and then the decoding of that is much , much faster or can be much , much faster if it is n't a big bushy network . and you can decode that now with speech that you 've actually processed using this longer time , uh , subtraction . so i mean , it 's it 's common that people do this sort of thing where they do more things that are more complex or require looking over more time , whatever , in some kind of second pass . grad e : mm - hmm . ok ."
}