{
    "query": "<s> summarize the discussion on noise addition",
    "answer": "phd e : and if you add too much noise it get worse also . and it seems that right now this this is c a constant that does not depend on { comment } on anything that you can learn from the utterance . it 's just a constant noise addition . um . and i i think w w professor d : i i 'm sorry . then then i 'm confused . phd e : i think professor d : i thought you 're saying it does n't depend on the utterance but i thought you were adding an amount that was twenty - five db down from the signal energy . phd e : yeah , so the way i did that , { comment } i i just measured the average speech energy of the all the italian data . and then i i have i used this as mean speech energy . mm - hmm . professor d : oh , it 's just a constant amount over all . phd e : yeah . and wha what i observed is that for italian and spanish , { comment } when you go to thirty and twenty - five db , { comment } uh it it 's good . it stays in this range , it 's , uh , the p u well , the performance of the this algorithm is quite good . but for finnish , you have a degradation already when you go from thirty - five to thirty and then from thirty to twenty - five . and i have the feeling that maybe it 's because just finnish has a mean energy that 's lower than than the other databases . and due to this the thresholds should be professor d : yeah . phd e : the the a the noise addition should be lower professor d : but in i mean , in the real thing you 're not gon na be able to measure what people are doing over half an hour or an hour , or anything , right ? phd e : and professor d : so you have to come up with this number from something else . phd e : yeah . so professor g : uh , but you are not doing it now language dependent ? or ? phd e : it 's not . it 's just something that 's fixed . professor g : no . it 's overall . phd e : yeah . mm - hmm . um professor d : but what he is doing language dependent is measuring what that number i reference is that he comes down twenty - five down from . phd e : yeah , so i g no . it no . because i did it i started working on italian . i obtained this average energy professor d : yeah . phd e : and then i used this one . phd b : for all the languages . ok . phd e : yeah . professor d : so it 's sort of arbitrary . phd b : yeah . professor d : i mean , so if y if yeah . yeah . phd e : um , yeah , so the next thing is to use this as as maybe initialization professor d : uh - huh . phd e : and then use something on - line . professor d : something more adaptive , phd e : but and i expect improvement at least in finnish because eh the way professor d : yeah . ok . phd e : well , um , for italian and spanish it 's th this value works good but not necessarily for finnish . mmm . but unfortunately there is , like , this forty millisecond latency and , um yeah , so i would try to somewhat reduce this @ @ . i already know that if i completely remove this latency , so . um , { comment } it um there is a three percent hit on italian . professor g : mm - hmm . phd b : d does latency sorry . go ahead . professor g : yeah . your your smoothing was @ @ { comment } uh , over this s so to say , the the factor of the wiener . and then it 's , uh what was it ? this phd e : mm - hmm . professor g : this smoothing , it was over the subtraction factor , so to say . phd e : it 's a smoothing over the the gain of the subtraction algorithm . professor g : was this done mm - hmm . and and you are looking into the future , into the past . phd e : right . professor g : and smoothing . phd e : so , to smooth this thing . professor g : mm - hmm . phd e : yeah . um professor g : and did did you try simply to smooth um to smooth the the t to to smooth stronger the the envelope ? phd e : um , no , i did not . professor g : because i mean , it should have a similar effect if you phd e : yeah . professor g : i mean , you you have now several stages of smoothing , so to say . you start up . as far as i remember you you smooth somehow the envelope , you smooth somehow the noise estimate , phd e : mm - hmm . mmm professor g : and and later on you smooth also this subtraction factor . phd e : uh , no , it 's it 's just the gain that 's smoothed actually phd b : uh , actually i d i do all the smoothing . phd e : but it 's smoothed professor g : ah . oh , it w it was you . phd b : yeah , yeah . phd e : uh yeah . professor g : yeah . phd e : yeah . no , in this case it 's just the gain . professor g : yeah . phd e : and professor g : uh - huh . phd e : but the way it 's done is that um , for low gain , there is this non nonlinear smoothing actually . for low gains um , i use the smoothed sm uh , smoothed version but for high gain @ @ { comment } it 's i do n't smooth . professor g : uh . mm - hmm . i just , uh it experience shows you , if if you do the the best is to do the smoo smoothing as early as possible . phd e : uh - huh . professor g : so w when you start up . i mean , you start up with the with the somehow with the noisy envelope . phd e : mm - hmm . professor g : and , best is to smooth this somehow . phd e : mm - hmm . uh , yeah , i could try this . um . professor g : and phd b : so , before estimating the snr , @ @ smooth the envelope . professor g : yeah . yeah . uh - huh . phd e : mm - hmm . but yeah . then i i would need to find a way to like smooth less also when there is high energy . cuz i noticed that it it helps a little bit to s like smooth more during low energy portions and less during speech , professor g : yes , y phd e : because if you smooth then y you kind of distort the speech . professor g : yeah . yeah . right . phd e : mm - hmm . professor g : yeah , i think when w you you could do it in this way that you say , if you if i 'm you have somehow a noise estimate , phd e : mm - hmm . professor g : and , if you say i 'm i 'm with my envelope i 'm close to this noise estimate , phd e : yeah . professor g : then you have a bad signal - to - noise ratio and then you you would like to have a stronger smoothing . phd e : mm - hmm . professor g : so you could you could base it on your estimation of the signal - to - noise ratio on your actual phd e : mm - hmm . mm - hmm . mmm . phd b : yeah , or some silence probability from the vad if you have phd e : um , yeah , but i do n't trust the current vad . so . phd b : yeah , uh , so not not right now maybe . phd e : well , maybe . professor d : the vad later will be much better . phd e : maybe . professor d : yeah . so . i see . phd f : so is that it ? phd e : uh , fff { comment } i think that 's it . yeah . uh . professor g : s so to summarize the performance of these , speechdat - car results is similar than than yours so to say . phd b : yeah , so the fifty - eight is like the be some fifty - six point phd e : yeah . professor g : y you have you have fifty - six point four phd b : yeah , that 's true . professor g : and and and dependent on this additive constant , it is s better or or worse . phd e : yeah . phd b : slightly better . phd e : mm - hmm . phd b : yeah . phd e : mm - hmm . professor g : yeah . phd e : and , yeah , i i i the condition where it 's better than your approach , it 's it just because maybe it 's better on well matched and that the weight on well matched is is bigger , phd b : yeah . yeah , you you caught up . phd e : because phd b : yep , that 's true . phd e : if you do n't weigh differently the different condition , you can see that your well , the win the two - stage wiener filtering is maybe better or phd b : yeah . phd e : it 's better for high mismatch , right ? phd b : yeah , it 's better for high mismatch ."
}