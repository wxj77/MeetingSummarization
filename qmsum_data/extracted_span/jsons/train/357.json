{
    "query": "<s> what did the team say on experiments ?",
    "answer": "grad h : yeah , i 've been playing with , um uh , using the close - talking mike to do to try to figure out who 's speaking . so my first attempt was just using thresholding and filtering , that we talked about about two weeks ago , and so i played with that a little bit , and it works o k , except that it 's very sensitive to your choice of your filter width and your threshold . so if you fiddle around with it a little bit and you get good numbers you can actually do a pretty good job of segmenting when someone 's talking and when they 're not . but if you try to use the same paramenters on another speaker , it does n't work anymore , even if you normalize it based on the absolute loudness . phd b : but does it work for that one speaker throughout the whole meeting ? grad h : it does work for the one speaker throughout the whole meeting . um pretty well . phd a : how did you do it adam ? grad h : pretty well . how did i do it ? phd a : yeah . grad h : what do you mean ? phd a : i mean , wh what was the grad h : the algorithm was , uh take o every frame that 's over the threshold , and then median - filter it , and then look for runs . phd a : yeah . mm - hmm . grad h : so there was a minimum run length , phd a : every frame that 's over what threshold ? grad h : so that a threshold that you pick . phd a : in terms of energy ? ah ! grad h : yeah . postdoc f : say that again ? frame over fres threshold . grad h : so you take a each frame , and you compute the energy and if it 's over the threshold you set it to one , and if it 's under the threshold you set it to zero , so now you have a bit stream of zeros and ones . postdoc f : hmm . ok . grad h : and then i median - filtered that using , um a fairly long filter length . uh well , actually i guess depends on what you mean by long , you know , tenth of a second sorts of numbers . um and that 's to average out you know , pitch , you know , the pitch contours , and things like that . and then , uh looked for long runs . and that works o k , if you fil if you tune the filter parameters , if you tune how long your median filter is and how high you 're looking for your thresholds . phd a : did you ever try running the filter before you pick a threshold ? grad h : no . i certainly could though . but this was just i had the program mostly written already so it was easy to do . ok and then the other thing i did , was i took javier 's speaker - change detector acoustic - change detector , and i implemented that with the close - talking mikes , and unfortunately that 's not working real well , and it looks like it 's the problem is he does it in two passes , the first pass is to find candidate places to do a break . and he does that using a neural net doing broad phone classification and he has the the , uh one of the phone classes is silence . and so the possible breaks are where silence starts and ends . and then he has a second pass which is a modeling a gaussian mixture model . um looking for uh whether it improves or or degrades to split at one of those particular places . and what looks like it 's happening is that the even on the close - talking mike the broad phone class classifier 's doing a really bad job . phd a : who was it trained on ? grad h : uh , i have no idea . i do n't remember . does an do you remember , morgan , was it broadcast news ? professor d : i think so , yeah . grad h : um so , at any rate , my next attempt , which i 'm in the midst of and have n't quite finished yet was actually using the uh , thresholding as the way of generating the candidates . because one of the things that definitely happens is if you put the threshold low you get lots of breaks . all of which are definitely acoustic events . they 're definitely someone talking . but , like , it could be someone who is n't the person here , but the person over there or it can be the person breathing . and then feeding that into the acoustic change detector . and so i think that might work . but , i have n't gotten very far on that . but all of this is close - talking mike , so it 's , uh just just trying to get some ground truth . phd e : only with eh uh , but eh i i i think , eh when when , y i i saw the the the the speech from pda and , eh close talker . i i think the there is a a great difference in the in the signal . grad h : oh , absolutely . phd e : um but eh i but eh i i i mean that eh eh in the in the mixed file you can find , uh zone with , eh great different , eh level of energy . grad h : so s my intention for this is is as an aide for ground truth . not phd e : um i i think for , eh algorithm based on energy , eh , that um h mmm , more or less , eh , like eh eh , mmm , first sound energy detector . grad h : say it again ? phd e : eh nnn . when y you the detect the the the first at at the end of of the detector of , ehm princ um . what is the the name in english ? the the , mmm , the de detector of , ehm of a word in the in the s in an isolated word in in the background that , uh grad h : i 'm i 'm not sure what you 're saying , can you try phd e : i mean that when when you use , eh eh any phd a : i think he 's saying the onset detector . phd e : yeah . grad h : onset detector , ok . phd e : i i think it 's probably to work well eh , because , eh you have eh , in the mixed files a great level of energy . eh and great difference between the sp speaker . and probably is not so easy when you use the the pda , eh that because the signal is , eh the in the e energy level . grad h : right . phd e : in in that , eh eh speech file is , eh more similar . between the different eh , speaker , um i i think is eh , it will i is my opinion . grad h : right . but different speakers . phd e : it will be , eh more difficult to to detect bass - tone energy . the the change . i think that , um grad h : ah , in the clo in the p d a , you mean ? phd e : in the pda . grad h : absolutely . phd e : yeah . yeah . grad h : yeah , no question . it 'll be much harder . professor d : yeah . grad h : much harder . phd e : and the the another question , that when i review the the the work of javier . i think the , nnn , the , nnn , that the idea of using a neural network to to get a broad class of phonetic , eh from , eh uh a candidate from the the the speech signal . if you have , eh uh , i 'm considering , only because javier , eh only consider , eh like candidate , the , nnn , eh the silence , because it is the the only model , eh eh , he used that , eh eh nnn , to detect the the possibility of a a change between the between the speaker , grad h : right . phd e : um another another research thing , different groups , eh working , eh on broadcast news prefer to , eh to consider hypothesis eh between each phoneme . grad h : mm - hmm . yeah , when a phone changes . phd e : because , i i i think it 's more realistic that , uh only consider the the the the silence between the speaker . eh there there exists eh silence between between , eh a speaker . is is , eh eh acoustic , eh event , important to to consider . professor d : mm - hmm . mm - hmm . phd e : i i found that the , eh silence in in many occasions in the in the speech file , but , eh when you have , eh eh , two speakers together without enough silence between between them , eh i think eh is better to use the acoustic change detector basically and i i i ix or , mmm , bic criterion for consider all the frames in my opinion . professor d : mm - hmm . yeah , the you know , the reason that he , uh just used silence was not because he thought it was better , it was it was it was the place he was starting . phd e : yeah . professor d : so , he was trying to get something going , phd e : yeah . professor d : and , uh e e you know , as as as is in your case , if you 're here for only a modest number of months you try to pick a realistic goal , phd e : yeah , yeah , yeah , yeah . yeah . yeah , yeah , yeah , yeah . grad h : do something . professor d : but his his goal was always to proceed from there to then allow broad category change also . phd e : uh - huh . but , eh do do you think that if you consider all the frames to apply the the , eh the bic criterion to detect the the the different acoustic change , eh between speaker , without , uh with , uh silence or with overlapping , uh , i think like like , eh eh a general , eh eh way of process the the acoustic change . professor d : mm - hmm . phd e : in a first step , i mean . professor d : mm - hmm . phd e : an - and then , eh eh without considering the you you you , um you can consider the energy like a another parameter in the in the feature vector , eh . grad h : right . absolutely . professor d : mm - hmm . phd e : this this is the idea . and if , if you do that , eh eh , with a bic uh criterion for example , or with another kind of , eh of distance in a first step , and then you , eh you get the , eh the hypothesis to the this change acoustic , eh to po process grad h : right . phd e : because , eh eh , probably you you can find the the eh a small gap of silence between speaker with eh eh a ga mmm , small duration less than , eh two hundred milliseconds for example professor d : mm - hmm . phd e : and apply another another algorithm , another approach like , eh eh detector of ene , eh detector of bass - tone energy to to consider that , eh that , eh zone . of s a small silence between speaker , or another algorithm to to process , eh the the segment between marks eh founded by the the the bic criterion and applied for for each frame . professor d : mm - hmm . mm - hmm . phd e : i think is , eh nnn , it will be a an an a more general approach the if we compare with use , eh a neural net or another , eh speech recognizer with a broad class or or narrow class , because , in my opinion eh it 's in my opinion , eh if you if you change the condition of the speech , i mean , if you adjust to your algorithm with a mixed speech file and to , eh to , eh adapt the neural net , eh used by javier with a mixed file . professor d : mm - hmm . mm - hmm . phd e : uh with a m mixed file , grad h : with the what file ? phd a : `` mixed `` . phd e : with a the mix , mix . postdoc f : `` mixed . `` grad h : `` mixed ? `` professor d : mm - hmm . phd e : sorry . and and then you you , eh you try to to apply that , eh , eh , eh , speech recognizer to that signal , to the pda , eh speech file , i i think you will have problems , because the the the the condition you you will need t t i i suppose that you will need to to to retrain it . professor d : well , i i grad h : oh , absolutely . this is this is not what i was suggesting to do . professor d : u look , i i think this is a one once it 's a i used to work , like , on voiced on voice silence detection , you know , and this is this kind of thing . phd e : really ? yeah . professor d : um if you have somebody who has some experience with this sort of thing , and they work on it for a couple months , they can come up with something that gets most of the cases fairly easily . then you say , `` ok , i do n't just wan na get most of the cases i want it to be really accurate . `` then it gets really hard no matter what you do . so , the p the problem is is that if you say , `` well i i have these other data over here , that i learn things from , either explicit training of neural nets or of gaussian mixture models or whatever . `` phd e : yeah . professor d : uh suppose you do n't use any of those things . you say you have looked for acoustic change . well , what does that mean ? that that means you set some thresholds somewhere or something , phd e : yeah . professor d : right ? and and so where do you get your thresholds from ? phd e : yeah . professor d : from something that you looked at . so you always have this problem , you 're going to new data um h how are you going to adapt whatever you can very quickly learn about the new data ? uh , if it 's gon na be different from old data that you have ? and i think that 's a problem with this . grad h : well , also what i 'm doing right now is not intended to be an acoustic change detector for far - field mikes . what i 'm doing is trying to use the close - talking mike and just use can - and just generate candidate and just try to get a first pass at something that sort of works . phd e : yeah ! phd a : you have candidates . phd g : actually actually actually phd e : the candidate . phd g : i phd a : to make marking easier . yeah . phd g : or grad h : and i have n't spent a lot of time on it and i 'm not intending to spend a lot of time on it . phd g : ok . i um , i , unfortunately , have to run , but , um i can imagine uh building a um model of speaker change detection that takes into account both the far - field and the uh actually , not just the close - talking mike for that speaker , but actually for all of th for all of the speakers . grad h : yep . everyone else . professor d : yeah . phd g : um if you model the the effect that me speaking has on your microphone and everybody else 's microphone , as well as on that , and you build , um basically i think you 'd you would build a an hmm that has as a state space all of the possible speaker combinations grad h : all the yep . phd e : yeah . phd g : and , um you can control grad h : it 's a little big . phd g : it 's not that big actually , um grad h : two to the n . two to the number of people in the meeting . professor d : but actually , andreas may maybe maybe just something simpler but but along the lines of what you 're saying , grad h : anyway . phd e : yeah . professor d : i was just realizing , i used to know this guy who used to build , uh um , mike mixers automatic mike mixers where , you know , t in order to able to turn up the gain , you know , uh as much as you can , you you you lower the gain on on the mikes of people who are n't talking , phd e : yeah { comment } yeah . phd g : mmm . mm - hmm . professor d : right ? and then he had some sort of reasonable way of doing that , phd g : mm - hmm . professor d : but uh , what if you were just looking at very simple measures like energy measures but you do n't just compare it to some threshold overall but you compare it to the energy in the other microphones . grad h : i was thinking about doing that originally to find out who 's the loudest , and that person is certainly talking . professor d : yeah . grad h : but i also wanted to find threshold uh , excuse me , mol overlap . professor d : yeah . grad h : so , not just just the loudest . phd e : but , eh postdoc f : mm - hmm . phd e : i i sorry . i i have found that when when i i analyzed the the speech files from the , eh mike , eh from the eh close eh microphone , eh i found zones with a a different level of energy . phd g : sorry , i have to go . grad h : ok . could you fill that out anyway ? just , put your name in . are y you want me to do it ? i 'll do it . phd a : but he 's not gon na even read that . oh . grad h : i know . phd e : including overlap zone . including . because , eh eh depend on the position of the of the microph of the each speaker to , eh , to get more o or less energy i in the mixed sign in the signal . and then , if you consider energy to to detect overlapping in in , uh , and you process the the in the the the speech file from the the the mixed signals . the mixed signals , eh . i i think it 's it 's difficult , um only to en with energy to to consider that in that zone we have eh , eh , overlapping zone eh , if you process only the the energy of the , of each frame . professor d : well , it 's probably harder , but i i think what i was s nnn noting just when he when andreas raised that , was that there 's other information to be gained from looking at all of the microphones and you may not need to look at very sophisticated things , phd e : yeah . professor d : because if there 's if most of the overlaps you know , this does n't cover , say , three , but if most of the overlaps , say , are two , if the distribution looks like there 's a couple high ones and and the rest of them are low , phd e : yeah . yeah . yeah . yeah . grad h : and everyone else is low , yeah . professor d : you know , what i mean , phd e : yeah . professor d : there 's some information there about their distribution even with very simple measures . phd e : yeah . yeah . professor d : uh , by the way , i had an idea with while i was watching chuck nodding at a lot of these things , is that we can all wear little bells on our heads , so that then you 'd know that phd e : yeah . grad h : ding , ding , ding , ding . phd e : yeah . postdoc f : `` ding `` . that 's cute ! phd b : i think that 'd be really interesting too , with blindfolds . then grad h : nodding with blindfolds , phd b : yeah . the question is , like whether grad h : `` what are you nodding about ? `` phd b : well , trying with and with and without , yeah . grad h : `` sorry , i 'm just i 'm just going to sleep . `` phd b : but then there 's just one @ @ , like . professor d : yeah . phd a : actually , i saw a uh a woman at the bus stop the other day who , um , was talking on her cell phone speaking japanese , and was bowing . you know , profusely . phd b : oh , yeah , that 's really common . phd c : yeah . phd e : yeah { comment } yeah . phd a : just , kept phd e : yeah . phd b : it 's very difficult if you try while you 're trying , say , to convince somebody on the phone it 's difficult not to move your hands . not you know , if you watch people they 'll actually do these things . professor d : mm - hmm ? phd b : so . i still think we should try a a meeting or two with the blindfolds , at least of this meeting that we have lots of recordings of grad h : mm - hmm . phd b : um , maybe for part of the meeting , we do n't have to do it the whole meeting . professor d : yeah , i think th i think it 's a great idea . phd b : that could be fun . it 'll be too hard to make barriers , i was thinking because they have to go all the way professor d : w yeah . phd b : you know , i can see chuck even if you put a barrier here . grad h : well , we could just turn out the lights . postdoc f : actually well also i i can say i made barr barriers for so that the stuff i was doing with collin wha which just used , um this kind of foam board . phd b : y yeah ? postdoc f : r really inexpensive . you can you can masking tape it together , these are you know , pretty l large partitions . professor d : yeah . phd b : but then we also have these mikes , is the other thing i was thinking , so we need a barrier that does n't disturb the sound , postdoc f : it 's true , it would disturb the , um the the long - range grad h : the acoustics ."
}