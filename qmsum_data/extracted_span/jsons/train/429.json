{
    "query": "<s> what were the main topics ?",
    "answer": "grad a : ok , we 're recording . professor f : we can say the word `` zero `` all we want , phd g : i 'm doing some professor f : but just phd g : square brackets , coffee sipping , square brackets . phd b : that 's not allowed , i think . postdoc c : cur - curly brackets . grad e : is that voiced or unvoiced ? grad a : curly brackets . phd b : curly brackets . professor f : curly brackets . grad a : right . phd b : oops . professor f : well , correction for transcribers . phd g : mmm ! { comment } gar - darn ! professor f : yeah . postdoc c : channel two . grad a : do we use square brackets for anything ? postdoc c : yeah . uh grad e : these poor transcribers . postdoc c : not ri not right now . i mean no . phd d : there 's gon na be some zeros from this morning 's meeting because i noticed that barry , i think maybe you turned your mike off before the digits were oh , was it during digits ? oh , so it does n't matter . professor f : yeah . grad a : it 's still not a good idea . phd b : so it 's not it 's not that bad if it 's at the end , but it 's in the beginning , it 's bad . phd d : yeah . yeah . grad a : yeah , you wan na you wan na keep them on so you get good noise noise floors , through the whole meeting . postdoc c : that 's interesting . hmm . professor f : uh , i probably just should have left it on . yeah i did have to run , but grad e : is there any way to change that in the software ? grad a : change what in the software ? grad e : where like you just do n't like if you if it starts catching zeros , like in the driver or something in the card , or somewhere in the hardware where if you start seeing zeros on w across one channel , you just add some random , @ @ { comment } noise floor like a small noise floor . grad a : i mean certainly we could do that , but i do n't think that 's a good idea . we can do that in post - processing if if the application needs it . grad e : yeah . phd b : manual post - processing . professor f : well , i u i actually do n't know what the default { comment } is anymore as to how we 're using the the front - end stuff but for for when we use the icsi front - end , grad a : as an argument . professor f : but um , there is an there is an o an option in in rasta , which , um , in when i first put it in , uh , back in the days when i actually wrote things , uh , i did actually put in a random bit or so that was in it , but then i realized that putting in a random bit was equivalent to adding uh adding flat spectrum , grad e : right . professor f : and it was a lot faster to just add a constant to the to the spectrum . so then i just started doing that grad e : mmm . ok . professor f : instead of calling `` rand `` { comment } or something , grad e : right . professor f : so . so it d it does that . gee ! here we all are ! grad a : uh , so the only agenda items were jane was jane wanted to talk about some of the ibm transcription process . professor f : there 's an agenda ? grad a : i sort of condensed the three things you said into that . and then just i only have like , this afternoon and maybe tomorrow morning to get anything done before i go to japan for ten days . so if there 's anything that n absolutely , desperately needs to be done , you should let me know now . professor f : uh , and you just sent off a eurospeech paper , so . phd g : right . i hope they accept it . professor f : right . phd g : i mean , i both actu as as a submission and you know , as a paper . um but grad a : well yeah , you sent it in late . professor f : yeah , i guess you first you have to do the first one , grad a : yeah . professor f : and then yeah . phd g : we actually exceeded the delayed deadline by o another day , so . phd b : oops . professor f : oh they they had some extension that they announced or something ? phd g : well yeah . liz had sent them a note saying `` could we please have another `` { comment } i do n't know , `` three days `` or something , and they said yes . phd d : and then she said `` did i say three ? i meant four . `` grad a : that was the other thing uh , uh , dave gelbart sent me email , i think he sent it to you too , { comment } that um , there 's a special topic , section in si in eurospeech on new , corp corpors corpora . and it 's not due until like may fifteenth . professor f : oh this is n't the aurora one ? it 's another one ? grad a : it 's a different one . phd b : no it 's yeah . yeah . grad a : and uh , phd b : i got this mail from grad a : i s forwarded it to jane as i thought being the most relevant person . um so , i thought it was highly relevant postdoc c : yeah i 'm professor f : that 's grad a : have you did you look at the url ? postdoc c : yeah . i think so too . um , i have n't gotten over to there yet , grad a : mm - hmm . postdoc c : but what our discussion yesterday , i really i i wan na submit one . phd b : was this smartkom message ? i think christoph draxler sent this , postdoc c : yeah . and , you offered to to join me , if you want me to . grad a : i 'll help , phd b : yeah . grad a : but obviously i ca n't , really do , most of it , postdoc c : yeah . yeah , that 's right . phd g : i think several people sent this , phd b : yeah . postdoc c : uh - huh . phd g : yeah . grad a : but any any help you need i can certainly provide . professor f : well , phd g : yeah . professor f : that 's that 's a great idea . phd g : well there there were some interesting results in this paper , though . for instance that morgan uh , accounted for fifty - six percent of the robustness meetings in terms of number of words . postdoc c : in in terms of what ? in term phd g : number of words . postdoc c : one ? wow ! ok . grad a : that 's just cuz he talks really fast . postdoc c : do you mean , professor f : n no . grad a : i know phd b : oh . short words . postdoc c : because is it partly , eh , c correctly identified words ? or is it or just overall volume ? phd g : no . well , according to the transcripts . grad a : but re well regardless . i think it 's he 's he 's in all of them , postdoc c : oh . ok . professor f : yeah . phd g : i mean , we did n't mention morgan by name grad a : and he talks a lot . phd g : we just grad a : one participant . professor f : well we have now , but phd g : we we we something about grad a : did you identify him as a senior member ? phd g : no , we as identify him as the person dominating the conversation . professor f : well . grad a : yeah . professor f : i mean i get these aarp things , but i 'm not se really senior yet , but but uh , other than that delightful result , what was the rest of the paper about ? phd g : um , well it was about it had three sections professor f : you sent it to me but i have n't seen it yet . phd g : uh three kinds of uh results , if you will . uh , the one was that the just the the amount of overlap grad a : the good , the bad , and the ugly . phd g : um , s in terms of in terms of number of words and also we computed something called a `` spurt `` , which is essentially a stretch of speech with uh , no pauses exceeding five hundred milliseconds . um , and we computed how many overlapped i uh spurts there were and how many overlapped words there were . um , for four different corpora , the meeting recorder meetings , the robustness meetings switchboard and callhome , and , found and sort of compared the numbers . um , and found that the , uh , you know , as you might expect the meeting recorder meetings had the most overlap uh , but next were switchboard and callhome , which both had roughly the same , almost identical in fact , and the robustness meetings were had the least , so one sort of unexpected result there is that uh two - party telephone conversations have about the same amount of overlap , grad a : i 'm surprised . phd g : sort of in gen you know order of magnitude - wise as , uh as face - to - face meetings with multiple grad a : i have i had better start changing all my slides ! phd g : yeah . also , i in the levinson , the pragmatics book , { comment } in you know , uh , textbook , there 's i found this great quote where he says you know you know , how people it talks about how uh how how people are so good at turn taking , postdoc c : mm - hmm . yeah . yeah . phd g : and so they 're so good that generally , u the overlapped speech does not is less than five percent . postdoc c : oh , that 's interesting . yeah . phd g : so , this is way more than five percent . grad e : did he mean face like face - to - face ? or ? phd g : well , in real conversations , everyday conversations . postdoc c : mm - hmm . phd g : it 's s what these conversation analysts have been studying for years and years there . postdoc c : mm - hmm . phd b : but postdoc c : well , of course , no , it does n't necessarily go against what he said , cuz he said `` generally speaking `` . in order to to go against that kind of a claim you 'd have to big canvassing . phd b : and in f phd g : well , he he made a claim grad a : well phd g : well phd b : but professor f : yeah , we we have pretty limited sample here . phd b : five percent of time or five percent of what ? grad a : yeah , i was gon na ask that too . postdoc c : yeah . phd b : yeah . postdoc c : exactly . phd g : well it 's time . phd b : yeah , so postdoc c : it 's i it 's not against his conclusion , phd g : so but still but still u postdoc c : it just says that it 's a bi bell curve , and that , you have something that has a nice range , in your sampling . phd g : yeah . so there are slight there are differences in how you measure it , but still it 's you know , the difference between um between that number and what we have in meetings , which is more like , you know , close to in meetings like these , uh you know , close to twenty percent . postdoc c : mm - hmm . mm - hmm . professor f : but what was it like , say , in the robustness meeting , for instance ? phd g : that grad a : but phd g : robustness meeting ? it was about half of the r so , in terms of number of words , it 's like seventeen or eigh eighteen percent for the meeting recorder meetings and about half that for , uh , the robustness . professor f : maybe ten percent ? grad a : but i do n't know if that 's really a fair way of comparing between , multi - party , conversations and two - party conversations . yeah . i i i do n't know . phd b : then then then you have to grad a : i mean that 's just something phd d : yeah , i just wonder if you have to normalize by the numbers of speakers or something . postdoc c : yeah . phd b : then yeah , then normalize by by something like that , postdoc c : yeah , that 's a good point . phd g : well , we did n't get to look at that , phd b : yeah . postdoc c : yeah . phd g : but this obvious thing to see if if there 's a dependence on the number of uh participants . postdoc c : good idea . grad a : i mean i bet there 's a weak dependence . i 'm sure it 's it 's not a real strong one . phd b : yeah . phd g : right . grad a : right ? because you phd d : cuz not everybody talks . grad a : right . phd g : right . phd d : yeah . grad a : you have a lot of a lot of two - party , subsets within the meeting . phd g : right . postdoc c : uh - huh . grad a : well regardless it 's an interesting result regardless . phd g : so right . postdoc c : yes , that 's right . phd g : and and and then and we also d computed this both with and without backchannels , postdoc c : mm - hmm . phd g : so you might think that backchannels have a special status because they 're essentially just grad a : uh - huh . so , did we all said `` uh - huh `` and nodded at the same time , phd g : r right . but , even if you take out all the backchannels so basically you treat backchannels l as nonspeech , as pauses , grad a : mm - hmm . professor f : mm - hmm . phd g : you still have significant overlap . you know , it goes down from maybe for switchboard it goes down from i do n't know f um { comment } i do n't know f fourteen percent of the words to maybe uh i do n't know , eleven percent or something it 's it 's not a dramatic change , grad a : mm - hmm . phd g : so it 's anyway , so it 's uh that was that was one set of results , and then the second one was just basically the the stuff we had in the in the hlt paper on how overlaps effect the recognition performance . grad a : nope . right . professor f : mm - hmm . phd g : and we rescored things um , a little bit more carefully . we also fixed the transcripts in in numerous ways . uh , but mostly we added one one number , which was what if you uh , basically score ignoring all so so the the conjecture from the hlt results was that most of the added recognition error is from insertions due to background speech . so , we scored all the recognition results , uh , in such a way that the uh grad a : oh by the way , who 's on channel four ? you 're getting a lot of breath . phd b : yeah . i j was just wondering . grad e : that 's phd b : yeah . grad e : that 's me . phd g : uh , well don 's been working hard . grad e : that 's right . phd g : ok , so so if you have the foreground speaker speaking here , and then there 's some background speech , may be overlapping it somehow , um , and this is the time bin that we used , then of course you 're gon na get insertion errors here and here . grad a : right . phd g : right ? so we scored everything , and i must say the nist scoring tools are pretty nice for this , where you just basically ignore everything outside of the , uh , region that was deemed to be foreground speech . and where that was we had to use the t forced alignment , uh , results from s for so that 's somewhat that 's somewhat subject to error , but still we we uh , don did some ha hand - checking and and we think that based on that , we think that the results are you know , valid , although of course , some error is gon na be in there . but basically what we found is after we take out these regions so we only score the regions that were certified as foreground speech , { comment } the recognition error went down to almost uh , the level of the non - overlapped speech . so that means that even if you do have background speech , if you can somehow separate out or find where it is , uh , the recognizer does a good job , grad a : that 's great . phd b : yeah . phd g : even though there is this back grad a : yeah , i guess that does n't surprise me , because , with the close - talking mikes , the the signal will be so much stronger . phd g : right . right . professor f : mm - hmm . phd g : mm - hmm . um , grad a : what what sort of normalization do you do ? phd g : so uh , well , we just @ @ { comment } we do u you know , vit grad a : i mean in you recognizer , in the sri recognizer . phd g : well , we do uh , vtl vocal tract length normalization , w and we uh you know , we we uh , make all the features have zero mean and unit variance . grad a : over an entire utterance ? professor f : and grad a : or windowed ? phd g : over over the entire c over the entire channel . phd b : do n't train phd g : over the but you know . um , now we did n't re - align the recognizer for this . we just took the old so this is actually a sub - optimal way of doing it , grad a : right . professor f : right . phd g : right ? so we took the old recognition output and we just scored it differently . so the recognizer did n't have the benefit of knowing where the foreground speech a start professor f : were you including the the lapel in this ? and did the did did the la did the the problems with the lapel go away also ? or phd g : um , it yeah . professor f : fray for for insertions ? phd g : it u not per i mean , not completely , but yes , professor f : less so . phd g : dramatically . so we have to um professor f : i mean , you still phd g : well i should bring the should bring the table with results . maybe we can look at it monday . professor f : i would presume that you still would have somewhat higher error with the lapel for insertions than phd g : yes . it 's it 's professor f : yeah . phd g : yes . yeah . professor f : cuz again , looking forward to the non - close miked case , i think that we s still phd g : mm - hmm . grad a : i 'm not looking forward to it . professor f : i it 's the high signal - to - noise ratio phd g : right . professor f : here that that helps you . phd g : u s right . so so that was number that was the second set of uh , the second section . and then , the third thing was , we looked at , uh , what we call `` interrupts `` , although that 's that may be a misnomer , but basically we looked at cases where uh , so we we used the punctuation from the original transcripts and we inferred the beginnings and ends of sentences . so , you know postdoc c : di - did you use upper - lower case also , or not ? phd g : um postdoc c : u upper lower case or no ? phd g : no , we only used , you know , uh periods , uh , question marks and exclamation . and we know that there 's th that 's not a very g i mean , we miss a lot of them , postdoc c : yeah . that 's ok but phd g : but but it 's f i i postdoc c : comma also or not ? phd g : no commas . no . and then we looked at locations where , uh , if you have overlapping speech and someone else starts a sentence , you know , where do these where do other people start their turns not turns really , but you know , sentences , um so we only looked at cases where there was a foreground speaker and then at the to at the so the the foreground speaker started into their sentence and then someone else started later . phd b : somewhere in between the start and the end ? phd g : ok ? and so what sorry ? phd b : somewhere in between the start and the end of the foreground ? phd g : yes . uh , so that such that there was overlap between the two sentences . phd b : yeah . phd g : so , the the question was how can we what can we say about the places where the second or or actually , several second speakers , um start their `` interrupts `` , as we call them . phd d : three words from the end . grad a : at pause boundaries . phd g : w and we looked at this in terms of um grad a : on t - closures , only . phd g : so so we had we had um u to for for the purposes of this analysis , we tagged the word sequences , and and we time - aligned them . um , and we considered it interrupt if it occurred in the middle of a word , we basically you know , considered that to be a interrupt as if it were at at the beginning of the word . so that , if any part of the word was overlapped , it was considered an interrupted word . professor f : mm - hmm . phd g : and then we looked at the the locatio the , um , you know , the features that the tags because we had tagged these word strings , { comment } um , that that occurred right before these these uh , interrupt locations . phd b : tag by uh phd g : and the tags we looked at are the spurt tag , which basically says or actually sorry . end of spurt . so whether there was a pause essentially here , because spurts are a defined as being you know , five hundred milliseconds or longer pauses , and then we had things like discourse markers , uh , backchannels , uh , disfluencies . um , uh , filled pauses so disfluen the d 's are for , um , the interruption points of a disfluency , so , where you hesitate , or where you start the repair there . uh , what else do we had . uh , repeated you know , repeated words is another of that kind of disfluencies and so forth . so we had both the beginnings and ends of these uh so , the end of a filled pause and the end of a discourse marker . and we just eyeballed i mean we did n't really hand - tag all of these things . we just looked at the distribution of words , and so every `` so yeah `` , and `` ok `` , uh , and `` uh - huh `` were were the were deemed to be backchannels and `` wow `` and `` so `` and uh `` right `` , uh were um not `` right `` . `` right `` is a backchannel . but so , we sort of just based on the lexical um , identity of the words , we we tagged them as one of these things . and of course the d the interruption points we got from the original transcripts . so , and then we looked at the disti so we looked at the distribution of these different kinds of tags , overall uh , and and and particularly at the interruption points . and uh , we found that there is a marked difference so that for instance after so at the end after a discourse marker or after backchannel or after filled pause , you 're much more likely to be interrupted than before . ok ? and also of course after spurt ends , which means basically in p inside pauses . so pauses are always an opportunity for so we have this little histogram which shows these distributions and , um , phd d : i wonder phd g : you know , it 's it 's it 's not no big surprises , but it is sort of interesting from grad a : it 's nice to actually measure it though . phd g : yeah . phd d : i wonder about the cause and effect there . in other words uh if you were n't going to pause you you will because you 're g being interrupted . phd g : well we 're ne phd d : uh phd g : right . there 's no statement about cause and effect . phd d : yeah , right . no , no , no . phd g : this is just a statistical correlation , phd d : right , i i see . yeah . phd g : yeah . professor f : but he yeah , he 's he 's right , y i mean maybe you were n't intending to pause at all , but you were intending to stop for fifty - seven milliseconds , phd g : right . professor f : but then chuck came in phd g : right . phd d : yeah . professor f : and so you paused for a second phd g : right . anyway . { comment } so , professor f : or more . phd g : uh , and that was basically it . and and we so we wrote this and then , we found we were at six pages , and then we started cutting furiously phd b : oops . phd g : and threw out half of the material again , and uh played with the latex stuff and grad a : made the font smaller and the narrows longer . phd g : uh , and until it fi phd b : font smaller , yeah . phd g : no , no . w well , d you could n't really make everything smaller phd b : put the abstract end . phd g : but we s we put oh , i i grad a : took out white space . phd g : you know the the gap between the two columns is like ten millimeters , phd b : yeah . phd g : so i d shrunk it to eight millimeters and that helped some . and stuff like that . phd d : was n't there was n't there some result , andreas professor f : yeah phd d : i i thought maybe liz presented this at some conference a while ago about uh , backchannels phd g : mm - hmm . mm - hmm . phd d : uh , and that they tend to happen when uh the pitch drops . you know you get a falling pitch . and so that 's when people tend to backchannel . phd g : yeah . well phd d : uh - i i do you rem phd g : y we did n't talk about , uh , prosodic , uh , properties at all , phd d : right . right . but phd g : although that 's i i take it that 's something that uh don will will look at grad e : yeah , we 're gon na be looking at that . phd g : now that we have the data and we have the alignment , so . this is purely based on you know the words phd d : mm - hmm . phd g : and postdoc c : i have a reference for that though . uh - huh . phd d : oh you do . phd g : yeah . phd d : so am i recalling correctly ? phd g : anyway , so . postdoc c : well , i did n't know about liz 's finding on that , phd d : about postdoc c : but i know of another paper that talks about something phd d : uh - huh . postdoc c : that grad e : i 'd like to see that reference too . phd d : it made me think about a cool little device that could be built to uh to handle those people that call you on the phone and just like to talk and talk and talk . and you just have this little detector that listens for these drops in pitch and gives them the backchannel . and so then you hook that to the phone and go off grad a : yeah . uh - huh . phd d : and do the do whatever you r wan na do , phd g : oh yeah . well phd d : while that thing keeps them busy . phd g : there 's actually uh there 's this a former student of here from berkeley , nigel nigel ward . phd d : uh - huh . sure . phd g : do you know him ? phd d : yeah . phd g : he did a system uh , in he he lives in japan now , and he did this backchanneling , automatic backchanneling system . professor f : right . phd g : it 's a very so , exactly what you describe , but for japanese . and it 's apparently for japa - in japanese it 's really important that you backchannel . it 's really impolite if you do n't , and so . professor f : huh . actually for a lot of these people i think you could just sort of backchannel continuously and it would pretty much be fine . phd d : it would n't matter ? yeah . grad e : yeah . that 's w that 's what i do . phd d : random intervals . grad a : there was there was of course a monty python sketch with that . where the barber who was afraid of scissors was playing a a tape of clipping sounds , and saying `` uh - huh `` , `` yeah `` , `` how about them sports teams ? `` phd g : anyway . so the paper 's on - line and y i i think i uh i cc ' ed a message to meeting recorder with the url so you can get it . professor f : yeah . grad a : printed it out , have n't read it yet . professor f : yeah . phd g : um , uh one more thing . so i i 'm actually about to send brian kingbury an email saying where he can find the the s the m the material he wanted for the s for the speech recognition experiment , so but i have n't sent it out yet because actually my desktop locked up , like i ca n't type anything . uh b so if there 's any suggestions you have for that i was just gon na send him the phd d : is it the same directory that you had suggested ? phd g : i made a directory . i called it um postdoc c : he still has his unix account here , you know . phd g : well this is n't postdoc c : yeah . phd g : he does ? postdoc c : and he and he 's phd g : yeah but but but he has to postdoc c : i 'd hafta add him to meeting recorder , i guess , phd g : he prefe he said he would prefer ftp postdoc c : but ok . phd g : and also , um , the other person that wants it there is one person at sri who wants to look at the um , you know , the uh the data we have so far , and so i figured that ftp is the best approach . so what i did is i um @ @ { comment } i made a n new directory after chuck said that would c that was gon na be a good thing . uh , so it 's `` ftp pub grad a : pub real . phd g : real `` exactly . mtgc what is it again ? cr grad a : ask dan ellis . professor f : u r d rdr , yeah . phd g : or yeah . right ? the same the same as the mailing list , professor f : yeah , phd g : and professor f : the no vowels . phd g : yeah . um , and then under there um actually oh and this directory , is not readable . it 's only uh , accessible . so , in other words , to access anything under there , you have to be told what the name is . grad a : right . phd g : so that 's sort of a g quick and dirty way of doing access control . professor f : mm - hmm . phd g : so uh , and the directory for this i call it i `` asr zero point one `` because it 's sort of meant for recognition . professor f : so anyone who hears this meeting now knows the grad a : beta ? phd g : and then then in there i have a file that lists all the other files , so that someone can get that file and then know the file names and therefore download them . if you do n't know the file names you ca n't professor f : is that a dash or a dot in there ? phd g : i mean you can grad a : do n't do n't do n't say . phd g : dash . anyway . so all i all i was gon na do there was stick the the transcripts after we the way that we munged them for scoring , because that 's what he cares about , and um , and also and then the the waveforms that don segmented . i mean , just basically tar them all up f i mean w for each meeting i tar them all into one tar file and g - zip them and stick them there . grad a : i uh , put digits in my own home directory home ftp directory , phd g : and so . grad a : but i 'll probably move them there as well . phd g : oh , ok . phd d : so we could point mari to this also for her march o - one request ? phd g : ok . yeah . march o - one . phd d : or you n remember she was phd g : oh she wanted that also ? phd d : well she was saying that it would be nice if we had they had a or was she talking yeah . she was saying it would be nice if they had eh the same set , so that when they did experiments they could compare . phd g : right , but they do n't have a recognizer even . phd d : yeah . grad e : um i phd g : but yeah , we can send i can cc mari on this so that she knows phd d : yeah . so , for the thing that postdoc c : that 's good . phd d : we need to give brian the beeps file , phd g : right . phd d : so i was gon na probably put it grad a : we can put it in the same place . just put in another directory . phd d : yeah , it i 'll make another directory . phd g : well , make ano make another directory . phd d : yeah . exactly . phd g : you do n't n m phd d : yeah . phd g : yeah . grad e : and , andreas , um , sampled ? phd g : yeah . they are ? grad e : i think so . yeah . um , so either we should regenerate the original versions , { comment } or um , we should just make a note of it . phd g : ok . oh . beca - well ok , because in one directory there 's two versions . grad e : yeah , that 's the first meeting i cut both versions . just to check which w if there is a significant difference . phd g : ok . and so i but ok so but for the other meetings it 's the downsampled version that you have . grad e : they 're all downsampled , yeah . phd g : oh , ok . oh that 's th important to know , ok so we should probably uh give them the non - downsampled versions . grad e : yeah . so phd g : ok . alright , then i 'll hold off on that and i 'll wait for you um grad e : probably by tomorrow i can i 'll send you an email . phd g : ok . alright . ok . yeah , definitely they should have the full bandwidth version , grad e : yeah , because i mean i i think liz decided to go ahead with the downsampled versions cuz we can there was no s like , r significant difference . phd g : yeah . ok . well , it takes it takes up less disk space , for one thing . grad e : it does take up less disk space , and apparently it did even better than the original than the original versions , phd g : yeah . yeah . grad e : which you know , is just , probably random . phd g : right . yeah , it was a small difference grad e : but , um they probably w want the originals . phd g : but yeah . yeah . ok . ok , good . good that well , it 's a good thing that grad a : ok , i think we 're losing , don and andreas at three - thirty , right ? ok . grad e : hey mon hafta booga . phd g : yeah . professor f : so , that 's why it was good to have andreas , say these things but so , we should probably talk about the ibm transcription process stuff that postdoc c : ok . so , um you know that adam created um , a b a script to generate the beep file ? to then create something to send to ibm . and , um , you you should probably talk about that . but but you were gon na to use the originally transcribed file because i tightened the time bins and that 's also the one that they had already in trying to debug the first stage of this . and uh , my understanding was that , um i have n't i have n't listened to it yet , grad a : mm - hmm . postdoc c : but it sounded very good and and i understand that you guys were going to have a meeting today , before this meeting . grad a : it was just to talk about how to generate it . um , just so that while i 'm gone , you can regenerate it if you decide to do it a different way . so uh , chuck and thilo should , now more or less know how to generate the file postdoc c : excellent . ok . grad a : and , the other thing chuck pointed out is that , um , since this one is hand - marked , there are discourse boundaries . right ? so so when one person is speaking , there 's breaks . postdoc c : mm - hmm . grad a : whereas thilo 's wo n't have that . so what what we 're probably gon na do is just write a script , that if two , chunks are very close to each other on the same channel we 'll just merge them . postdoc c : oh ! ok . ah , interesting . yeah . yeah . oh , sure . yeah , sure . makes sense . grad a : so , uh , and that will get around the problem of , the , you know `` one word beep , one word beep , one word beep , one word beep `` . postdoc c : yeah . ah ! clever . yes . clever . yeah . excellent . phd d : yeah , in fact after our meeting uh , this morning thilo came in and said that um , there could be other differences between the uh already transcribed meeting with the beeps in it and one that has just r been run through his process . postdoc c : and that 's the purpose . yeah . phd d : so tomorrow , when we go to make the um uh , chunked file for ibm , we 're going to actually compare the two . so he 's gon na run his process on that same meeting , postdoc c : great idea ! phd d : and then we 're gon na do the beep - ify on both , and listen to them and see if we notice any real differences . phd g : beep - ify ! postdoc c : ok , now one thing that prevented us from apply you you from applying exactly . the training so that is the training meeting . ok . phd d : yeah , w and we know that . wel - uh we just wan na if if there 're any major differences between doing it on the hand postdoc c : uh - huh . oh , interesting . ah ! ok . interesting idea . great . phd g : so this training meeting , uh w un is that uh some data where we have uh very um , you know , accurate time marks ? for postdoc c : i went back and hand - marked the ba the bins , i ment i mentioned that last week . phd g : ok , yeah . phd d : but the but there 's yeah , but there is this one issue with them in that there 're there are time boundaries in there that occur in the middle of speech . phd g : because phd d : so like when we went t to um when i was listening to the original file that adam had , it 's like you you hear a word then you hear a beep and then you hear the continuation of what is the same sentence . grad a : that 's on the other channel . that 's because of channel overlap . phd d : well , and and so the th grad a : it 's i phd d : so there are these chunks that look like uh that have uh grad a : i mean that 's not gon na be true of the foreground speaker . that 'll only be if it 's the background speaker . phd d : right . so you 'll you 'll have a chunk of , you know , channel a which starts at zero and ends at ten , and then the same channel starting at eleven , ending at fifteen , and then again , starting at sixteen , ending at twenty . right , so that 's three chunks where actually we w can just make one chunk out of that which is a , zero , twenty . phd g : mm - hmm . postdoc c : yeah . grad a : that 's what i just said , postdoc c : sure . sure . grad a : yeah . phd d : yeah . so i just wanted to make sure that it was clear . postdoc c : yeah , i thought that was phd d : so if you were to use these , you have to be careful not to pull out these individual postdoc c : yeah . phd g : oh ! i mean it right , i mean w i mean what i would i was interested in is having a se having time marks for the beginnings and ends of speech by each speaker . grad a : well , that 's definitely a problem . phd g : uh , because we could use that to fine tune our alignment process grad a : battery . phd d : yeah . phd g : to make it more accurate . phd b : battery ? phd d : mm - hmm . phd g : so uh , it i do n't care that you know , there 's actually abutting segments that we have to join together . that 's fine . but what we do care about is that the beginnings and ends um are actually close to the speech inside of that phd d : yeah , i think jane tightened these up by hand . phd g : uh postdoc c : yeah . phd g : ok , so what is the sort of how tight are they ? professor f : uh , it looks much better . phd b : yeah . looks good . postdoc c : they were , um , reasonably tight , but not excruciatingly tight . that would 've taken more time . i just wanted to get it so tha so that if you have like `` yeah `` { comment } in a swimming in a big bin , then it 's phd g : no , no ! i don grad a : let me make a note on yours . phd g : actually i i phd b : yeah . phd g : i it 's f that 's fine because we do n't want to th that 's perfectly fine . in fact it 's good . you always want to have a little bit of pause or nonspeech around the speech , say for recognition purposes . uh , but just just u w you know get an id i just wanted to have an idea of the of how much extra you allowed um so that i can interpret the numbers if i compared that with a forced alignment segmentation . postdoc c : i ca n't answer that , but but my main goal was um , in these areas where you have a three - way overlap and one of the overlaps involves `` yeah `` , and it 's swimming in this huge bin , i wanted to get it so that it was clo more closely localized . phd g : mm - hmm . mm - hmm . right . but are we talking about , i do n't know , a tenth of a second ? a ? you know ? how how much how much extra would you allow at most postdoc c : i i wanted to i wanted it to be able to l he be heard normally , phd g : mm - hmm . postdoc c : so that if you if you play back that bin and have it in the mode where it stops at the boundary , it sounds like a normal word . it does n't sound like the person i it sounds normal . it 's as if the person could 've stopped there . phd g : mm - hmm . postdoc c : and it would n't have been an awkward place to stop . now sometimes you know , it 's these are involved in places where there was no time . and so , there would n't be a gap afterwards because i mean some cases , there 're some people um , who who have very long segments of discourse where , you know , they 'll they 'll breath and then i put a break . phd g : mm - hmm . postdoc c : but other than that , it 's really pretty continuous and this includes things like going from one sentence into the u one utterance into the next , one sentence into the next , um , w without really stopping . i mean i they , i you know in writing you have this two spaces and a big gap phd g : mm - hmm . postdoc c : you know . phd g : right . postdoc c : but but uh i some people are planning and , you know , i mean , a lot we always are planning what we 're going to say next . but uh , in which case , the gap between these two complete syntactic units , um , which of course n spoken things are not always complete syntactically , but but it would be a shorter p shorter break than maybe you might like . phd g : mm - hmm . postdoc c : but the goal there was to not have the text be so so crudely parsed in a time bin . i mean , because from a discourse m purpose it 's it 's more it 's more useful to be able to see and also you know , from a speech recognition purpose my impression is that if you have too long a unit , it 's it does n't help you very much either , cuz of the memory . phd g : well , yeah . that 's fine . postdoc c : so , that means that the amount of time after something is variable depending partly on context , but my general goal when there was sufficient space , room , pause after it to have it be kind of a natural feeling gap . which i c i do n't know what it would be quantified as . you know , wally chafe says that um , in producing narratives , the spurts that people use tend to be , uh , that the the what would be a pause might be something like two two seconds . and um , that would be , you know one speaker . the discourse the people who look at turn taking often do use phd g : mm - hmm . postdoc c : i was interested that you chose uh , you know um , { comment } the you know that you use cuz i think that 's a unit that would be more consistent with sociolinguistics . yeah . phd g : well we chose um , you know , half a second because if if you go much larger , you have a y you know , your your statement about how much overlap there is becomes less , um , precise , postdoc c : mm - hmm . phd g : because you include more of actual pause time into what you consider overlap speech . um , so , it 's sort of a compromise , phd b : yeah . { comment } yeah , i also used i think something around zero point five seconds for the speech - nonspeech detector phd g : and it 's also based i mean liz suggested that value based on the distribution of pause times that you see in switchboard and and other corpora . postdoc c : mm - hmm . phd g : um so phd b : for the minimum silence length . phd g : mm - hmm . i see . yeah . postdoc c : mm - hmm . in any case , this this uh , meeting that i hand i i hand - adjusted two of them i mentioned before , phd g : mm - hmm . postdoc c : and i sent i sent email , so phd g : so so at some point we will try to fine - tune our forced alignment postdoc c : and i sent the { comment } path . phd g : maybe using those as references because you know , what you would do is you would play with different parameters . and to get an object you need an objective measure of how closely you can align the models to the actual speech . and that 's where your your data would be very important to have . so , i will um phd b : yeah and hopefully the new meetings which will start from the channelized version will will have better time boundaries and alignments . phd g : mm - hmm . right . postdoc c : but i like this idea of uh , for our purposes for the for the ibm preparation , uh , n having these joined together , phd b : yeah . yeah . postdoc c : and uh it makes a lot of sense . and in terms of transcription , it would be easy to do it that way . phd g : yeah . postdoc c : the way that they have with the longer units , phd g : yeah . postdoc c : not having to fuss with adding these units at this time . phd b : yeah . whi - which could have one drawback . if there is uh a backchannel in between those three things , phd g : right . postdoc c : mm - hmm . phd b : the the n the backchannel will will occur at the end of of those three . and and in in the in the previous version where in the n which is used now , there , the backchannel would would be in - between there somewhere , so . postdoc c : i see . phd b : that would be more natural postdoc c : yeah . well , phd b : but postdoc c : that 's that 's right , but you know , thi this brings me to the other f stage of this which i discussed with you earlier today , phd b : yeah . postdoc c : which is the second stage is um , w what to do in terms of the transcribers adjustment of these data . i discussed this with you too . um , the tr so the idea initially was , we would get uh , for the new meetings , so the e edu meetings , that thilo ha has now presegmented all of them for us , on a channel by channel basis . and um , so , i 've assigned i 've i 've assigned them to our transcribers and um , so far i 've discussed it with one , with uh and i had a about an hour discussion with her about this yesterday , we went through uh edu - one , at some extent . and it occurred to me that um that basically what we have in this kind of a format is you could consider it as a staggered mixed file , we had some discussion over the weekend a about at at this other meeting that we were all a at um , about whether the tran the ibm transcribers should hear a single channel audio , or a mixed channel audio . and um , in in a way , by by having this this chunk and then the backchannel after it , it 's like a stagal staggered mixed channel . and um , it occurred to me in my discussion with her yesterday that um , um , the the the maximal gain , it 's from the ibm people , may be in long stretches of connected speech . so it 's basically a whole bunch of words which they can really do , because of the continuity within that person 's turn . so , what i 'm thinking , and it may be that not all meetings will be good for this , { comment } but but what i 'm thinking is that in the edu meetings , they tend to be driven by a couple of dominant speakers . and , if the chunked files focused on the dominant speakers , then , when when it got s patched together when it comes back from ibm , we can add the backchannels . it seems to me that um , you know , the backchannels per - se would n't be so hard , but then there 's this question of the time @ @ { comment } uh , marking , and whether the beeps would be uh y y y and i 'm not exactly sure how that how that would work with the with the backchannels . and , so um and certainly things that are intrusions of multiple words , taken out of context and displaced in time from where they occurred , that would be hard . so , m my thought is i i 'm having this transcriber go through the edu - one meeting , and indicate a start time f for each dominant speaker , endpoi end time for each dominant speaker , and the idea that these units would be generated for the dominant speakers , and maybe not for the other channels . grad a : yeah the only , um , disadvantage of that is , then it 's hard to use an automatic method to do that . the advantage is that it 's probably faster to do that than it is to use the automated method and correct it . so . postdoc c : well , it grad a : we 'll just have to see . postdoc c : ok . i think i i think um , you know , the original plan was that the transcriber would adjust the t the boundaries , and all that for all the channels but , you know , that is so time - consuming , and since we have a bottleneck here , we want to get ibm things that are usable s as soon as possible , then this seemed to me it 'd be a way of gett to get them a flood of data , which would be useful when it comes back to us . and um grad a : yeah . postdoc c : oh also , at the same time she when she goes through this , she 'll be uh if there 's anything that was encoded as a pause , but really has something transcribable in it , then she 's going to uh , make a mark w uh , so you know , so that that bin would be marked as it as double dots and she 'll just add an s . and in the other in the other case , if it 's marked as speech , and really there 's nothing transcribable in it , then she 's going to put a s dash , and i 'll go through and it and um , you know , with a with a substitution command , get it so that it 's clear that those are the other category . i 'll just , you know , recode them . but um , um , the transcribable events that um , i 'm considering in this , uh , continue to be laugh , as well as speech , and cough and things like that , so i 'm not stripping out anything , just just you know , being very lenient in what 's considered speech . yeah ? phd d : jane ? in terms of the this new procedure you 're suggesting , um , u what is the grad a : it 's not that different . phd d : so i 'm a little confused , because how do we know where to put beeps ? is it i d y is it postdoc c : oh , ok . grad a : transcriber will do it . postdoc c : so what it what it what it involves is is really a s uh , uh , the original pr procedure , but only applied to uh , a certain strategically chosen s aspect of the data . grad a : we pick the easy parts of the data basically , postdoc c : so grad a : and transcriber marks it by hand . postdoc c : you got it . grad a : and because phd d : but after we 've done thilo 's thing . grad a : oh , after . oh , ok , i did n't i did n't understand that . postdoc c : oh yeah ! phd b : so , i 'm @ @ now i 'm confused . postdoc c : ok . we start with your presegmented version phd g : ok , and i 'm leaving . grad e : yeah , i have to go as well . phd g : so , um grad a : ok , leave the mikes on , and just put them on the table . grad e : ok . thanks . postdoc c : we start with the presegmented version grad a : let me mark you as no digits . phd b : you start with the presegmentation , r yeah ? postdoc c : yeah . and then um , the transcriber , instead of going painstakingly through all the channels and moving the boundaries around , and deciding if it 's speech or not , but not transcribing anything . ok ? instead of doing that , which was our original plan , the tra they focus on the dominant speaker phd d : mm - hmm . they just do that on the main channels . postdoc c : yeah . so what they do is they identify who 's the di dominant speaker , and when the speaker starts . phd b : yeah ? ok . postdoc c : so i mean , you 're still gon na phd b : and you just postdoc c : so we 're it 's based on your se presegmentation , that 's the basic thing . phd b : and you just use the s the segments of the dominant speaker then ? for for sending to to ibm or ? postdoc c : yeah . exactly . phd d : so , now jane , my question is when they 're all done adjusting the w time boundaries for the dominant speaker , { comment } have they then also erased the time boundaries for the other ones ? postdoc c : mm - hmm . uh no . no , no . huh - uh . s phd d : so how will we know who phd b : yeah . postdoc c : that 's that 's why she 's notating the start and end points of the dominant speakers . so , on a you know , so i in edu - one , i as far as i listened to it , you start off with a a s section by jerry . so jerry starts at minute so - and - so , and goes until minute so - and - so . and then mark paskin comes in . and he starts at minute such - and - such , and goes on till minute so - and - so . ok . and then meanwhile , she 's listening to both of these guys ' channels , determining if there 're any cases of misclassification of speech as nothing , and nothing as speech , phd d : mm - hmm . ok . postdoc c : and a and adding a tag if that happens . phd d : so she does the adjustments on those guys ? postdoc c : but you know , i wanted to say , his segmentation is so good , that um , the part that i listened to with her yesterday did n't need any adjustments of the bins . phd b : on that meeting . phd d : mm - hmm . postdoc c : so far we have n't . so this is not gon na be a major part of the process , at least least not in not on ones that that really phd d : so if you do n't have to adjust the bins , why not just do what it for all the channels ? postdoc c : mm - hmm ? phd d : why not just throw all the channels to ibm ? postdoc c : well there 's the question o of whether well , ok . she i it 's a question of how much time we want our transcriber to invest here when she 's gon na have to invest that when it comes back from ibm anyway . phd d : mm - hmm . postdoc c : so if it 's only inserting `` mm - hmm `` s here and there , then , would n't that be something that would be just as efficient to do at this end , instead of having it go through i b m , then be patched together , then be double checked here . phd d : mm - hmm . right . phd b : yeah . but but then we could just use the the output of the detector , and do the beeping on it , and send it to i b phd d : without having her check anything . phd b : yeah . professor f : right . postdoc c : well , i guess grad a : i think we just we just have to listen to it and see how good they are . phd b : for some meetings , i 'm i 'm sure it i n postdoc c : i 'm i 'm open to that , it was professor f : yeah , if it 's working well , phd b : that 's and some on some meetings it 's good . professor f : that sounds like a good idea since as you say you have to do stuff with the other end anyway . phd b : yeah . postdoc c : well yea ok , good . i mean the detector , this phd d : yeah , i mean we have to fix it when it comes back anyhow . phd b : yeah . postdoc c : now , you were saying that they they differ in how well they work depending on channel s sys systems and stuff . phd b : yeah . so we should perhaps just select meetings on which the speech - nonspeech detection works well , postdoc c : but edu is great . phd b : and just use , those meetings to to to send to ibm and , do the other ones . grad a : release to begin with . postdoc c : how interesting . you know professor f : what 's the problem the l i forget . is the problem the lapel , or or phd b : uh , it really depends . um , my my my impression is that it 's better for meetings with fewer speakers , and it 's better for for meetings where nobody is breathing . yeah , professor f : the dead meetings . phd b : get that 's it . phd d : so in fact this might suggest an alternative sort of a a c a hybrid between these two things . grad a : no , the undead meeting , yeah . postdoc c : yeah . yeah ? phd d : so the the one suggestion is you know we we run thilo 's thing and then we have somebody go and adjust all the time boundaries phd b : yeah . postdoc c : yeah ? phd d : and we send it to ibm . the other one is we just run his thing and send it to ibm . phd b : yeah . phd d : there 's a a another possibility if we find that there are some problems , phd b : yeah . yeah . phd d : and that is if we go ahead and we just run his , and we generate the beeps file , then we have somebody listen beeps file . phd b : yeah . and erase phd d : and they listen to each section and say `` yes , no `` whether that section is phd b : yeah . postdoc c : is intelligible . phd d : i i intelligible or not . and it just you know , there 's a little interface which will for all the `` yes `` - es it then that will be the final beep file . phd b : yeah . grad a : blech . postdoc c : that 's interesting ! cuz that 's that 's directly related to the e end task . grad a : stress test . phd d : mm - hmm . postdoc c : how interesting ! phd d : yeah . i mean it would n't be that much fun for a transcriber to sit there , hear it , beep , yes or no . phd b : nope . professor f : i i i do n't know . phd d : but it would be quick . professor f : it would be kind of quick but they 're still listening to everything . phd d : but there 's no adjusting . and that 's what 's slow . there 's no adjusting of time boundaries . postdoc c : well , eh , listening does take time too . phd d : yeah . professor f : yeah . i do n't know , i i think i 'm i 'm really tending towards grad a : one and a half times real time . professor f : i mean , what 's the worst that happens ? do the transcribers i mean as long as th on the other end they can say there 's there 's something conventions so that they say `` huh ? `` phd d : yeah . right . they they professor f : and then we can flag those later . phd d : yeah . that 's true . professor f : i i it i phd d : we can just catch it at the catch everything at this side . professor f : yeah . phd d : well maybe that 's the best way to go , postdoc c : how interesting ! phd d : just grad a : i mean it just depends on how postdoc c : well edu phd b : yeah , grad a : sorry , go ahead . postdoc c : so i was gon na say , edu - one is good enough , phd b : yeah . postdoc c : maybe we could include it in this in this set of uh , this stuff we send . phd b : yeah there 's i i think there are some meetings where it would would it 's possible like this . grad a : yeah i i think , we wo n't know until we generate a bunch of beep files automatically , listen to them and see how bad they are . phd b : yeah . yeah . phd d : yeah . postdoc c : mm - hmm . phd d : we wo n't be able to s include it with this first thing , grad a : if postdoc c : hmm . oh , ok . phd d : because there 's a part of the process of the beep file which requires knowing the normalization coefficients . postdoc c : oh , i see . phd d : and so a grad a : that 's not hard to do . just it takes you know , it just takes five minutes rather than , taking a second . phd b : yeah . grad a : so . i just hand hard - coded it . phd d : right , except i do n't think that the c the instructions for doing that was in that directory , right ? i i did n't see where you had gener grad a : no , but it 's easy enough to do . phd b : what professor f : but i but i have a phd b : doing the gain ? it 's no problem . adjusting the gain ? phd d : n doing th no , getting the coefficients , for each channel . phd b : yeah , that 's no problem . postdoc c : know what numbers . phd d : ok . so we just run that one grad a : there are lots of ways to do it . phd b : we can do that . grad a : i have one program that 'll do it . you can find other programs . phd b : yeah . i i used it , so . phd d : we just run that phd b : yeah . phd d : j - sound - stat ? ok . professor f : yeah . grad a : minus d , capital d . phd b : yeah . professor f : but but but i i i have another suggestion on that , which is , since , really what this is , is is is trying to in the large , send the right thing to them and there is gon na be this this post - processing step , um , why do n't we check through a bunch of things by sampling it ? phd d : mm - hmm . professor f : right ? in other words , rather than , um , uh , saying we 're gon na listen to everything grad a : i did n't mean listen to everything , i meant , just see if they 're any good . professor f : yeah . so y you do a bunch of meetings , you listen to to a little bit here and there , phd d : yeah . professor f : if it sounds like it 's almost always right and there 's not any big problem you send it to them . phd d : send it to them . phd b : yeah . professor f : and , you know , then they 'll send us back what we w what what they send back to us , postdoc c : oh , that 'd be great . professor f : and we 'll we 'll fix things up and some meetings will cost more time to fix up than others . grad a : we should yeah . phd b : yeah . grad a : and we should just double - check with brian on a few simple conventions on how they should mark things . phd b : sure . phd d : ok . when they when there 's either no speech in there , phd b : yeah . yeah . phd d : or something they do n't understand , postdoc c : yeah . mm - hmm . phd d : things like that . grad a : yeah , cuz @ @ uh what i had originally said to brian was well they 'll have to mark , when they ca n't distinguish between the foreground and background , professor f : yeah . grad a : because i thought that was gon na be the most prevalent . but if we send them without editing , then we 're also gon na hafta have m uh , notations for words that are cut off , phd d : mm - hmm . phd b : yeah . phd d : mm - hmm . grad a : and other sorts of , uh , acoustic problems . phd b : yeah . postdoc c : they do already . phd d : and they may just guess at what those cut - off words are , postdoc c : yeah . phd d : but w i mean we 're gon na adjust everything when we come back grad a : but what what we would like them to do is be conservative so that they should only write down the transcript if they 're sure . phd b : yeah . grad a : and otherwise they should mark it so that we can check . phd b : mark it . sure . yeah . yeah . phd d : mm - hmm . postdoc c : well , we have the unintelligibility convention . grad a : mm - hmm . postdoc c : and actually they have one also , grad a : right . postdoc c : which professor f : i can i maybe have have an order of it 's probably in your paper that i have n't looked at lately , but postdoc c : certainty . professor f : uh , an order of magnitude notion of of how on a good meeting , how often uh , do you get segments that come in the middle of words and so forth , and uh in a bad meeting how often ? postdoc c : was is it in a in a what what is the t professor f : well he 's saying , you know , that the the edu meeting was a good good meeting , postdoc c : in a good meeting , what ? phd b : yeah . postdoc c : yeah . professor f : right ? postdoc c : oh i see , professor f : uh , and so so so it was almost it was almost always doing the right thing . postdoc c : the characteristics . professor f : so i wanted to get some sense of what what almost always meant . and then , uh in a bad meeting , or p some meetings where he said oh he 's had some problems , what does that mean ? postdoc c : uh - huh . ok . professor f : so i mean does one of the does it mean one percent and ten percent ? or does it mean five percent and fifty percent ? uh phd b : so professor f : or maybe percentage is n't the right word , phd b : yeah th professor f : but you know how many how many per minute , or you know . phd b : yeah , the the problem is that , nnn , the numbers ian gave in the paper is just uh , some frame error rate . so that 's that 's not really what will be effective for for the transcribers , is they have to yeah , in in they have to insure that that 's a real s spurt or something . and but , the numbers oops . um let me think . so the speech the amount of speech that is missed by the detector , for a good meeting , i th is around or under one percent , i would say . but there can be yeah . for yeah , but there can be more there 's there 's more amount speech uh , more amount of yeah well , the detector says there is speech , but there is none . so that that can be a lot when when it 's really a breathy channel . professor f : but i think that 's less of a problem . phd b : yeah . professor f : they 'll just listen . it 's just wasted time . phd b : yeah . professor f : and th and that 's for a good meeting . now what about in a meeting that you said we 've you 've had some more trouble with ? phd b : i ca n't { comment } really hhh , { comment } tsk . { comment } i do n't have really representative numbers , i think . that 's really i i did this on on four meetings and only five minutes of of every meet of of these meetings so , it 's not not that representative , but , it 's perhaps , fff . um yeah , it 's perhaps then it 's perhaps five percent of something , which s uh the the frames speech frames which are which are missed , but um , i ca n't ca n't really tell . professor f : right . so i so i sometime , we might wan na go back and look at it more in terms of how many times is there a spurt that 's that 's uh , interrupted ? phd b : yeah . yeah . yeah . professor f : something like that ? postdoc c : the other problem is , that when it when it uh d i on the breathy ones , where you get breathing , uh , inti indicated as speech . professor f : and phd b : so postdoc c : and i guess we could just indicate to the transcribers not to encode that if they we could still do the beep file . professor f : yeah again i i think that that is probably less of a problem because if you 're if there 's if if a if a word is is split , then they might have to listen to it a few times to really understand that they ca n't quite get it . postdoc c : ok . ok . phd b : but professor f : whereas if they listen to it and there 's do n't hear any speech i think they 'd probably just listen to it once . phd b : yeah . professor f : so there 'd you 'd think there 'd be a a factor of three or four in in , uh , cost function , you know , between them or something . phd b : yeah , so but i think that 's n that really does n't happen very often that that that a word is cut in the middle or something . that 's that 's really not not normal . professor f : so so what you 're saying is that nearly always what happens when there 's a problem is that is that uh , there 's some uh , uh nonspeech that uh that is b interpreted as speech . phd b : that is marked as speech . yeah . yeah . professor f : well then , we really should just send the stuff . postdoc c : that would be great . professor f : right ? because that does n't do any harm . phd b : yeah , it 's professor f : you know , if they they hear you know , a dog bark and they say what was the word , they { comment } you know , they phd b : yeah , i als i professor f : ruff ruff ! phd b : yeah i also thought of there there are really some channels where it is almost { comment } um , only bre breathing in it . and to to re - run 's professor f : yeah ? phd b : eh , um . yeah . i 've got a a p - a method with loops into the cross - correlation with the pzm mike , and then to reject everything which which seems to be breath . professor f : uh - huh . phd b : so , i could run this on those breathy channels , and perhaps throw out grad a : that 's a good idea . postdoc c : wow , that 's a great idea . professor f : yeah . but i think i th again , i think that sort of that that would be good , phd b : yeah . professor f : and what that 'll do is just cut the time a little further . phd b : yeah . phd d : mm - hmm . professor f : but i think none of this is stuff that really needs somebody doing these these uh , uh , explicit markings . phd d : yeah . postdoc c : excellent . oh , i 'd be delighted with that , i i was very impressed with the with the result . yeah . professor f : yeah , cuz the other thing that was concerning me about it was that it seemed kind of specialized to the edu meeting , and and that then when you get a meeting like this or something , phd b : yeah . professor f : and and you have a b a bunch of different dominant speakers postdoc c : oh yeah , interesting . professor f : you know , how are you gon na handle it . postdoc c : oh yeah . professor f : whereas this sounds like a more general solution postdoc c : oh yeah , i pr i much prefer this , professor f : is postdoc c : i was just trying to find a way cuz i i do n't think the staggered mixed channel is awfully good as a way of handling overlaps . professor f : yeah . uh - huh . postdoc c : but but uh phd d : well good . that that really simplifies thing then . postdoc c : yeah . phd d : and we can just , you know , get the meeting , process it , put the beeps file , send it off to ibm . postdoc c : mm - hmm . phd d : you know ? phd b : yeah . phd d : with very little work on our side . phd b : process it , hear into it . i would phd d : do what ? phd b : um , listen to it , and then grad a : or at least sample it . phd b : yeah . phd d : well , sample it . phd b : yeah . phd d : sample it . professor f : i i would just use some samples , phd b : yeah . yeah . professor f : make sure you do n't send them three hours of `` bzzz `` { comment } or something . phd d : yeah . yeah . right . phd b : that wo n't be good . postdoc c : yeah . phd d : yeah . yeah that would be very good . phd b : yeah . phd d : and then we can you know professor f : yeah . phd d : that 'll oughta be a good way to get the pipeline going . postdoc c : oh , i 'd be delighted . yeah . phd b : and there 's there 's one point which i { comment } uh yeah , which which i r we covered when i when i r listened to one of the edu meetings , professor f : great . phd b : and that 's that somebody is playing sound from his laptop . grad a : uh - huh phd b : and i the speech - nonspeech detector just assigns randomly the speech to to one of the channels , so . uh - i have n't - i did n't think of of s of this before , grad a : what can you do ? phd b : but what what shall we do about s things like this ? postdoc c : well you were suggesting you suggested maybe just not sending that part of the meeting . grad a : yep . mmm . postdoc c : but phd b : but , sometimes the the the laptop is in the background and some somebody is is talking , and , that 's really a little bit confusing , but grad a : it 's a little bit confusing . professor f : that 's life . phd b : yeah . grad a : i mean , { comment } what 're we gon na do ? phd b : yeah . grad a : even a hand - transcription would postdoc c : do you professor f : yeah . grad a : a hand - transcriber would have trouble with that . phd b : yeah , that 's that 's a second question , `` what what will different transcribers do with with the laptop sound ? `` postdoc c : would you would professor f : what was the l what was the laptop sound ? postdoc c : yeah , go ahead . professor f : i mean was it speech , phd b : yeah . professor f : or was it phd b : it 's speech . professor f : great . postdoc c : well , so i mean so my standard approach has been if it 's not someone close - miked , then , they do n't end up on one of the close - miked channels . they end up on a different channel . and we have any number of channels available , professor f : uh - huh . phd b : yeah . postdoc c : i mean it 's an infinite number of channels . so just put them on some other channel . phd b : when thi when this is sent to to the i m - eh , i b m transcribers , i do n't know if if they can tell that 's really postdoc c : yeah , that 's right . grad a : yeah cuz there will be no channel on which it is foreground . phd b : yeah . yeah . grad a : uh postdoc c : well , they have a convention , in their own procedures , which is for a background sound . grad a : right , but , uh , in general i do n't think we want them transcribing the background , cuz that would be too much work . phd b : yeah . grad a : right ? for it because in the overlap sections , then they 'll phd d : well i do n't think jane 's saying they 're gon na transcribe it , but they 'll just mark it as being there 's some background stuff there , grad a : but that 's gon na be all over the place . postdoc c : yeah . phd d : right ? grad a : how w how will they tell the difference between that sort of background and the dormal normal background of two people talking at once ? phd b : yeah . postdoc c : oh , i think i think it 'd be easy to to say `` background laptop `` . grad a : how would they know that ? phd d : but wait a minute , why would they treat them differently ? phd b : yeah . postdoc c : well because one of them grad a : because otherwise it 's gon na be too much work for them to mark it . they 'll be marking it all over the place . phd b : yeah . postdoc c : oh , i s background laptop or , background lt would n't take any time . grad a : sure , but how are they gon na tell bet the difference between that and two people just talking at the same time ? postdoc c : and phd b : yeah . postdoc c : oh , you can tell . acoustically , ca n't you tell ? phd b : it 's really good sound , so postdoc c : oh is it ? oh ! professor f : well , i mean , is n't there a category something like uh , `` sounds for someone for whom there is no i close mike `` ? phd b : yeah that would be very important , grad a : but how do we d how do we do that for the i b m folks ? postdoc c : yeah . phd b : yeah . grad a : how can they tell that ? phd d : well we may just have to do it when it gets back here . grad a : yes , that 's my opinion as well . phd b : yeah . grad a : so we do n't do anything for it with it . phd d : yeah . postdoc c : that sounds good . grad a : and they 'll just mark it however they mark it , postdoc c : that sounds good . phd d : yeah . grad a : and we 'll correct it when it comes back . professor f : yeah . phd b : there was a category for @ @ { comment } speech . grad a : yeah , the default . postdoc c : yeah , s a grad a : no , not default . postdoc c : well , as it comes back , we have a uh when we can use the channelized interface for encoding it , then it 'll be easy for us to handle . phd b : yeah . postdoc c : but but if if out of context , they ca n't tell if it 's a channeled speak uh , you know , a close - miked speaker or not , then that would be confusing to them . grad a : right . postdoc c : i do n't know , i it does n't i do n't either way would be fine with me , i do n't really care . professor f : yeah . so . shall we uh , do digits and get out of here ? postdoc c : i have o i have one question . do you think we should send the um that whole meeting to them and not worry about pre - processing it ? professor f : yes ma ' postdoc c : or uh , what i mean is we we should leave the part with the audio in the uh , beep file that we send to ibm for that one , or should we start after the that part of the meeting is over in what we send . professor f : which part ? phd b : with postdoc c : so , the part where they 're using sounds from their from their laptops . phd b : with the laptop sound , or ? just postdoc c : w if we have speech from the laptop should we just uh , excise that from what we send to ibm , or should we i give it to them and let them do with it what they can ? phd d : i think we should just it it 's gon na be too much work if we hafta worry about that i think . postdoc c : ok , that 'd be nice to have a a uniform procedure . phd d : yeah , i think if we just m send it all to them . you know . grad a : worry about it when we get back . postdoc c : good . and see how well they do . phd d : let yeah , worry about it when we get back in . postdoc c : and give them freedom to to indicate if it 's just not workable . professor f : yeah . postdoc c : yeah , phd d : yeah . professor f : yeah . postdoc c : excellent . professor f : cuz , i would n't do n't think we would mind having that transcribed , if they did it . grad a : i think phd d : yeah , e grad a : as i say , we 'll just have to listen to it and see how horrible it is . postdoc c : yeah , yeah . phd b : yeah . grad a : sample it , rather . postdoc c : ok . alright . phd b : i think that that will be a little bit of a problem phd d : yeah . postdoc c : that 's great . phd b : as it really switches around between two different channels , i think . grad a : mm - hmm , and and they 're very it 's very audible ? on the close - talking channels ? phd b : what what i would yeah . grad a : oh well . i mean , it 's the same problem as the lapel mike . professor f : yeah . phd b : yeah . grad a : but postdoc c : oh , interesting . phd b : comparable , yeah . professor f : yeah . postdoc c : ok , alright . digits . professor f : let 's do digits . postdoc c : ok , so we read the transcript number first , right ? grad a : are we gon na do it altogether or separately ? phd b : so what time is it ? professor f : uh , why do n't we do it together , postdoc c : uh , quarter to four . phd b : oh , ok . professor f : that 's that 's a nice fast way to do it . postdoc c : mm - hmm . professor f : one , two , three , go ! postdoc c : it 's kind of interesting if there 're any more errors in these , than we had the first set . grad a : nnn , yeah , i think there probably will be . phd b : yeah . phd d : do you guys plug your ears when you do it ? grad a : i do . postdoc c : i usually do . phd d : i do . phd b : i do n't . postdoc c : i did n't this time . phd d : you do n't ? professor f : i have n't been , phd d : how can you do that ? i i professor f : uh , concentration . phd b : perhaps there are lots of errors in it grad a : total concentration . are you guys ready ? phd d : you hate to have your ears plugged ? professor f : yeah ."
}