{
    "query": "<s> what did phd c think about on-line normalization ?",
    "answer": "phd c : mmm yeah . then , uh , whhh well , i 've been working on on t mainly on on - line normalization this week . uh , i 've been trying different slightly slightly different approaches . um , the first thing is trying to play a little bit again with the , um , time constant . uh , second thing is , uh , the training of , uh , on - line normalization with two different means , one mean for the silence and one for the speech . um , and so i have two recursions which are controlled by the , um , probability of the voice activity detector . mmm . this actually do n't s does n't seem to help , although it does n't hurt . so . but well , both on - line normalization approach seems equivalent . well , they phd f : are the means pretty different for the two ? phd c : yeah . they can be very different . yeah . mm - hmm . professor b : so do you maybe make errors in different places ? different kinds of errors ? phd c : i did n't look , uh , more closely . um . it might be , yeah . mm - hmm . um . well , eh , there is one thing that we can observe , is that the mean are more different for for c - zero and c - one than for the other coefficients . and yeah . and yeah , it the c - one is there are strange strange thing happening with c - one , is that when you have different kind of noises , the mean for the the silence portion is can be different . and so when you look at the trajectory of c - one , it 's has a strange shape and i was expecting th the s that these two mean helps , especially because of the the strange c - ze c - one shape , uh , which can like , yo you can have , um , a trajectory for the speech and then when you are in the silence it goes somewhere , but if the noise is different it goes somewhere else . so which would mean that if we estimate the mean based on all the signal , even though we have frame dropping , but we do n't frame ev uh , drop everything , but uh , this can hurts the estimation of the mean for speech , and mmm . { comment } but i still have to investigate further , i think . um , a third thing is , um , that instead of t having a fixed time constant , i try to have a time constant that 's smaller at the beginning of the utterances to adapt more quickly to the r something that 's closer to the right mean . t t um yeah . and then this time constant increases and i have a threshold that professor b : mm - hmm . phd c : well , if it 's higher than a certain threshold , i keep it to this threshold to still , uh , adapt , um , the mean when if the utterance is , uh , long enough to to continue to adapt after , like , one second professor b : mm - hmm . mm - hmm . phd c : or mmm . uh , well , this does n't help neither , but this does n't hurt . so , well . it seems pretty phd f : was n't there some experiment you were gon na try where you did something differently for each , um , uh i do n't know whether it was each mel band or each , uh , um , fft bin or someth there was something you were gon na uh , { comment } some parameter you were gon na vary depending on the frequency . i do n't know if that was phd c : i guess it was i do n't know . no . u maybe it 's this this idea of having different on - line normalization , um , tunings for the different mfcc 's . phd f : for each , uh professor b : mm - hmm . phd c : but mm - hmm . phd f : yeah . i i thought , morgan , you brought it up a couple meetings ago . and then it was something about , uh , some and then somebody said `` yeah , it does seem like , you know , c - zero is the one that 's , you know , the major one `` or , uh , s i ca n't remember exactly what it was now . phd c : mmm . yeah . there uh , actually , yeah . s um , it 's very important to normalize c - zero and much less to normalize the other coefficients . and , um , actu uh , well , at least with the current on - line normalization scheme . and we i think , we kind of know that normalizing c - one does n't help with the current scheme . and and yeah . in my idea , i i was thinking that the the the reason is maybe because of these funny things that happen between speech and silence which have different means . um yeah . but maybe it 's not so so easy to professor b : um , i i really would like to suggest looking , um , a little bit at the kinds of errors . i know you can get lost in that and go forever and not see too much , but sometimes , phd c : mm - hmm . professor b : but but , um , just seeing that each of these things did n't make things better may not be enough . it may be that they 're making them better in some ways and worse in others , phd c : yeah . mm - hmm . professor b : or increasing insertions and decreasing deletions , or or , um , um , you know , helping with noisy case but hurting in quiet case . and if you saw that then maybe you it would something would occur to you of how to deal with that . phd c : mm - hmm . mm - hmm . alright . mmm . yeah . w um , so that 's it , i think , for the on - line normalization . um yeah . i 've been playing a little bit with some kind of thresholding , and , mmm , as a first experiment , i think i yeah . well , what i did is t is to take , um to measure the average no , the maximum energy of s each utterance and then put a threshold well , this for each mel band . then put a threshold that 's fifteen db below well , uh , a couple of db below this maximum , professor b : mm - hmm . mmm . phd c : and actually it was not a threshold , it was just adding noise . professor b : mm - hmm . phd c : so i was adding a white noise energy , uh , that 's fifteen db below the maximum energy of the utterance . and yeah . when we look at at the , um , mfcc that result from this , they are a lot more smoother . um , when we compare , like , a channel zero and channel one utterance um , so a clean and , uh , the same noisy utterance well , there is almost no difference between the cepstral coefficients of the two . um . and yeah . and the result that we have in term of speech recognition , actually it 's not it 's not worse , it 's not better neither , but it 's , um , kind of surprising that it 's not worse because basically you add noise that 's fifteen db just fifteen db below the maximum energy . grad a : sorry . phd c : and at least phd f : so why does that m smooth things out ? i do n't i do n't understand that . professor b : well , there 's less difference . right ? phd c : it 's i think , it 's whitening this the portion that are more silent , professor b : cuz it 's phd c : as you add a white noise that are has a very high energy , it whitens everything phd f : huh . oh , ok . phd c : and and the high - energy portion of the speech do n't get much affected anyway by the other noise . and as the noise you add is the same is the shape , it 's also the same . professor b : yeah . phd c : so they have the trajectory are very , very similar . and and professor b : so , i mean , again , if you trained in one kind of noise and tested in the same kind of noise , you 'd you know , given enough training data you do n't do b do badly . the reason that we d that we have the problems we have is because it 's different in training and test . even if the general kind is the same , the exact instances are different . and and phd f : mm - hmm . professor b : so when you whiten it , then it 's like you the the only noise to to first order , the only th noise that you have is white noise and you 've added the same thing to training and test . phd f : mm - hmm . professor b : so it 's , uh phd f : so would that be similar to , like , doing the smoothing , then , over time or ? phd c : mm - hmm . professor b : well , it 's a kind of smoothing , phd c : i think it 's i think it 's different . professor b : but phd c : it 's it 's something that yeah , that affects more or less the silence portions because phd f : mm - hmm . phd c : well , anyway , the sp the portion of speech that ha have high energy are not ch a lot affected by the noises in the aurora database . professor b : mm - hmm . phd c : if if you compare th the two shut channels of speechdat - car during speech portion , it 's n n n the mfcc are not very different . they are very different when energy 's lower , like during fricatives or during speech pauses . and , professor b : yeah , but you 're still getting more recognition errors , phd c : uh"
}